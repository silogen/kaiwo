apiVersion: amd.com/v1alpha1
kind: DeviceConfig
metadata:
  # the names for the device plugin, metrics exporter and node labeler pods will be prefixed with this name
  name: default
  # it is highly recommended to use the namespace where AMD GPU Operator is running
  namespace: kube-amd-gpu
spec:
  driver:
    # set to ture for deploying out-of-tree driver with specified ROCm version
    # set to false to directly use inbox or pre-installed driver on worker nodes
    enable: false

    # set to true to add blacklist for the amdgpu inbox driver kernel module, required for spec.driver.enable=true
    # set to false to remove blacklist for the amdgpu inbox driver kernel module, required for spec.driver.enable=false
    # the reboot of worker node is required to apply the updated blacklist
    blacklist: false

    # Specify the out-of-tree driver version
    version: "6.3.2"

    # Specify driver image here
    # DO NOT include the image tag as AMD GPU Operator will automatically manage the image tag for you
    # e.g. docker.io/username/amdgpu-driver
    image: docker.io/username/repo

    # Specify the credential for your private registry if it requires credential to get pull/push access
    # you can create the docker-registry type secret by running command like:
    # kubectl create secret docker-registry mysecret -n kube-amd-gpu --docker-username=xxx --docker-password=xxx
    # Make sure you created the secret within the namespace that gpu operator controller is running
    #imageRegistrySecret:
    #  name: mysecret

    # Specify the image registry TLS config if you are using insecure registry for managin driver images
    #imageRegistryTLS:
    #  insecure: true
    #  insecureSkipTLSVerify: true

    # Specify the image signing config for building + signing image within cluster
    #imageSign:
    #  keySecret:
    #    name: mysignkey
    #  certSecret:
    #    name: mysigncert
  devicePlugin:
    # Specify the device plugin image
    # default value is rocm/k8s-device-plugin:latest
    devicePluginImage: rocm/k8s-device-plugin:latest

    # Specify the node labeller image
    # default value is rocm/k8s-device-plugin:labeller-latest
    nodeLabellerImage: rocm/k8s-device-plugin:labeller-latest

    # Specify to enable/disable the node labeller
    # node labeller is required for adding / removing blacklist config of amdgpu kernel module
    # please set to true if you want to blacklist the inbox driver and use our-of-tree driver
    enableNodeLabeller: true

    devicePluginArguments:
      resource_naming_strategy: "mixed"

  # Specify the metrics exporter config
  metricsExporter:
    # To enable/disable the metrics exporter, disabled by default
    enable: true

    # configure a node selector for metrics exporter
    # if not specified metrics exporter will use the node selector from spec.selector by default
    #selector:
    #  feature.node.kubernetes.io/amd-gpu: "true"

    # kubernetes service type for metrics exporter, clusterIP(default) or NodePort
    serviceType: "ClusterIP"

    # internal service port used for in-cluster and node access to pull metrics from the metrics-exporter (default 5000)
    port: 5000

    # Node port for metrics exporter service, metrics endpoint $node-ip:$nodePort
    nodePort: 32500

    image: "docker.io/rocm/device-metrics-exporter:v1.3.0"

    config:
      name: "gpu-config"

  # Specify the node to be managed by this DeviceConfig Custom Resource
  selector:
    feature.node.kubernetes.io/amd-gpu: "true"

  # Enable the config manager to manage partitioning
  configManager:
    enable: true
    image: "rocm/device-config-manager:v1.3.0"
    imagePullPolicy: IfNotPresent
    config:
      name: "config-manager-config"
    configManagerTolerations:
    - key: "kaiwo-gpu-partitioning"
      operator: "Exists"
      effect: "NoSchedule"
