# Single-node Direct Preference Optimization (DPO) example with HF Accelerate

Run on 4 GPUs with `kaiwo submit -p workloads/training/LLMs/dpo -g 4 -n yournamespace --storage=100Gi,yourstorageclass`