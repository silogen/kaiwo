apiVersion: kaiwo.silogen.ai/v1alpha1
kind: KaiwoJob
metadata:
  name: multinode-stage-zero3-pretraining-example
spec:
  user: test@amd.com
  gpus: 16
  ray: true
  entrypoint: |
    python code/main.py \
    --model-name=meta-llama/Llama-3.1-8B-Instruct \
    --ds-config=./code/zero_3_offload_optim_param.json \
    --bucket=silogen-dev \
    --num-epochs=1 \
    --num-devices=$NUM_GPUS \
    --batch-size-per-device=32 \
    --eval-batch-size-per-device=32 \
    --ctx-len=1024
  env:
  - name: AWS_ACCESS_KEY_ID
    valueFrom:
      secretKeyRef:
        name: minio-secret
        key: access_key_id
  - name: AWS_SECRET_ACCESS_KEY
    valueFrom:
      secretKeyRef:
        name: minio-secret
        key: secret_key
  - name: HF_TOKEN
    valueFrom:
      secretKeyRef:
        name: hf-token
        key: hf-token
  - name: MODEL_ID
    value: meta-llama/Llama-3.1-8B-Instruct
  storage:
    storageEnabled: true
    storageclassName: rwx-nfs
    data:
      storageSize: 20Mi
      mountPath: /workload
      download:
        git:
        - repository: https://github.com/silogen/kaiwo.git
          path: workloads/training/LLMs/full-parameter-pretraining/full-param-zero3-single-multinode
          targetPath: code
    huggingFace:
      storageSize: "100Gi"
      mountPath: "/hf_cache" # Also sets the env var HF_HOME to this value in each container
      preCacheRepos:
      - repoId: meta-llama/Llama-3.1-8B-Instruct
        files: []
