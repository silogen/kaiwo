apiVersion: chainsaw.kyverno.io/v1alpha1
kind: Test
metadata:
  name: integration-cache-from-service-public
spec:
  description: Test that an AIMService can use template cache with network isolation, caching enabled from service spec, with public model
  steps:
  - name: Create runtime config
    try:
    - apply:
        file: runtime-config.yaml

  - name: Create cluster model
    try:
    - apply:
        file: cluster-model.yaml

  - name: Wait for template to be ready with model sources
    try:
    - assert:
        timeout: 10m
        resource:
          apiVersion: aim.silogen.ai/v1alpha1
          kind: AIMClusterServiceTemplate
          metadata:
            name: aim-meta-llama-llama-3-1-8b-instruct-0-7-1x-mi300x-lat-fp8-6729
          status:
            status: Ready
            modelSources:
            - name: amd/Llama-3.1-8B-Instruct-FP8-KV
              sourceUri: hf://amd/Llama-3.1-8B-Instruct-FP8-KV

  - name: Manually create template cache (cluster templates don't auto-create)
    try:
    - apply:
        file: template-cache.yaml

  - name: Create service with cacheModel enabled
    try:
    - apply:
        file: service.yaml

  - name: Verify template cache exists
    try:
    - assert:
        timeout: 1m
        resource:
          apiVersion: aim.silogen.ai/v1alpha1
          kind: AIMTemplateCache
          metadata:
            name: aim-meta-llama-llama-3-1-8b-instruct-0-7-1x-mi300x-lat-fp8-6729-tc

  - name: Verify template cache becomes available
    try:
    - assert:
        timeout: 10m
        resource:
          apiVersion: aim.silogen.ai/v1alpha1
          kind: AIMTemplateCache
          metadata:
            name: aim-meta-llama-llama-3-1-8b-instruct-0-7-1x-mi300x-lat-fp8-6729-tc
          status:
            status: Available

  - name: Apply network policy to block inference pod internet access
    try:
    - apply:
        file: network-policy.yaml

  - name: Verify service becomes ready despite network isolation
    try:
    - assert:
        timeout: 10m
        resource:
          apiVersion: aim.silogen.ai/v1alpha1
          kind: AIMService
          metadata:
            name: integration-cache-from-service-public
          status:
            status: Running
            (conditions[?type == 'RuntimeReady']):
            - status: "True"
            (conditions[?type == 'CacheReady']):
            - status: "True"

  - name: Verify pod has cache mounts
    try:
    - assert:
        timeout: 1m
        resource:
          apiVersion: v1
          kind: Pod
          metadata:
            labels:
              serving.kserve.io/inferenceservice: integration-cache-from-service-public
          spec:
            containers:
            - name: kserve-container
              env:
              - name: AIM_CACHE_PATH
                value: /workspace/model-cache
              volumeMounts:
              - mountPath: /workspace/model-cache/amd/Llama-3.1-8B-Instruct-FP8-KV
          status:
            phase: Running

  - name: Verify the service responds
    try:
    - script:
        timeout: 2m
        env:
        - name: HTTP_BASE_PATH
          value: /integration/custom-path/integration-cache-from-service-public/v1
        content: bash ../../_shared/validate-http.sh
