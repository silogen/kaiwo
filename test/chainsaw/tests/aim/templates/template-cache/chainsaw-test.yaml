apiVersion: chainsaw.kyverno.io/v1alpha1
kind: Test
metadata:
  name: template-cache
spec:
  description: Testing template cache creation, downloading and mounting of models
  timeouts:
    assert: 60s
  steps:
  - name: Create AIMImage, AIMTemplate and AIMService
    try:
    - apply:
        file: template_stack_init.yaml

  - name: Verify that template cache is created
    try:
    - assert:
        timeout: 10s
        resource:
          apiVersion: aim.silogen.ai/v1alpha1
          kind: AIMTemplateCache
          metadata:
            name: aimdummy-template-tc
            ownerReferences:
              - name: aimdummy-template
          spec:
            modelSources:
            - name: smol2-135m
              size: 512Mi
              sourceUri: hf://HuggingFaceTB/SmolLM2-135M
            runtimeConfigName: default
            templateRef: aimdummy-template


  - name: Verify that the template cache becomes available
    try:
    - assert:
        timeout: 60s
        resource:
          apiVersion: aim.silogen.ai/v1alpha1
          kind: AIMTemplateCache
          metadata:
            name: aimdummy-template-tc
          status:
            status: Available

  - name: Verify that the cached model is mounted into the inference container
    try:
    - assert:
        timeout: 10s
        resource:
          apiVersion: v1
          kind: Pod
          metadata:
            labels:
              serving.kserve.io/inferenceservice: smollm-chat
          spec:
            (containers[?name == 'kserve-container']):
            - env:
              - name: AIM_MODEL_ID
                value: smol2-135m
              - name: VLLM_ENABLE_METRICS
                value: "true"
              (volumeMounts[?name == 'smol2-135m-cache']):
              - mountPath: /mnt/models/HuggingFaceTB/SmolLM2-135M
                name: smol2-135m-cache
          status:
            phase: Running
