apiVersion: chainsaw.kyverno.io/v1alpha1
kind: Test
metadata:
  name: multiple-services-different-templates
spec:
  description: Test that multiple services can use different templates for the same model
  timeouts:
    assert: 60s
  steps:
  - name: Create prerequisites
    try:
    - apply:
        file: cluster-image.yaml
    - apply:
        file: cluster-template-latency.yaml
    - apply:
        file: cluster-template-throughput.yaml

  - name: Wait for templates to become Available
    try:
    - assert:
        timeout: 30s
        resource:
          apiVersion: aim.silogen.ai/v1alpha1
          kind: AIMClusterServiceTemplate
          metadata:
            name: llama-3-8b-latency-multi-diff
          status:
            status: Available
    - assert:
        timeout: 30s
        resource:
          apiVersion: aim.silogen.ai/v1alpha1
          kind: AIMClusterServiceTemplate
          metadata:
            name: llama-3-8b-throughput-multi-diff
          status:
            status: Available

  - name: Create both services
    try:
    - apply:
        file: service-latency.yaml
    - apply:
        file: service-throughput.yaml

  - name: Verify both services resolve
    try:
    - assert:
        timeout: 30s
        resource:
          apiVersion: aim.silogen.ai/v1alpha1
          kind: AIMService
          metadata:
            name: latency-service
          status:
            (conditions[?type == 'Resolved']):
            - status: "True"
    - assert:
        timeout: 30s
        resource:
          apiVersion: aim.silogen.ai/v1alpha1
          kind: AIMService
          metadata:
            name: throughput-service
          status:
            (conditions[?type == 'Resolved']):
            - status: "True"

  - name: Verify separate InferenceServices with different configs
    try:
    - assert:
        resource:
          apiVersion: serving.kserve.io/v1beta1
          kind: InferenceService
          metadata:
            name: latency-service
    - assert:
        resource:
          apiVersion: serving.kserve.io/v1beta1
          kind: InferenceService
          metadata:
            name: throughput-service
