apiVersion: kaiwo.silogen.ai/v1alpha1
kind: KaiwoJob
metadata:
  name: download-job-ray-starts
  namespace: kaiwo-test
spec:
  user: test@amd.com
  gpus: 0
  resources:
    limits:
      cpu: "100m"
      memory: "100Mi"
    requests:
      cpu: "100m"
      memory: "100Mi"
  ray: true
  image: ghcr.io/silogen/ray-test:v0.3
  entrypoint: |
    sleep 1
  storage:
    storageEnabled: true
    storageClassName: "nfs-client"
    huggingFace:
      storageSize: "1Gi"
      mountPath: "/hf_cache"
      preCacheRepos:
      - repoId: TinyLlama/TinyLlama-1.1B-Chat-v1.0
        files:
        - "README.md"
