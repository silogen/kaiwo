apiVersion: kaiwo.silogen.ai/v1alpha1
kind: KaiwoJob
metadata:
  name: download-job-ray-starts
spec:
  user: test@amd.com
  resources:
    limits:
      cpu: "100m"
      memory: "100Mi"
    requests:
      cpu: "100m"
      memory: "100Mi"
  ray: true
  image: ghcr.io/silogen/ray-test:v0.3
  entrypoint: |
    sleep 1
  storage:
    storageClassName: rwx-nfs
    storageEnabled: true
    huggingFace:
      storageSize: "1Gi"
      mountPath: "/hf_cache"
      preCacheRepos:
      - repoId: TinyLlama/TinyLlama-1.1B-Chat-v1.0
        files:
        - "README.md"
