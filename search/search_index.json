{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to Kaiwo","text":"<p>\ud83d\ude80\ufe0f\ud83d\ude80\ufe0f Kaiwo supports AMD GPUs! \ud83d\ude80\ufe0f\ud83d\ude80\ufe0f</p>"},{"location":"#description","title":"Description","text":"<p>Kaiwo (pronunciation \"ky-voh\") is a Kubernetes-native tool designed to optimize GPU resource utilization for AI workloads. Built on top of Ray and Kueue , Kaiwo minimizes GPU idleness and increases resource efficiency through intelligent job queueing, fair sharing of resources, guaranteed quotas and opportunistic gang scheduling.</p> <p>Kaiwo supports a wide range of AI workloads, including distributed multi-node pretraining, fine-tuning, online inference, and batch inference, with seamless integration into Kubernetes environments.</p> <p>This documentation is intended for two main audiences:</p> <ul> <li>AI Scientists/Engineers: who want Kaiwo to manage their AI workloads on Kubernetes. See here</li> <li>Infrastructure/Platform Administrators: who want to deploy and manage Kaiwo on their Kubernetes clusters. See here</li> </ul>"},{"location":"#main-features","title":"Main Features","text":"GPU Utilization Optimization Kaiwo Operator dynamically queues workloads to reduce GPU idle time and maximize resource utilization. CLI Tool Simplified workload submission using the kaiwo CLI tool Distributed Workload Scheduling Effortlessly schedule distributed workloads across multiple Kubernetes nodes with Kaiwo Operator. Broad Workload Support with pre-built templates Supports running Kubernetes Jobs, Deployments, RayJobs and RayServices. Integration with Ray and Kueue Leverages the power of Ray for distributed computing and Kueue for efficient job queueing."},{"location":"admin/auth/","title":"Authentication &amp; Authorization","text":"<p>Kaiwo integrates with Kubernetes authentication and authorization mechanisms.</p>"},{"location":"admin/auth/#cluster-queue-namespaces","title":"Cluster queue namespaces","text":"<p>Since the <code>KaiwoQueueConfig</code> lists the namespaces for the cluster queues, you must make sure that users that use these queues have the correct RBAC rights for these namespaces.</p>"},{"location":"admin/auth/#user-authentication-cli","title":"User Authentication (CLI)","text":"<p>If you wish to set up authentication on the Kube API server, please follow the official documentation. For setting up the <code>kaiwo</code> CLI to use this authentication, please see the CLI documentation.</p>"},{"location":"admin/auth/#authorization-rbac","title":"Authorization (RBAC)","text":"<p>Access control within Kubernetes, including permissions to create, view, and manage Kaiwo resources (<code>KaiwoJob</code>, <code>KaiwoService</code>, etc.) and underlying resources (Pods, Jobs, Deployments, PVCs), is managed through Kubernetes Role-Based Access Control (RBAC).</p> <ul> <li>Kaiwo Operator Permissions: The <code>install.yaml</code> manifest includes <code>ClusterRole</code> and <code>ClusterRoleBinding</code> (or <code>Role</code>/<code>RoleBinding</code>) definitions granting the Kaiwo operator's Service Account the necessary permissions to manage resources across the cluster or within specific namespaces. These permissions include creating/updating/deleting Jobs, Deployments, Ray resources, Kueue resources, PVCs, ConfigMaps, etc. Review the RBAC rules in <code>config/rbac/</code> in the source repository for specifics.</li> <li>User Permissions: As an administrator, you need to grant users appropriate RBAC permissions to interact with Kaiwo resources. Users typically need:<ul> <li><code>get</code>, <code>list</code>, <code>watch</code>, <code>create</code>, <code>update</code>, <code>patch</code>, <code>delete</code> permissions on <code>kaiwojobs.kaiwo.silogen.ai</code> and <code>kaiwoservices.kaiwo.silogen.ai</code> within their target namespaces.</li> <li><code>get</code>, <code>list</code>, <code>watch</code> permissions on Pods, Services, Events within their namespaces to allow <code>kaiwo manage</code>, <code>logs</code>, <code>monitor</code>, <code>exec</code>.</li> <li>Permissions to create <code>PersistentVolumeClaims</code> if they use the <code>storage</code> feature.</li> <li>Permissions to access <code>Secrets</code> referenced in their manifests (e.g., for image pulls, data download credentials).</li> </ul> </li> </ul> <p>Example User Role:</p> <pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  namespace: ai-project-ns # Target namespace for the user\n  name: kaiwo-scientist-role\nrules:\n- apiGroups: [\"kaiwo.silogen.ai\"]\n  resources: [\"kaiwojobs\", \"kaiwoservices\"]\n  verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n- apiGroups: [\"\"] # Core API group\n  resources: [\"pods\", \"pods/log\", \"services\", \"events\", \"persistentvolumeclaims\", \"configmaps\", \"secrets\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n- apiGroups: [\"\"]\n  resources: [\"pods/exec\"] # For kaiwo exec/monitor\n  verbs: [\"create\"]\n- apiGroups: [\"batch\"]\n  resources: [\"jobs\"] # To view underlying batch jobs\n  verbs: [\"get\", \"list\", \"watch\"]\n- apiGroups: [\"apps\"]\n  resources: [\"deployments\"] # To view underlying deployments\n  verbs: [\"get\", \"list\", \"watch\"]\n- apiGroups: [\"ray.io\"] # If using Ray\n  resources: [\"rayjobs\", \"rayservices\", \"rayclusters\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n# Add other permissions as needed (e.g., create PVCs)\n</code></pre> <p>Bind this role to specific users or groups using a <code>RoleBinding</code>.</p>"},{"location":"admin/configuration/","title":"Configuration Guide","text":"<p>Administrators configure Kaiwo primarily through</p> <ul> <li>The cluster-scoped <code>KaiwoQueueConfig</code> Custom Resource Definition (CRD)</li> <li>The cluster-scoped <code>KaiwoConfig</code> CRD</li> <li>Environment variables or flags passed to the Kaiwo operator</li> </ul> <p>Users configure the CLI tool separately.</p>"},{"location":"admin/configuration/#kaiwoqueueconfig-crd","title":"KaiwoQueueConfig CRD","text":"<p>This is the central point for managing how Kaiwo interacts with Kueue. There can be only one <code>KaiwoQueueConfig</code> resource in the cluster, and its <code>metadata.name</code> must be <code>kaiwo</code> (or the value specified in the KaiwoConfig Custom Resource field <code>spec.defaultKaiwoQueueConfigName</code>, which defaults to <code>kaiwo</code>, see more below).</p> <p>Default Configuration on Startup:</p> <p>The Kaiwo operator includes a startup routine that checks if a <code>KaiwoQueueConfig</code> named <code>kaiwo</code> exists. If it does not, the operator automatically creates a default one. This default configuration aims to provide a functional baseline:</p> <ul> <li>It attempts to auto-discover node pools based on common GPU labels (e.g., <code>amd.com/gpu.product-name</code>, <code>nvidia.com/gpu.product</code>, <code>nvidia.com/gpu.count</code>) and CPU/Memory capacity.</li> <li>It creates corresponding Kueue <code>ResourceFlavor</code> resources based on this discovery, labeling the nodes with <code>kaiwo/nodepool=&lt;generated-flavor-name&gt;</code>.</li> <li>It defines a single Kueue <code>ClusterQueue</code> named <code>kaiwo</code> (or the value of <code>DEFAULT_CLUSTER_QUEUE_NAME</code>), configured to use all discovered <code>ResourceFlavors</code> and their estimated capacities as <code>nominalQuota</code>.</li> <li>It specifies that this default <code>ClusterQueue</code> should have a corresponding <code>LocalQueue</code> automatically created in the <code>kaiwo</code> namespace.</li> <li>It does not define any <code>WorkloadPriorityClass</code> resources by default.</li> </ul> <p>You can modify this automatically created configuration or create your own <code>kaiwo</code> resource manually using: <code>kubectl edit kaiwoqueueconfig kaiwo</code> or by applying a YAML manifest.</p> <p>Key Fields (<code>spec</code>):</p> <ul> <li> <p><code>resourceFlavors</code>: Defines the types of hardware resources available in the cluster, corresponding to Kueue <code>ResourceFlavor</code> resources.</p> <ul> <li><code>name</code>: A unique name for the flavor (e.g., <code>amd-mi300-8gpu</code>, <code>nvidia-a100-40gb</code>, <code>cpu-standard</code>).</li> <li><code>nodeLabels</code>: A map of labels that nodes must possess to be considered part of this flavor. This is crucial for scheduling pods onto the correct hardware. Example: <code>{\"kaiwo/nodepool\": \"amd-mi300-nodes\"}</code>.</li> <li><code>taints</code>: (Optional) A list of Kubernetes taints associated with this flavor. Pods scheduled to this flavor will need corresponding tolerations. Kaiwo automatically adds tolerations for GPU taints if <code>ADD_TAINTS_TO_GPU_NODES</code> is enabled.</li> </ul> <p>Auto-Discovery vs. Explicit Definition</p> <p>If <code>spec.resourceFlavors</code> is empty or omitted in the <code>kaiwo</code> <code>KaiwoQueueConfig</code>, the operator's startup logic attempts to auto-discover node pools and create corresponding flavors as described above. While convenient for initial setup, explicitly defining <code>resourceFlavors</code> in the <code>KaiwoQueueConfig</code> provides more precise control and is generally recommended for production environments. Explicitly defined flavors will override any auto-discovered ones during reconciliation.</p> </li> <li> <p><code>clusterQueues</code>: Defines the Kueue <code>ClusterQueue</code> resources managed by Kaiwo.</p> <ul> <li><code>name</code>: The name of the <code>ClusterQueue</code> (e.g., <code>team-a-queue</code>, <code>default-gpu-queue</code>).</li> <li><code>spec</code>: The full Kueue <code>ClusterQueueSpec</code>. This is where you define resource quotas, cohorts, preemption policies, etc. See Kueue ClusterQueue Documentation.<ul> <li><code>resourceGroups</code>: Define sets of flavors and their associated quotas (<code>nominalQuota</code>). This links the queue to the available hardware defined in <code>resourceFlavors</code>.</li> <li><code>namespaceSelector</code>: Controls which namespaces can use this queue via <code>LocalQueue</code> resources if those LocalQueues exist. Note that Kaiwo's automatic <code>LocalQueue</code> creation relies on the <code>namespaces</code> field below, not this selector.</li> </ul> </li> <li><code>namespaces</code>: A list of namespace names where Kaiwo should automatically create and manage a Kueue <code>LocalQueue</code> pointing to this <code>ClusterQueue</code>. The <code>LocalQueue</code> created will have the same name as the <code>ClusterQueue</code>.</li> </ul> </li> <li> <p><code>workloadPriorityClasses</code>: Defines Kueue <code>WorkloadPriorityClass</code> resources.</p> <ul> <li>Follows the standard Kueue <code>WorkloadPriorityClass</code> structure (<code>name</code>, <code>value</code>, <code>description</code>). Kaiwo ensures these exist as defined. See Kueue Priority Documentation.</li> </ul> </li> </ul> <p>Example <code>KaiwoQueueConfig</code>:</p> <pre><code>apiVersion: kaiwo.silogen.ai/v1alpha1\nkind: KaiwoQueueConfig\nmetadata:\n  name: kaiwo # Must be named 'kaiwo' (or DEFAULT_KAIWO_QUEUE_CONFIG_NAME)\nspec:\n  resourceFlavors:\n    - name: amd-mi300-8gpu\n      nodeLabels:\n        kaiwo/nodepool: amd-mi300-nodes # Nodes with this label belong to this flavor\n        # Add other identifying labels if needed, e.g., topology.amd.com/gpu-count: '8'\n      # taints: # Optional, define if specific taints apply ONLY to these nodes\n      # - key: \"amd.com/gpu\"\n      #   operator: \"Exists\"\n      #   effect: \"NoSchedule\"\n    - name: cpu-high-mem\n      nodeLabels:\n        kaiwo/nodepool: cpu-high-mem-nodes\n\n  clusterQueues:\n    - name: ai-research-queue # Name of the ClusterQueue\n      namespaces: # Auto-create/manage LocalQueues in these namespaces\n        - ai-research-ns-1\n        - ai-research-ns-2\n      spec: # Standard Kueue ClusterQueueSpec\n        queueingStrategy: BestEffortFIFO\n        resourceGroups:\n          - coveredResources: [\"cpu\", \"memory\", \"amd.com/gpu\"] # Resources managed by this group\n            flavors:\n              - name: amd-mi300-8gpu # Reference to a defined resourceFlavor\n                resources:\n                  - name: \"cpu\"\n                    nominalQuota: \"192\" # Total CPU quota for this flavor in this queue\n                  - name: \"memory\"\n                    nominalQuota: \"1024Gi\" # Total Memory quota\n                  - name: \"amd.com/gpu\"\n                    nominalQuota: \"8\" # Total GPU quota\n          - coveredResources: [\"cpu\", \"memory\"]\n            flavors:\n              - name: cpu-high-mem\n                resources:\n                  - name: \"cpu\"\n                    nominalQuota: \"256\"\n                  - name: \"memory\"\n                    nominalQuota: \"2048Gi\"\n        # cohort: \"gpu-cohort\" # Optional: Group queues for borrowing/preemption\n        # preemption: ...\n\n  workloadPriorityClasses:\n    - name: high-priority\n      value: 1000\n    - name: low-priority\n      value: 100\n</code></pre>"},{"location":"admin/configuration/#controller-operation-and-kueue-resource-synchronization","title":"Controller Operation and Kueue Resource Synchronization","text":"<p>The <code>KaiwoQueueConfigController</code> acts as a translator, continuously ensuring that the Kueue resources in your cluster accurately reflect the configuration defined in the single <code>kaiwo</code> <code>KaiwoQueueConfig</code> resource. It monitors this resource and automatically manages the lifecycle of the associated Kueue objects:</p> <ul> <li> <p><code>spec.resourceFlavors</code> -&gt; Kueue <code>ResourceFlavor</code>:</p> <ul> <li>Each entry in this list directly defines a Kueue <code>ResourceFlavor</code>.</li> <li>The controller ensures a corresponding <code>ResourceFlavor</code> exists for each entry, creating or updating it as necessary based on the specified <code>name</code>, <code>nodeLabels</code>, and <code>taints</code>.</li> <li>If an entry is removed from this list, the controller deletes the corresponding <code>ResourceFlavor</code>.</li> </ul> </li> <li> <p><code>spec.clusterQueues</code> -&gt; Kueue <code>ClusterQueue</code> and <code>LocalQueue</code>:</p> <ul> <li>Each entry in this list defines a Kueue <code>ClusterQueue</code>. The controller translates the structure into a standard <code>ClusterQueueSpec</code> and ensures the resource exists and matches the definition. Removing an entry deletes the corresponding <code>ClusterQueue</code>.</li> <li>The <code>namespaces</code> field within each <code>clusterQueues</code> entry dictates where Kueue <code>LocalQueue</code>s should exist. The controller automatically creates a <code>LocalQueue</code> (named after the <code>ClusterQueue</code>) in each listed namespace, pointing to the corresponding <code>ClusterQueue</code>. If a namespace is removed from the list, or the parent <code>ClusterQueue</code> entry is removed, the controller deletes the associated <code>LocalQueue</code> in that namespace.</li> </ul> </li> <li> <p><code>spec.workloadPriorityClasses</code> -&gt; Kueue <code>WorkloadPriorityClass</code>:</p> <ul> <li>Each entry defines a Kueue <code>WorkloadPriorityClass</code>.</li> <li>The controller manages these resources, ensuring they exist with the specified <code>name</code>, <code>value</code>, and <code>description</code>.</li> <li>Removing an entry results in the deletion of the corresponding <code>WorkloadPriorityClass</code>.</li> </ul> </li> </ul> <p>Owner References</p> <p>The controller establishes the <code>kaiwo</code> <code>KaiwoQueueConfig</code> as the owner of all the Kueue resources it creates. This linkage ensures that if the <code>KaiwoQueueConfig</code> is deleted, Kubernetes automatically cleans up all the managed Kueue resources (<code>ResourceFlavor</code>, <code>ClusterQueue</code>, <code>LocalQueue</code>, <code>WorkloadPriorityClass</code>).</p> <p>Kueue resource management</p> <p>Kaiwo takes ownership of Kueue <code>ResourceFlavor</code>, <code>ClusterQueue</code>, <code>LocalQueue</code> and <code>WorkloadPriorityClass</code> resources. This means that resources of these types that are created manually, i.e. not via the <code>KaiwoQueueConfig</code>, may be deleted by the Kaiwo Controller</p> <p>The controller updates the <code>status.status</code> field of the <code>KaiwoQueueConfig</code> resource (<code>Pending</code>, <code>Ready</code>, or <code>Failed</code>) to indicate the current state of synchronization between the desired configuration and the actual Kueue resources in the cluster. This continuous reconciliation keeps the Kueue setup aligned with the central <code>KaiwoQueueConfig</code>.</p>"},{"location":"admin/configuration/#kaiwoconfig-crd","title":"KaiwoConfig CRD","text":"<p>The Kaiwo Operator's runtime configuration is managed through the <code>KaiwoConfig</code> Custom Resource Definition (CRD). This approach allows Kubernetes administrators to dynamically adjust operator behavior without requiring a restart. The operator always retrieves the most recent configuration values during each reconcile loop.</p>"},{"location":"admin/configuration/#configuration-structure","title":"Configuration Structure","text":"<p>The primary configuration resource is the <code>KaiwoConfig</code> CRD, typically maintained as a singleton within the Kubernetes cluster. Its key components are encapsulated in the <code>KaiwoConfigSpec</code>, which briefly includes:</p> <ul> <li><code>kueue</code>: Configures default integration settings with Kueue, including the default cluster queue name.</li> <li><code>ray</code>: Specifies Ray-specific parameters, including default container images and memory allocations.</li> <li><code>storage</code>: Manages default filesystem paths for mounting data storage and HuggingFace caches.</li> <li><code>nodes</code>: Defines node-specific settings such as GPU resource keys, GPU node taints, and node pool exclusions.</li> <li><code>scheduling</code>: Sets scheduling-related configurations, like the Kubernetes scheduler name.</li> <li><code>resourceMonitoring</code>: Configures resource monitoring, including averaging intervals, utilization thresholds, and targeted namespaces.</li> <li><code>defaultKaiwoQueueConfigName</code>: Specifies the default name for the Kaiwo queue configuration object.</li> </ul>"},{"location":"admin/configuration/#specifying-the-configuration-cr","title":"Specifying the Configuration CR","text":"<p>The Kaiwo Operator identifies its configuration resource via the environment variable <code>CONFIG_NAME</code>. By default, this is set to <code>kaiwo</code>. Ensure that a <code>KaiwoConfig</code> resource with this exact name exists in your cluster. The operator automatically creates a default configuration at startup if none exists.</p> <p>Note</p> <p>The operator waits up to 30 seconds for the specified configuration resource to be found. If no resource is detected within this period, the operator pod will fail with an error.</p>"},{"location":"admin/configuration/#example-kaiwoconfig-cr","title":"Example KaiwoConfig CR","text":"<p>Here's a minimal example of a valid <code>KaiwoConfig</code> definition:</p> <pre><code>apiVersion: config.kaiwo.silogen.ai/v1alpha1\nkind: KaiwoConfig\nmetadata:\n  name: kaiwo\nspec:\n  scheduling:\n    kubeSchedulerName: \"kaiwo-scheduler\"\n  resourceMonitoring:\n    averagingTime: \"20m\"\n    lowUtilizationThreshold: 20\n    profile: \"gpu\"\n</code></pre> <p>For detailed descriptions of individual configuration fields, please see the full API reference.</p>"},{"location":"admin/configuration/#operator-environmental-variables","title":"Operator Environmental Variables","text":"<p>Some configuration is not changeable during runtime, or they may be often referenced from other config maps or secrets, and thus they are stored as environmental variables. These settings are not dynamic, and the operator must be restarted in order for changes to these values to take effect.</p>"},{"location":"admin/configuration/#kueue","title":"Kueue","text":"<ul> <li><code>DEFAULT_KAIWO_QUEUE_CONFIG_NAME</code>: The name of the singleton <code>KaiwoQueueConfig</code> custom resource to be used (defaults to <code>kaiwo</code>)</li> <li><code>DEFAULT_CLUSTER_QUEUE_NAME</code>: The name of the default Kueue cluster queue (defaults to <code>kaiwo</code>)</li> </ul>"},{"location":"admin/configuration/#resource-monitoring","title":"Resource Monitoring","text":"<p>To enable and configure resource monitoring within the Kaiwo Operator, the following environment variables must be set on the operator deployment:</p> <ul> <li><code>RESOURCE_MONITORING_ENABLED=true</code> \u2013 Enables the resource monitoring component.</li> <li><code>RESOURCE_MONITORING_PROMETHEUS_ENDPOINT=&lt;prometheus-endpoint&gt;</code> \u2013 Specifies the Prometheus endpoint to query metrics from.</li> <li><code>RESOURCE_MONITORING_POLLING_INTERVAL=10m</code> \u2013 Sets the interval between metric polling queries.</li> </ul>"},{"location":"admin/configuration/#other-configuration-options","title":"Other configuration options","text":"<ul> <li><code>WEBHOOK_CERT_DIRECTORY</code>: Path to manually provided webhook certificates (overrides automatic management if set). See Installation.</li> </ul> <p>Forthcoming feature</p> <p><code>ENFORCE_KAIWO_ON_GPU_WORKLOADS</code> (Default: <code>false</code>): If <code>true</code>, the mutating admission webhook for <code>batchv1.Job</code> will automatically add the <code>kaiwo.silogen.ai/managed: \"true\"</code> label to any job requesting GPU resources, forcing it to be managed by Kaiwo/Kueue.</p> <p>All environmental variables are typically set in the operator's <code>Deployment</code> manifest.</p> <p>Command-Line Flags:</p> <p>Refer to the output of <code>kaiwo-operator --help</code> (or check <code>cmd/operator/main.go</code>) for flags controlling metrics, health probes, leader election, and certificate paths.</p>"},{"location":"admin/installation/","title":"Installation Guide","text":"<p>This guide provides clear, step\u2011by\u2011step instructions to install the Kaiwo operator and its dependencies on a Kubernetes cluster.</p>"},{"location":"admin/installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>A running Kubernetes cluster (v1.22+ recommended)</li> <li><code>kubectl</code> configured with cluster-admin privileges</li> <li><code>helm</code> (for Helm-based install)</li> <li><code>git</code> (if using the helper scripts)</li> </ul> <p>Optional (for GPU workloads): GPU-capable nodes and the appropriate GPU operator (AMD or NVIDIA).</p>"},{"location":"admin/installation/#dependency-overview","title":"Dependency Overview","text":"<p>Kaiwo requires several core Kubernetes components to function correctly:</p> <ol> <li>Cert-Manager: Manages TLS certificates for webhooks.</li> <li>GPU Operator:<ul> <li>AMD: AMD GPU Operator. (Includes Node Labeler).</li> <li>NVIDIA: NVIDIA GPU Operator + GPU Feature Discovery.</li> <li>Ensures GPU drivers are installed and nodes are correctly labeled with GPU information.</li> </ul> </li> <li>Kueue: Provides job queueing, fair sharing, and quota management. (Docs).</li> <li>KubeRay Operator: Required only if users will run Ray-based workloads (<code>spec.ray: true</code>). Manages Ray clusters. (Docs).</li> <li>AppWrapper: Used by Kueue to manage atomic scheduling of complex workloads, particularly Ray clusters/services. (GitHub).</li> <li>Prometheus (Recommended): For monitoring the Kaiwo operator and cluster metrics.</li> </ol>"},{"location":"admin/installation/#aim-inference-dependencies","title":"AIM Inference Dependencies","text":"<p>The following components are required for deploying AIM inference services:</p> <ol> <li>KServe: Serves as the inference runtime for AIM services. Provides model serving infrastructure with support for autoscaling and canary deployments. (Docs).</li> <li>Gateway API / KGateway: Handles HTTP routing for inference endpoints. KGateway provides a Gateway API implementation. (Gateway API Docs).</li> </ol>"},{"location":"admin/installation/#autoscaling-dependencies-optional","title":"Autoscaling Dependencies (Optional)","text":"<p>The following components are required only if you want to use autoscaling for AIM inference services:</p> <ol> <li>KEDA: Kubernetes Event-driven Autoscaling. Enables scaling based on custom metrics from various sources. (Docs).</li> <li>Kedify OpenTelemetry Add-on: Provides the OpenTelemetry scaler for KEDA, enabling autoscaling based on metrics from vLLM and other inference runtimes. (GitHub).</li> <li>OpenTelemetry Operator: Manages OpenTelemetry Collectors that scrape metrics from inference pods and forward them to KEDA. (Docs).</li> </ol>"},{"location":"admin/installation/#installation-methods","title":"Installation Methods","text":"<p>There are two main phases: install dependencies (Step 1) and install Kaiwo (Step 2). Choose the option(s) that fit your environment.</p>"},{"location":"admin/installation/#step-1-install-dependencies","title":"Step 1: Install Dependencies","text":"<p>You can either install dependencies yourself or use the helper script (handy for dev/test).</p> <p>Note</p> <p>The helper script requires Helmfile and yq.</p> <p>Clone the repository and install dependencies using the script:</p> <pre><code>git clone https://github.com/silogen/kaiwo.git\ncd kaiwo\ndependencies/deploy.sh kind-test up  # Use appropriate environment\n</code></pre> <p>Available environments: - <code>kind-test</code>: For Kind/testing clusters - <code>tw-009-038</code>: GPU environment example - <code>banff-sc-cx42-43</code>: GPU environment example</p> <p>Info</p> <p>The GPU environments above are examples with hard-coded values for specific environments. To use the helper script with your own GPU cluster:</p> <ol> <li>Create a new environment file: <code>dependencies/environments/&lt;my-env&gt;.yaml</code></li> <li>Create a new overlay: <code>dependencies/kustomization-server-side/overlays/environments/&lt;my-env&gt;/kustomization.yaml</code></li> </ol> <p>Then install: <code>dependencies/deploy.sh &lt;my-env&gt; up</code></p>"},{"location":"admin/installation/#step-2-install-the-kaiwo-operator","title":"Step 2: Install the Kaiwo Operator","text":"<p>You can install Kaiwo via Helm (recommended) or by applying a prebuilt manifest with Kustomize.</p>"},{"location":"admin/installation/#option-a-helm","title":"Option A \u2014 Helm","text":"<p>Install from the OCI registry:</p> <pre><code># Install latest version to kaiwo-system namespace\nhelm install kaiwo oci://ghcr.io/silogen/charts/kaiwo-operator \\\n  --namespace kaiwo-system --create-namespace\n\n# Install a specific version\nhelm install kaiwo oci://ghcr.io/silogen/charts/kaiwo-operator \\\n  --version &lt;version&gt; \\\n  --namespace kaiwo-system --create-namespace\n</code></pre>"},{"location":"admin/installation/#option-b-kustomize-manifests","title":"Option B \u2014 Kustomize Manifests","text":"<p>Install the latest version:</p> <pre><code>kubectl apply -f https://github.com/silogen/kaiwo/releases/latest/download/install.yaml --server-side\n</code></pre> <p>Or install a specific version:</p> <pre><code>export KAIWO_VERSION=vX.Y.Z\nkubectl apply -f https://github.com/silogen/kaiwo/releases/download/${KAIWO_VERSION}/install.yaml --server-side\n</code></pre> <p>Install from a local build (useful for development):</p> <pre><code>make build-installer # produces dist/install.yaml\nkubectl apply -f dist/install.yaml --server-side\n</code></pre> <p>This installs:</p> <ul> <li>Kaiwo CRDs (cluster-scoped)</li> <li><code>kaiwojobs.kaiwo.silogen.ai</code></li> <li><code>kaiwoservices.kaiwo.silogen.ai</code></li> <li><code>kaiwoqueueconfigs.kaiwo.silogen.ai</code></li> <li><code>kaiwoconfigs.config.kaiwo.silogen.ai</code></li> <li><code>resourceflavors.kaiwo.silogen.ai</code></li> <li><code>topologies.kaiwo.silogen.ai</code></li> <li>The Kaiwo controller <code>Deployment</code> in the <code>kaiwo-system</code> namespace</li> <li>RBAC rules (<code>ClusterRole</code>, <code>Role</code>, <code>ClusterRoleBinding</code>, <code>RoleBinding</code>)</li> <li>Webhook configurations and services</li> </ul>"},{"location":"admin/installation/#verification","title":"Verification","text":"<p>After installation, verify that all components are running correctly:</p>"},{"location":"admin/installation/#1-check-dependencies","title":"1. Check Dependencies","text":"<p>Verify that all dependency components are running (only the ones you installed/apply):</p> <pre><code># Check Cert-Manager\nkubectl get pods -n cert-manager\n\n# Check Kueue\nkubectl get pods -n kueue-system\n\n# Check KubeRay (if Ray workloads are used)\nkubectl get pods -A | grep kuberay-operator || true\n\n# Check AppWrapper\nkubectl get pods -n appwrapper-system\n</code></pre> <p>For AIM inference services, also verify:</p> <pre><code># Check KServe\nkubectl get pods -n kserve-system\n\n# Check Gateway (KGateway)\nkubectl get pods -n kgateway-system\n</code></pre> <p>For autoscaling support, verify:</p> <pre><code># Check KEDA\nkubectl get pods -n keda\n\n# Check Kedify OpenTelemetry Add-on (runs as keda-otel-scaler)\nkubectl get pods -n keda -l app.kubernetes.io/name=otel-add-on\n\n# Check OpenTelemetry Operator\nkubectl get pods -n opentelemetry-operator-system\n</code></pre>"},{"location":"admin/installation/#2-check-kaiwo-operator","title":"2. Check Kaiwo Operator","text":"<p>Ensure the Kaiwo controller manager pod is running:</p> <pre><code>kubectl get pods -n kaiwo-system\n# Expected output:\n# NAME                                        READY   STATUS    RESTARTS   AGE\n# kaiwo-controller-manager-xxxxxxxxxx-xxxxx   2/2     Running   0          2m\n</code></pre>"},{"location":"admin/installation/#3-verify-crds","title":"3. Verify CRDs","text":"<p>Check that the Kaiwo Custom Resource Definitions are installed:</p> <pre><code>kubectl get crds | grep -E 'kaiwo\\.silogen\\.ai|config\\.kaiwo\\.silogen\\.ai'\n# Expected output (at minimum):\n# kaiwojobs.kaiwo.silogen.ai\n# kaiwoservices.kaiwo.silogen.ai\n# kaiwoqueueconfigs.kaiwo.silogen.ai\n# kaiwoconfigs.config.kaiwo.silogen.ai\n# resourceflavors.kaiwo.silogen.ai\n# topologies.kaiwo.silogen.ai\n</code></pre>"},{"location":"admin/installation/#4-check-default-configuration","title":"4. Check Default Configuration","text":"<p>The operator should automatically create a default <code>KaiwoQueueConfig</code>:</p> <pre><code>kubectl get kaiwoqueueconfig kaiwo\n# Expected output:\n# NAME    AGE\n# kaiwo   3m\n</code></pre> <p>If this is missing, check the operator logs:</p> <pre><code>kubectl logs -n kaiwo-system -l app.kubernetes.io/name=kaiwo\n</code></pre> <p>If pods are pending or webhooks fail, see Troubleshooting.</p>"},{"location":"admin/installation/#uninstallation","title":"Uninstallation","text":""},{"location":"admin/installation/#remove-kaiwo-operator","title":"Remove Kaiwo Operator","text":"<p>For Helm installations:</p> <pre><code>helm uninstall kaiwo -n kaiwo-system\n</code></pre> <p>CRD Removal</p> <p>Helm uninstall keeps CRDs by default. Deleting CRDs will remove all Kaiwo resources. Only delete CRDs if you intend to wipe all Kaiwo state.</p> <p>For Kustomize installations:</p> <pre><code>kubectl delete -f https://github.com/silogen/kaiwo/releases/latest/download/install.yaml\n</code></pre> <p>CRD Removal</p> <p>Kustomize will delete CRDs, which removes all Kaiwo resources. Only delete CRDs if you intend to wipe all Kaiwo state.</p>"},{"location":"admin/installation/#remove-dependencies","title":"Remove Dependencies","text":"<p>To remove dependencies:</p> <pre><code>cd kaiwo  # Your cloned repository\ndependencies/deploy.sh kind-test down  # Use same environment as installation\n</code></pre>"},{"location":"admin/installation/#provide-cli-to-users","title":"Provide CLI to Users","text":"<p>Instruct your users (AI Scientists/Engineers) on how to download and install the <code>kaiwo</code> CLI tool. Point them to the User Quickstart guide or the CLI Installation instructions.</p>"},{"location":"admin/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Configure Kaiwo: Customize <code>KaiwoQueueConfig</code> and (optionally) <code>KaiwoConfig</code> to reflect your cluster\u2019s hardware and policies. See the Configuration Guide.</li> <li>Set up Monitoring: Integrate Kaiwo operator metrics with your monitoring system (e.g., Prometheus). See the Monitoring Guide.</li> <li>Authentication: Ensure users have the necessary <code>kubeconfig</code> files and any required authentication plugins installed. See Authentication &amp; Authorization.</li> <li>Troubleshooting: If something isn\u2019t working, review common issues and fixes in Troubleshooting.</li> </ul>"},{"location":"admin/maintenance/","title":"Maintenance Guide","text":"<p>This section outlines common maintenance tasks for the Kaiwo system.</p>"},{"location":"admin/maintenance/#upgrading-kaiwo","title":"Upgrading Kaiwo","text":"<ol> <li>Check Release Notes: Before upgrading, review the release notes for the target version on the GitHub Releases page. Pay attention to any breaking changes, dependency updates, or manual migration steps required.</li> <li>Backup (Optional but Recommended): Consider backing up relevant configurations, especially your <code>KaiwoQueueConfig</code> CRD (<code>kubectl get kaiwoqueueconfig kaiwo -o yaml &gt; kaiwoqueueconfig_backup.yaml</code>).</li> <li> <p>Apply New Manifest: Apply the <code>install.yaml</code> manifest for the new version using <code>kubectl apply --server-side</code>.</p> <p><pre><code>export KAIWO_NEW_VERSION=vX.Y.Z # Set to the target version\nkubectl apply -f https://github.com/silogen/kaiwo/releases/download/${KAIWO_NEW_VERSION}/install.yaml --server-side\n</code></pre> 4.  Verify Upgrade:</p> <ul> <li>Check that the Kaiwo operator pod restarts and uses the new image version:     <pre><code>kubectl get pods -n kaiwo-system -l control-plane=kaiwo-controller-manager\nkubectl describe pod -n kaiwo-system -l control-plane=kaiwo-controller-manager | grep Image:\n</code></pre></li> <li>Monitor operator logs for any errors during startup:     <pre><code>kubectl logs -n kaiwo-system -l control-plane=kaiwo-controller-manager -f\n</code></pre></li> <li>Ensure Kaiwo CRDs remain functional and workloads continue to be processed.</li> <li>Upgrade Dependencies: If the Kaiwo release notes indicate required upgrades for dependencies (Kueue, Ray, Cert-Manager, etc.), perform those upgrades according to their respective documentation.</li> </ul> </li> </ol>"},{"location":"admin/maintenance/#certificate-rotation","title":"Certificate Rotation","text":"<ul> <li>Cert-Manager (Default): If using the default setup with Cert-Manager, certificate rotation for webhooks is typically handled automatically based on the <code>Certificate</code> resources created during installation. Monitor Cert-Manager logs and certificate expiry (<code>kubectl get certificates -n kaiwo-system</code>) if issues arise.</li> </ul>"},{"location":"admin/maintenance/#operator-pod-management","title":"Operator Pod Management","text":"<ul> <li>Restarting: If the operator becomes unresponsive, you can restart it by deleting the pod:     <pre><code>kubectl delete pod -n kaiwo-system -l control-plane=kaiwo-controller-manager\n</code></pre>     The Deployment will automatically create a new pod.</li> <li>Scaling: The Kaiwo operator deployment typically runs with a single replica due to leader election (<code>--leader-elect=true</code>). Scaling is generally not required unless leader election is disabled (not recommended for production).</li> </ul>"},{"location":"admin/maintenance/#cleaning-up-resources","title":"Cleaning Up Resources","text":"<ul> <li>Workloads: Users can delete their workloads using <code>kaiwo manage</code> or <code>kubectl delete kaiwojob &lt;name&gt;</code> / <code>kubectl delete kaiwoservice &lt;name&gt;</code>. The Kaiwo operator's finalizers ensure associated resources (like underlying Jobs/Deployments, PVCs created by Kaiwo download jobs) are cleaned up.</li> <li>Kueue Resources: Resources managed by <code>KaiwoQueueConfig</code> (Flavors, ClusterQueues, PriorityClasses) are typically deleted if removed from the <code>kaiwo</code> <code>KaiwoQueueConfig</code> spec.</li> <li>Uninstalling Kaiwo: To completely remove Kaiwo, delete the installation manifest and clean up CRDs and namespaces:     <pre><code># Replace vX.Y.Z with the installed version\nexport KAIWO_VERSION=vX.Y.Z\nkubectl delete -f https://github.com/silogen/kaiwo/releases/download/${KAIWO_VERSION}/install.yaml\n\n# Delete CRDs (use with caution - this will delete ALL KaiwoJob/Service/QueueConfig resources)\nkubectl delete crd kaiwojobs.kaiwo.silogen.ai\nkubectl delete crd kaiwoservices.kaiwo.silogen.ai\nkubectl delete crd kaiwoqueueconfigs.kaiwo.silogen.ai\n# ... delete other Kaiwo CRDs if any\n\n# Delete namespace\nkubectl delete namespace kaiwo-system\n</code></pre>     Remember to also uninstall dependencies if they are no longer needed.</li> </ul>"},{"location":"admin/monitoring/","title":"Monitoring Kaiwo","text":"<p>Monitoring the Kaiwo operator and the workloads it manages is crucial for ensuring system health and performance.</p>"},{"location":"admin/monitoring/#operator-metrics","title":"Operator Metrics","text":"<p>The Kaiwo operator exposes metrics in Prometheus format.</p> <ul> <li>Endpoint: By default, metrics are exposed on port <code>8080</code> (HTTP) or <code>8443</code> (HTTPS, if <code>--metrics-secure=true</code>, which is the default). The bind address can be configured via the <code>--metrics-bind-address</code> flag (defaults to <code>0</code> which disables the endpoint unless overridden). The <code>install.yaml</code> manifest typically configures this.</li> <li>Security: When <code>--metrics-secure=true</code>, the endpoint uses TLS. Certificates can be auto-generated by controller-runtime, managed by Cert-Manager, or provided manually via flags (<code>--metrics-cert-path</code>, etc.). Authentication and authorization can be enabled via <code>controller-runtime</code>'s filters (<code>metricsServerOptions.FilterProvider = filters.WithAuthenticationAndAuthorization</code>). RBAC for accessing the metrics endpoint needs to be configured separately (see <code>config/rbac/kustomization.yaml</code> in the source repository for examples).</li> <li>Key Metrics: The operator exposes standard controller-runtime metrics (e.g., reconcile times, errors, queue lengths) and potentially custom metrics related to Kaiwo operations.</li> </ul> <p>Integration with Prometheus:</p> <ol> <li>Ensure a Prometheus instance (e.g., Prometheus Operator, managed Prometheus service) is running in your cluster.</li> <li>Configure Prometheus to scrape the Kaiwo operator's metrics endpoint. This typically involves creating a <code>ServiceMonitor</code> or <code>PodMonitor</code> resource targeting the <code>kaiwo-controller-manager</code> service/pods in the <code>kaiwo-system</code> namespace.</li> <li>If using TLS (<code>--metrics-secure=true</code>), configure Prometheus scraping job with the appropriate TLS configuration (e.g., <code>insecure_skip_verify: true</code> for self-signed certs, or proper CA/client certs).</li> </ol> <p>Consult the <code>controller-runtime</code> documentation and your Prometheus setup guide for detailed scraping configuration.</p>"},{"location":"admin/monitoring/#operator-logs","title":"Operator Logs","text":"<p>Monitor the logs of the Kaiwo operator pod for errors or important events:</p> <pre><code>kubectl logs -n kaiwo-system -l control-plane=kaiwo-controller-manager -f\n</code></pre> <p>Consider shipping these logs to a central logging system (e.g., Loki, Elasticsearch, Splunk) for easier analysis and alerting.</p>"},{"location":"admin/monitoring/#kueue-monitoring","title":"Kueue Monitoring","text":"<p>Kueue also exposes its own metrics and has status conditions on its resources (<code>ClusterQueue</code>, <code>LocalQueue</code>, <code>Workload</code>). Monitoring Kueue is essential for understanding queue lengths, resource utilization, admission decisions, and potential bottlenecks.</p> <ul> <li>Kueue Metrics: Scrape metrics from the <code>kueue-controller-manager</code> similar to the Kaiwo operator.</li> <li>Queue Status: Check the status of <code>ClusterQueue</code> and <code>LocalQueue</code> resources:     <pre><code>kubectl get clusterqueue &lt;queue-name&gt; -o yaml\nkubectl get localqueue -n &lt;namespace&gt; &lt;queue-name&gt; -o yaml\n</code></pre></li> <li>Workload Status: Inspect <code>Workload</code> resources created by Kueue for admitted/pending jobs:     <pre><code>kubectl get workloads -n &lt;namespace&gt;\nkubectl describe workload -n &lt;namespace&gt; &lt;workload-name&gt;\n</code></pre></li> </ul> <p>Refer to the Kueue documentation for details on its metrics.</p>"},{"location":"admin/monitoring/#workload-status-and-events","title":"Workload Status and Events","text":"<p>Monitor the status of the <code>KaiwoJob</code> and <code>KaiwoService</code> resources themselves:</p> <pre><code>kubectl get kaiwojobs -A\nkubectl get kaiwoservices -A\n\nkubectl describe kaiwojob -n &lt;namespace&gt; &lt;job-name&gt;\nkubectl describe kaiwoservice -n &lt;namespace&gt; &lt;service-name&gt;\n</code></pre> <p>Check the <code>status</code> field for the overall phase (<code>PENDING</code>, <code>RUNNING</code>, <code>COMPLETE</code>, <code>FAILED</code>, <code>READY</code>) and <code>conditions</code>.</p> <p>Also, monitor Kubernetes events related to Kaiwo resources and the underlying pods/jobs/deployments:</p> <pre><code>kubectl get events -n &lt;namespace&gt; --sort-by='.lastTimestamp'\n</code></pre>"},{"location":"admin/monitoring/#cluster-resource-utilization","title":"Cluster Resource Utilization","text":"<p>Use standard Kubernetes monitoring tools (e.g., <code>kubectl top nodes</code>, <code>kubectl top pods</code>, Prometheus with <code>kube-state-metrics</code> and <code>node-exporter</code>) to track overall cluster CPU, memory, and GPU utilization. Pay special attention to GPU utilization on nodes designated for AI workloads.</p>"},{"location":"admin/monitoring/#dashboards-and-alerting","title":"Dashboards and Alerting","text":"<p>Create dashboards (e.g., in Grafana) combining metrics from the Kaiwo operator, Kueue, GPU operator, and standard Kubernetes components to get a holistic view of the system. Set up alerts based on key metrics or status conditions (e.g., high queue lengths, operator errors, low GPU utilization, failed workloads).</p>"},{"location":"admin/overview/","title":"Overview for Administrators","text":"<p>Kaiwo provides a layer on top of Kubernetes, Kueue, and Ray to streamline the management and execution of AI workloads, particularly focusing on efficient GPU utilization. As an administrator, your role involves deploying, configuring, and maintaining the Kaiwo system.</p>"},{"location":"admin/overview/#key-components-and-concepts","title":"Key Components and Concepts","text":"<ol> <li> <p>Kaiwo Operator:</p> <ul> <li>Runs as a deployment within the Kubernetes cluster.</li> <li>Manages the lifecycle of Kaiwo Custom Resources (<code>KaiwoJob</code>, <code>KaiwoService</code>, <code>KaiwoQueueConfig</code>).</li> <li>Controllers: Includes specific controllers for each CRD:<ul> <li><code>KaiwoJobController</code>: Translates <code>KaiwoJob</code> into <code>batchv1.Job</code> or <code>rayv1.RayJob</code>, manages dependencies (like download jobs, PVCs), and updates status.</li> <li><code>KaiwoServiceController</code>: Translates <code>KaiwoService</code> into <code>appsv1.Deployment</code> or <code>rayv1.RayService</code> (wrapped in an <code>AppWrapper</code>), manages dependencies, and updates status.</li> <li><code>KaiwoQueueConfigController</code>: Manages Kueue resources (<code>ClusterQueue</code>, <code>ResourceFlavor</code>, <code>WorkloadPriorityClass</code>) based on the cluster-scoped <code>KaiwoQueueConfig</code> CRD. Ensures a default configuration exists.</li> </ul> </li> <li>Integration: Interacts with the Kubernetes API, Kueue, and Ray operators.</li> </ul> </li> <li> <p>Kaiwo CRDs:</p> <ul> <li><code>KaiwoJob</code> / <code>KaiwoService</code>: User-facing resources defined by AI Scientists to describe their workloads. They abstract away much of the underlying Kubernetes/Ray/Kueue complexity.</li> <li><code>KaiwoQueueConfig</code>: A cluster-scoped resource (typically one named <code>kaiwo</code>) used by administrators to define and manage Kueue configurations centrally. This includes defining queues, resource types (flavors), and priorities.</li> </ul> </li> <li> <p>Kueue Integration:</p> <ul> <li>Kaiwo relies on Kueue for job queueing, scheduling, and resource quota management.</li> <li>The Kaiwo Operator, specifically the <code>KaiwoQueueConfigController</code>, manages the creation and synchronization of Kueue <code>ClusterQueue</code>, <code>ResourceFlavor</code>, and <code>WorkloadPriorityClass</code> resources based on the <code>KaiwoQueueConfig</code> CRD.</li> <li>Workloads (<code>KaiwoJob</code>/<code>KaiwoService</code>) are submitted to a specific <code>ClusterQueue</code> (via the <code>kueue.x-k8s.io/queue-name</code> label, derived from <code>spec.clusterQueue</code>).</li> </ul> </li> <li> <p>Ray Integration:</p> <ul> <li>If <code>spec.ray: true</code> is set in a <code>KaiwoJob</code> or <code>KaiwoService</code>, the operator creates <code>RayJob</code> or <code>RayService</code> resources instead of standard Kubernetes ones.</li> <li>This leverages Ray for distributed execution capabilities. Requires the KubeRay operator to be installed.</li> </ul> </li> <li> <p>Kaiwo CLI:</p> <ul> <li>The primary user interface for AI Scientists.</li> <li>Communicates with the Kubernetes API to create and manage Kaiwo CRDs.</li> <li>Requires <code>kubeconfig</code> access similar to <code>kubectl</code>.</li> </ul> </li> </ol>"},{"location":"admin/overview/#administrator-responsibilities","title":"Administrator Responsibilities","text":"<ul> <li>Installation: Deploying the Kaiwo operator and its dependencies (Kueue, Ray Operator, Cert-Manager, GPU Operator, etc.).</li> <li>Configuration: Defining cluster-wide queuing policies, resource flavors (mapping to node types/pools), and priorities using the <code>KaiwoQueueConfig</code> CRD. Managing storage classes referenced by users.</li> <li>Maintenance: Upgrading Kaiwo components, monitoring operator health, managing certificates.</li> <li>Monitoring: Observing cluster resource utilization, queue lengths, and workload statuses. Integrating with monitoring tools like Prometheus.</li> <li>User Management: Potentially managing namespaces and ensuring users target appropriate Kueue queues.</li> <li>Troubleshooting: Diagnosing issues related to scheduling, resource allocation, operator errors, or workload failures.</li> </ul>"},{"location":"admin/resource-monitoring/","title":"Resource Monitoring","text":"<p>The Kaiwo Operator includes a resource monitoring utility which continuously watches your Kaiwo workloads (Jobs or Services) and checks their GPU utilization via metrics endpoints. If any pod of a workload that reserves GPUs is underutilizing the GPU, the operator marks the workload as Underutilized and emits an event. If the workload does not utilize the GPU for a given amount of time, it is automatically terminated. This termination feature is enabled by default if resource monitoring is enabled, but it can be disabled in case you want to implement your own termination logic.</p> <p>In order for workloads to be monitored, they must be deployed via Kaiwo CRDs (<code>KaiwoJob</code> or <code>KaiwoService</code>). This ensures that the created resources have the correct labels and are inspected by the resource monitor.</p>"},{"location":"admin/resource-monitoring/#configuration","title":"Configuration","text":""},{"location":"admin/resource-monitoring/#operator-environmental-variables","title":"Operator Environmental Variables","text":"<p>Resource monitoring is enabled via environmental variables given to the Kaiwo operator: </p> Parameter Description Default <code>RESOURCE_MONITORING_ENABLED</code> Enable or disable monitoring (<code>true</code>/<code>false</code>) <code>false</code> <code>RESOURCE_MONITORING_METRICS_ENDPOINT</code> URL of your metrics endpoint (required) <code>RESOURCE_MONITORING_POLLING_INTERVAL</code> How often to check metrics (e.g. <code>30s</code>, <code>1m</code>) (required) <p>Note</p> <p>Setting the polling interval very long with workloads that only use GPUs occasionally may end up causing false early terminations, if the GPU is not in use during the polling check. Ensure that your polling interval is low enough to catch GPU usage based on your workload.</p> <p>These options are set as the operator environment variables and cannot be changed during runtime.</p>"},{"location":"admin/resource-monitoring/#resourcemonitoring-field-in-kaiwoconfig","title":"<code>resourceMonitoring</code> field in KaiwoConfig","text":"<p>Please see the CRD documentation for the available options for setting the runtime configuration for the resource monitoring. Changing these fields takes effect immediately.</p> <p>By default, <code>terminateUnderutilizingAfter</code> is set to 24 hours and <code>lowUtilizationThreshold</code> is set to 1 (percent). This means that if a workload reaches at least 1 % GPU utilization at least once over 24 hours, it will not be terminated. These values should most likely be changed to suit your environment.</p>"},{"location":"admin/resource-monitoring/#terminating-underutilizing-workloads","title":"Terminating Underutilizing Workloads","text":"<p>If the KaiwoConfig field <code>spec.resourceMonitoring.terminateUnderutilizing</code> is <code>true</code> (the default), once a workload has been underutilizing one or more GPUs continuously for the time specified in the field <code>spec.resourceMonitoring.terminateUnderutilizingAfter</code>, it is flagged for termination by setting the early termination condition and setting the status to <code>TERMINATING</code>. The Kaiwo operator will then take care of deleting the dependent resources, but keeps the Kaiwo workload object available to provide a way to inspect the reason for termination.</p>"},{"location":"admin/resource-monitoring/#status-conditions","title":"Status Conditions","text":"<p>Once monitoring begins, each KaiwoWorkload will have a condition under <code>.status.conditions</code>:</p> <pre><code>- type: ResourceUnderutilization\n  status: \"False\"    # \u201cTrue\u201d means Underutilized, \u201cFalse\u201d means Normal\n  reason: GpuUtilizationNormal    # or GpuUtilizationLow\n  message: \"GPU utilization normal\"\n</code></pre> <p>If a workload is flagged for early termination, it will have an additional condition:</p> <pre><code>- type: WorkloadTerminatedEarly\n  status: \"True\"\n  reason: GpuUtilizationLow    # or GpuUtilizationLow\n  message: \"Early termination due to low GPU usage\"\n</code></pre>"},{"location":"admin/resource-monitoring/#best-practices","title":"Best Practices","text":"<ul> <li>Right-size your thresholds   Choose a sensible cutoff (e.g. 10\u201330%) so you catch idle pods without false positives</li> <li>Namespace filtering   Use the KaiwoConfig field <code>spec.resourceMonitoring.targetNamespaces</code> to restrict monitoring to critical workloads only.</li> </ul>"},{"location":"admin/resource-monitoring/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>No status updates?<ul> <li>Ensure <code>ENABLED=true</code> and <code>METRICS_ENDPOINT</code> is reachable.</li> <li>Check operator logs for query errors.</li> </ul> </li> <li>Excessive events?<ul> <li>Increase <code>lowUtilizationThreshold</code> to reduce sensitivity.</li> </ul> </li> </ul>"},{"location":"admin/troubleshooting/","title":"Troubleshooting Guide","text":"<p>This guide provides steps for diagnosing common issues with Kaiwo.</p>"},{"location":"admin/troubleshooting/#operator-issues","title":"Operator Issues","text":""},{"location":"admin/troubleshooting/#operator-pod-not-running-or-crashing","title":"Operator Pod Not Running or Crashing","text":"<ol> <li> <p>Check Pod Status:     <pre><code>kubectl get pods -n kaiwo-system -l control-plane=kaiwo-controller-manager\n</code></pre>     Look for pods in <code>CrashLoopBackOff</code>, <code>Error</code>, or <code>Pending</code> states.</p> </li> <li> <p>Examine Pod Logs:     <pre><code>kubectl logs -n kaiwo-system -l control-plane=kaiwo-controller-manager\n# Or for a specific crashing pod:\nkubectl logs -n kaiwo-system &lt;pod-name&gt; -p # Check previous container logs\n</code></pre>     Look for error messages related to startup, configuration, API connectivity, or reconciliation loops.</p> </li> <li> <p>Describe Pod:     <pre><code>kubectl describe pod -n kaiwo-system &lt;pod-name&gt;\n</code></pre>     Check for events related to scheduling failures (resource constraints, taints/tolerations), image pull errors, readiness/liveness probe failures, or volume mount issues.</p> </li> <li> <p>Check Dependencies: Ensure all dependencies (Cert-Manager, Kueue, Ray Operator, GPU Operator, AppWrapper) are running correctly in their respective namespaces. Check their logs if necessary.</p> </li> <li> <p>RBAC Permissions: Verify the Kaiwo operator's <code>ServiceAccount</code>, <code>ClusterRole</code>, and <code>ClusterRoleBinding</code> grant sufficient permissions. Errors related to \"forbidden\" access often point to RBAC issues.</p> </li> <li> <p>Webhook Issues: If webhooks are enabled, check Cert-Manager status and webhook service connectivity. Invalid certificates or network policies blocking webhook calls can prevent resource creation/updates.</p> <ul> <li>Check webhook configurations: <code>kubectl get mutatingwebhookconfigurations</code>, <code>kubectl get validatingwebhookconfigurations</code></li> <li>Check certificate status: <code>kubectl get certificates -n kaiwo-system</code></li> <li>Test webhook service endpoint.</li> </ul> </li> </ol>"},{"location":"admin/troubleshooting/#default-kaiwoqueueconfig-not-created","title":"Default <code>KaiwoQueueConfig</code> Not Created","text":"<ul> <li>Check operator logs (<code>kubectl logs -n kaiwo-system -l control-plane=kaiwo-controller-manager</code>) for errors during the startup routine that creates the default configuration.</li> <li>Common causes include inability to list Nodes (RBAC issue) or errors during node labeling/tainting if enabled.</li> </ul>"},{"location":"admin/troubleshooting/#kueue-resources-not-syncing","title":"Kueue Resources Not Syncing","text":"<ul> <li>Ensure the <code>kaiwo</code> <code>KaiwoQueueConfig</code> resource exists (<code>kubectl get kaiwoqueueconfig kaiwo</code>).</li> <li>Check operator logs for errors related to creating/updating Kueue <code>ResourceFlavors</code>, <code>ClusterQueues</code>, or <code>WorkloadPriorityClasses</code>.</li> <li>Verify the operator has RBAC permissions to manage these Kueue resources.</li> <li>Check Kueue controller logs (<code>kubectl logs -n kueue-system -l control-plane=controller-manager -f</code>) for related errors.</li> </ul>"},{"location":"admin/troubleshooting/#workload-issues","title":"Workload Issues","text":""},{"location":"admin/troubleshooting/#workload-stuck-in-pending","title":"Workload Stuck in <code>PENDING</code>","text":"<p>This usually means Kueue has not admitted the workload yet.</p> <ol> <li> <p>Check Kueue Workload Status: Find the Kueue <code>Workload</code> resource corresponding to your <code>KaiwoJob</code>/<code>KaiwoService</code>.     <pre><code># Find the workload (often named after the Kaiwo resource)\nkubectl get workloads -n &lt;namespace&gt;\n# Describe the workload to see admission status and reasons for pending\nkubectl describe workload -n &lt;namespace&gt; &lt;workload-name&gt;\n</code></pre>     Look for conditions like <code>Admitted</code> being <code>False</code> and check the <code>Message</code> for reasons (e.g., quota exhaustion, no matching <code>ResourceFlavor</code>).</p> </li> <li> <p>Check ClusterQueue Status:     <pre><code>kubectl describe clusterqueue &lt;queue-name&gt;\n</code></pre>     Look at usage vs. quota (<code>nominalQuota</code>) for relevant resource flavors.</p> </li> <li> <p>Check ResourceFlavor Definitions: Ensure <code>ResourceFlavors</code> defined in <code>KaiwoQueueConfig</code> correctly match node labels in your cluster.</p> </li> <li> <p>Check LocalQueue: Ensure a <code>LocalQueue</code> pointing to the correct <code>ClusterQueue</code> exists in the workload's namespace (<code>kubectl get localqueue -n &lt;namespace&gt; &lt;queue-name&gt;</code>). Kaiwo operator should create these if specified in <code>KaiwoQueueConfig.spec.clusterQueues[].namespaces</code>.</p> </li> </ol>"},{"location":"admin/troubleshooting/#workload-fails-immediately-status-failed","title":"Workload Fails Immediately (Status <code>FAILED</code>)","text":"<ol> <li> <p>Check Kaiwo Resource Events:     <pre><code>kubectl describe kaiwojob -n &lt;namespace&gt; &lt;job-name&gt;\n# or\nkubectl describe kaiwoservice -n &lt;namespace&gt; &lt;service-name&gt;\n</code></pre>     Look for events indicating failures during dependency creation (e.g., PVC, download job) or underlying resource creation.</p> </li> <li> <p>Check Download Job Logs (if applicable): If using <code>spec.storage</code> with downloads, check the logs of the downloader job pod.     <pre><code># Find the downloader pod (usually name ends with '-download-&lt;hash&gt;')\nkubectl get pods -n &lt;namespace&gt; | grep &lt;job-name&gt;-download\n# Get logs\nkubectl logs -n &lt;namespace&gt; &lt;downloader-pod-name&gt;\n</code></pre>     Look for errors related to accessing storage secrets, connecting to S3/GCS/Git, or filesystem permissions.</p> </li> <li> <p>Check Underlying Resource Events/Logs:</p> <ul> <li>For <code>KaiwoJob</code> -&gt; <code>BatchJob</code>: <code>kubectl describe job -n &lt;namespace&gt; &lt;job-name&gt;</code> and check pod events/logs.</li> <li>For <code>KaiwoJob</code> -&gt; <code>RayJob</code>: <code>kubectl describe rayjob -n &lt;namespace&gt; &lt;job-name&gt;</code> and check Ray cluster/pod events/logs.</li> <li>For <code>KaiwoService</code> -&gt; <code>Deployment</code>: <code>kubectl describe deployment -n &lt;namespace&gt; &lt;service-name&gt;</code> and check pod events/logs.</li> <li>For <code>KaiwoService</code> -&gt; <code>RayService</code>: <code>kubectl describe rayservice -n &lt;namespace&gt; &lt;service-name&gt;</code> and check Ray cluster/pod events/logs.</li> </ul> </li> </ol>"},{"location":"admin/troubleshooting/#pods-not-scheduling-stuck-in-pending","title":"Pods Not Scheduling / Stuck in <code>Pending</code>","text":"<p>This occurs after Kueue admits the workload but before Kubernetes schedules the pod(s).</p> <ol> <li>Describe Pod:     <pre><code>kubectl describe pod -n &lt;namespace&gt; &lt;pod-name&gt;\n</code></pre>     Check the <code>Events</code> section for messages from the scheduler (e.g., <code>FailedScheduling</code>). Common reasons include:<ul> <li>Insufficient Resources: Not enough CPU, memory, or GPUs available on any node.</li> <li>Node Affinity/Selector Mismatch: Pod requires labels that no node possesses (often related to <code>ResourceFlavor</code> <code>nodeLabels</code>).</li> <li>Taint/Toleration Mismatch: Pod lacks tolerations for taints present on suitable nodes (e.g., GPU taint). Kaiwo should add GPU tolerations automatically if GPUs are requested.</li> <li>PVC Binding Issues: If using <code>storage</code>, check if the <code>PersistentVolumeClaim</code> is stuck in <code>Pending</code> (<code>kubectl get pvc -n &lt;namespace&gt;</code>). This could be due to no available <code>PersistentVolume</code> or StorageClass issues.</li> </ul> </li> </ol>"},{"location":"admin/troubleshooting/#pods-crashing-crashloopbackoff","title":"Pods Crashing / <code>CrashLoopBackOff</code>","text":"<ol> <li> <p>Check Pod Logs: This is the most important step.     <pre><code>kubectl logs -n &lt;namespace&gt; &lt;pod-name&gt;\nkubectl logs -n &lt;namespace&gt; &lt;pod-name&gt; -p # Previous container instance logs\n</code></pre>     Look for application errors, missing files, permission issues, OOMKilled errors, GPU driver/runtime errors.</p> </li> <li> <p>Describe Pod: Check events for reasons like OOMKilled.</p> </li> <li> <p>Exec into Pod (if possible): Use <code>kaiwo exec</code> or <code>kubectl exec</code> to inspect the container environment.     <pre><code>kaiwo exec job/&lt;job-name&gt; --command \"/bin/bash\" -n &lt;namespace&gt;\n# or\nkubectl exec -it -n &lt;namespace&gt; &lt;pod-name&gt; -- /bin/bash\n</code></pre></p> </li> </ol>"},{"location":"admin/troubleshooting/#developer-debugging-kaiwo-dev","title":"Developer Debugging (<code>kaiwo-dev</code>)","text":"<p>Info</p> <p>This feature is only intended for contributors</p> <p>The <code>kaiwo-dev</code> tool (built separately from the main CLI/operator) provides debugging utilities.</p> <ul> <li> <p><code>kaiwo-dev debug chainsaw</code>: Helps debug Kyverno Chainsaw E2E tests by collecting and correlating logs and events from a specific test namespace.</p> <p><pre><code># Build the tool: go build -o bin/kaiwo-dev ./pkg/cli/dev/main.go\n./bin/kaiwo-dev debug chainsaw -n &lt;test-namespace&gt; [--print-level &lt;debug|info|warn|error&gt;]\n</code></pre> This command gathers Kaiwo controller logs relevant to the namespace, pod logs within the namespace, and Kubernetes events, sorts them chronologically, and prints them with color-coding. Useful for understanding the sequence of events during a failed test run.</p> </li> </ul>"},{"location":"aim/","title":"AIM - AMD Inference Microservice","text":"<p>AIM (AMD Inference Microservice) Engine is a Kubernetes operator that simplifies the deployment and management of AI inference workloads on AMD GPUs. It provides a declarative, cloud-native approach to running ML models at scale.</p>"},{"location":"aim/#what-aim-does","title":"What AIM Does","text":"<p>AIM abstracts the complexity of inference deployment by providing:</p> <ul> <li>Simple Service Deployment: Deploy inference endpoints with minimal configuration using <code>AIMService</code> resources</li> <li>Automatic Optimization: Configure workloads for latency or throughput optimization with preset profiles</li> <li>Model Catalog Management: Maintain a catalog of available models across cluster and namespace scopes</li> <li>HTTP Routing Integration: Expose services through Gateway API with customizable path templates</li> <li>Resource Management: Handle GPU allocation, resource requirements, and scaling automatically</li> </ul>"},{"location":"aim/#quick-example","title":"Quick Example","text":"<p>Deploy an inference service:</p> <pre><code>apiVersion: aim.silogen.ai/v1alpha1\nkind: AIMService\nmetadata:\n  name: llama-chat\n  namespace: ml-team\nspec:\n  model:\n    image: ghcr.io/silogen/aim-meta-llama-llama-3-1-8b-instruct:0.7.0\n  replicas: 2\n  routing:\n    enabled: true\n    gatewayRef:\n      name: inference-gateway\n      namespace: gateways\n    pathTemplate: \"{.metadata.namespace}/{.metadata.name}\"\n</code></pre> <p>AIM Engine automatically:</p> <ul> <li>Resolves the model container image</li> <li>Selects an appropriate runtime configuration</li> <li>Deploys a KServe InferenceService</li> <li>Creates HTTP routing through Gateway API via the path <code>ml-team/llama-chat</code></li> </ul>"},{"location":"aim/#documentation","title":"Documentation","text":"<ul> <li> <p>Usage Guides: Practical guides for deploying and configuring inference services</p> <ul> <li>Services - Deploy and manage inference endpoints</li> <li>Runtime Configuration - Configure credentials and settings</li> </ul> </li> <li> <p>Concepts: Deep dive into AIM Engine architecture and internals</p> <ul> <li>Models - Model catalog and discovery mechanism</li> <li>Templates - Runtime profiles and discovery</li> <li>Runtime Config - Resolution algorithm and architecture</li> <li>Model Caching - Cache lifecycle and deletion behavior</li> </ul> </li> </ul>"},{"location":"aim/#getting-started","title":"Getting Started","text":"<ol> <li> <p>Deploy a service: Start with the Services usage guide to deploy your first inference endpoint</p> </li> <li> <p>Configure authentication: Set up credentials for private registries using Runtime Configuration</p> </li> <li> <p>Explore advanced features: Learn about automatic template selection, model caching, and custom routing in the Concepts documentation</p> </li> </ol>"},{"location":"aim/#architecture","title":"Architecture","text":"<p>AIM builds on Kubernetes and KServe to provide:</p> <ul> <li>Declarative API: Define inference services using Kubernetes custom resources</li> <li>Multi-tenancy: Namespace-scoped and cluster-scoped resources support team isolation</li> <li>GitOps-friendly: All configuration expressed as YAML for version control and automation</li> <li>Gateway API Integration: Modern, standards-based HTTP routing</li> </ul>"},{"location":"aim/#support","title":"Support","text":"<p>For issues, questions, or contributions, please refer to the main project repository.</p>"},{"location":"aim/concepts/caching/","title":"Model Caching","text":"<p>AIM provides a hierarchical caching system that allows model artifacts to be pre-downloaded and shared across services in the same namespace. This document explains the caching architecture, resource lifecycle, and deletion behavior.</p>"},{"location":"aim/concepts/caching/#overview","title":"Overview","text":"<p>Model caching in AIM uses three resource types:</p> <ol> <li>AIMModelCache: Stores downloaded model artifacts on a PVC</li> <li>AIMTemplateCache: Groups model caches for a specific template (owned by <code>AIMServiceTemplate</code>)</li> <li>AIMService: Can trigger template cache creation via <code>spec.cacheModel: true</code></li> </ol>"},{"location":"aim/concepts/caching/#caching-hierarchy","title":"Caching Hierarchy","text":""},{"location":"aim/concepts/caching/#ownership-structure","title":"Ownership Structure","text":"<pre><code>AIMServiceTemplate\n    \u2514\u2500\u2500 AIMTemplateCache (owned by template)\n            \u2514\u2500\u2500 AIMModelCache(s) (created by template cache)\n                    \u2514\u2500\u2500 PVC(s) + Download Job(s) (owned by model cache)\n</code></pre>"},{"location":"aim/concepts/caching/#creation-flow","title":"Creation Flow","text":"<p>When an <code>AIMService</code> has <code>spec.cacheModel: true</code>, the service controller creates an <code>AIMTemplateCache</code>, if one doesn't already exist, for the resolved template. However, the cache is owned by the template, not the service. This allows:</p> <ul> <li>Multiple services to share the same template cache</li> <li>Cache preservation when a service is deleted (if the AIMTemplateCache becomes Available)</li> <li>Proper cleanup when the template itself is deleted</li> </ul> <p>The <code>AIMTemplateCache</code> creates an <code>AIMModelCache</code> for each needed model. The <code>AIMModelCache</code> handles the model download.</p>"},{"location":"aim/concepts/caching/#cache-status-values","title":"Cache Status Values","text":"<p>Each cache resource tracks its status:</p> Status Description <code>Pending</code> Cache created, waiting for processing <code>Progressing</code> Download or provisioning in progress <code>Available</code> Cache is ready and can be used <code>Failed</code> Cache creation failed (download error, storage issue, etc.) <p>Note that a <code>Failed</code> AIMModelCache will retry the download periodically, causing the Status to change at the same time.</p>"},{"location":"aim/concepts/caching/#deletion-behavior","title":"Deletion Behavior","text":"<p>AIM implements a cache cleanup process that preserves useful caches while cleaning up non-functioning ones.</p>"},{"location":"aim/concepts/caching/#cache-handling-when-aimservice-is-deleted","title":"Cache handling when AIMService is deleted","text":"<p>When an <code>AIMService</code> is deleted:</p> <p>Template caches that were created by this service are evaluated: - Available caches \u2192 Preserved (can be reused by future services) - Non-available caches (Pending/Progressing/Failed) \u2192 Deleted</p> <p>This design allows cache reuse: if you delete a service and recreate it later, the existing Available cache will be used immediately without re-downloading.</p> <p>Note: Since template caches are owned by templates (not services), an Available cache persists as long as its owning template exists.</p>"},{"location":"aim/concepts/caching/#cache-handling-when-aimservicetemplate-is-deletion","title":"Cache handling when AIMServiceTemplate is deletion","text":"<p>When an <code>AIMServiceTemplate</code> is deleted:</p> <ol> <li>Template caches owned by this template are garbage-collected automatically</li> <li>This cleans up non-Available model caches</li> </ol>"},{"location":"aim/concepts/caching/#aimtemplatecache-deletion","title":"AIMTemplateCache Deletion","text":"<p>When an <code>AIMTemplateCache</code> is deleted:</p> <ol> <li>Model caches created by this template cache are evaluated:</li> <li>Available caches \u2192 Preserved (can be reused by other template caches)</li> <li>Non-available caches (Pending/Progressing/Failed) \u2192 Deleted</li> <li>The template cache itself is removed</li> </ol> <p>Available Model caches are preserved because they can be shared across template caches for the same model sources, and they can be reused by any <code>AIMTemplateCache</code> created later.</p> <p>Note that if an AIMService has caching enabled, a new AIMTemplateCache will be immediately created by the AIMService.</p>"},{"location":"aim/concepts/caching/#aimmodelcache-deletion","title":"AIMModelCache Deletion","text":"<p>When an <code>AIMModelCache</code> is deleted:</p> <ol> <li>The PVC containing downloaded model files is garbage-collected</li> <li>Any running download Job is garbage-collected</li> </ol> <p>NOTE: Any AIMService running with this Model will keep the PVC mounted </p>"},{"location":"aim/concepts/caching/#cache-reuse","title":"Cache Reuse","text":""},{"location":"aim/concepts/caching/#automatic-reuse","title":"Automatic Reuse","text":"<p>Services automatically detect and use existing caches:</p> <ol> <li>Service resolves its template</li> <li>Controller looks for <code>AIMTemplateCache</code> matching the template</li> <li>If an Available cache exists, the service mounts its PVCs directly</li> <li>No re-download is needed</li> </ol>"},{"location":"aim/concepts/caching/#cross-service-sharing","title":"Cross-Service Sharing","text":"<p>Multiple services can share the same cached models:</p> <ul> <li>Services using the same template reference the same <code>AIMTemplateCache</code></li> <li>Model caches are identified by <code>sourceURI</code>, enabling reuse across templates</li> </ul>"},{"location":"aim/concepts/caching/#manual-cache-management","title":"Manual Cache Management","text":"<ul> <li>To manually make sure a model is available create an AIMModelCache for that model.</li> <li>To make sure all models that belong to a AIMServiceTemplate or AIMClusterServiceTemplate is available, create an AIMTemplateCache in the namespace.</li> <li>Manual cleanup is necessary for all <code>Available</code> AIMModelCaches.</li> </ul>"},{"location":"aim/concepts/caching/#related-documentation","title":"Related Documentation","text":"<ul> <li>Templates - Understanding ServiceTemplates and discovery</li> <li>Services - Deploying services with caching</li> </ul>"},{"location":"aim/concepts/kv-cache/","title":"KV Cache","text":"<p>KV Cache (Key-Value Cache) is a performance optimization technique for Large Language Model (LLM) inference that significantly improves throughput and reduces latency by caching intermediate computation results.</p>"},{"location":"aim/concepts/kv-cache/#overview","title":"Overview","text":"<p>During LLM inference, the model processes input tokens and generates attention key-value pairs. These key-value pairs can be cached and reused across requests that share common prompt prefixes, eliminating redundant computation and dramatically improving performance for common use cases like:</p> <ul> <li>Chat applications with system prompts</li> <li>RAG (Retrieval Augmented Generation) with shared context</li> <li>Code completion with common boilerplate</li> <li>Batch processing with template prefixes</li> </ul>"},{"location":"aim/concepts/kv-cache/#architecture","title":"Architecture","text":"<p>The KV cache implementation in Kaiwo consists of two key components:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   AIMService    \u2502  References or creates\n\u2502                 \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                     \u2502\n                                        \u25bc\n                              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                              \u2502  AIMKVCache      \u2502\n                              \u2502  (Custom Resource)\u2502\n                              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                        \u2502 Creates &amp; manages\n                                        \u25bc\n                              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                              \u2502   StatefulSet    \u2502\n                              \u2502   + Service      \u2502\n                              \u2502                  \u2502\n                              \u2502  Redis  \u2502\n                              \u2502  Backend         \u2502\n                              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"aim/concepts/kv-cache/#components","title":"Components","text":"<p>AIMService - Specifies KV cache requirements via <code>spec.kvCache</code> - Can create a new KV cache or reference an existing one - Receives KV cache endpoint configuration automatically</p> <p>AIMKVCache (Custom Resource) - Manages the lifecycle of a KV cache backend - Creates and maintains a StatefulSet with persistent storage - Provides a stable Service endpoint for cache access - Supports Redis backends</p> <p>Backend (StatefulSet) - Runs the actual KV cache storage (Redis) - Uses persistent volumes for durability - Provides network endpoint for cache operations</p>"},{"location":"aim/concepts/kv-cache/#lifecycle-management","title":"Lifecycle Management","text":""},{"location":"aim/concepts/kv-cache/#creation-patterns","title":"Creation Patterns","text":"<p>Pattern 1: AIMService Creates KV Cache When an <code>AIMService</code> specifies <code>kvCache.type</code> without a <code>name</code>, a new <code>AIMKVCache</code> resource is automatically created with the name <code>kvcache-{namespace}</code>.</p> <p>Pattern 2: Shared KV Cache Multiple <code>AIMService</code> resources can reference the same <code>AIMKVCache</code> by specifying <code>kvCache.name</code>. This enables cache sharing across multiple inference endpoints.</p>"},{"location":"aim/concepts/kv-cache/#ownership","title":"Ownership","text":"<ul> <li>When an <code>AIMService</code> creates a KV cache (Pattern 1), it owns the cache resource</li> <li>The KV cache's lifecycle is tied to the owning service</li> <li>When referencing an existing cache (Pattern 2), the cache is independent and can outlive the service</li> </ul>"},{"location":"aim/concepts/kv-cache/#states","title":"States","text":"<p>An <code>AIMKVCache</code> progresses through the following states:</p> <ol> <li>Pending - Resource created, StatefulSet creation queued</li> <li>Progressing - StatefulSet and Service being deployed, waiting for pods to be ready</li> <li>Ready - Backend is running and available for use</li> <li>Failed - Deployment encountered an error (check conditions for details)</li> </ol>"},{"location":"aim/concepts/kv-cache/#status-information","title":"Status Information","text":"<p>The <code>AIMKVCache</code> status provides comprehensive information about the cache state:</p> <p>Basic Information: - <code>status</code> - Current state (Pending, Progressing, Ready, Failed) - <code>statefulSetName</code> - Name of the managed StatefulSet - <code>serviceName</code> - Name of the Kubernetes Service providing network access</p> <p>Operational Metrics: - <code>endpoint</code> - Connection string for accessing the cache (e.g., <code>redis://service-name:6379</code>) - <code>replicas</code> - Total number of replicas configured - <code>readyReplicas</code> - Number of replicas currently ready and serving - <code>storageSize</code> - Allocated storage capacity (e.g., <code>50Gi</code>)</p> <p>Error Tracking: - <code>lastError</code> - Most recent error message (cleared when resolved) - <code>conditions</code> - Detailed condition history for troubleshooting</p>"},{"location":"aim/concepts/kv-cache/#storage-considerations","title":"Storage Considerations","text":""},{"location":"aim/concepts/kv-cache/#sizing","title":"Sizing","text":"<p>The storage size for a KV cache depends on several factors:</p> <ul> <li>Model size: Larger models have bigger key-value tensors</li> <li>Context length: Longer contexts require more cache storage</li> <li>Batch size: Higher batch sizes increase cache requirements</li> <li>Expected request volume: More concurrent requests need more cache space</li> </ul> <p>Monitor actual usage and adjust accordingly.</p>"},{"location":"aim/concepts/kv-cache/#storage-classes","title":"Storage Classes","text":"<p>The KV cache uses Kubernetes <code>PersistentVolumeClaims</code> for durable storage. If no <code>storageClassName</code> is specified, the cluster's default storage class is used.</p> <p>Recommendations: - Use SSD-backed storage for better performance - Ensure the storage class supports <code>ReadWriteOnce</code> access mode - Verify sufficient storage quota in your namespace</p>"},{"location":"aim/concepts/kv-cache/#backend-types","title":"Backend Types","text":""},{"location":"aim/concepts/kv-cache/#redis","title":"Redis","text":"<p>Redis is the default and currently supported backend. It provides: - High-performance in-memory caching with disk persistence - Mature, battle-tested reliability - Straightforward configuration</p>"},{"location":"aim/concepts/kv-cache/#best-practices","title":"Best Practices","text":"<ol> <li>Size appropriately: Start with recommended sizes and monitor actual usage</li> <li>Share when possible: Use shared caches for services with overlapping use cases</li> <li>Monitor storage: Set up alerts for storage capacity</li> <li>Use fast storage: SSD-backed storage classes provide best performance</li> <li>Plan for growth: KV cache storage needs grow with traffic volume</li> </ol>"},{"location":"aim/concepts/kv-cache/#see-also","title":"See Also","text":"<ul> <li>KV Cache Usage Guide - Practical examples and configuration</li> <li>Deploying Inference Services - AIMService configuration</li> <li>Runtime Configuration - Additional service configuration</li> </ul>"},{"location":"aim/concepts/model-sources/","title":"Model Sources","text":"<p>AIMClusterModelSource automatically discovers and syncs AI model images from container registries, creating AIMClusterModel resources for matched images.</p>"},{"location":"aim/concepts/model-sources/#overview","title":"Overview","text":"<p>Model sources eliminate the need to manually create model resources for every image version. They continuously sync with container registries, automatically creating models when new images are published.</p> <p>Key features:</p> <ul> <li>Automatic discovery: Continuously monitors registries for images matching your filters</li> <li>Flexible filtering: Use wildcards, version constraints, and exclusions</li> <li>Multi-registry support: Works with Docker Hub, GitHub Container Registry (ghcr.io), and more</li> <li>Periodic sync: Configurable sync intervals to keep models up to date</li> <li>Private registries: Supports authentication via imagePullSecrets</li> </ul>"},{"location":"aim/concepts/model-sources/#basic-example","title":"Basic Example","text":"<pre><code>apiVersion: aim.silogen.ai/v1alpha1\nkind: AIMClusterModelSource\nmetadata:\n  name: silogen-models\nspec:\n  filters:\n    - image: amdenterpriseai/aim-*\n  syncInterval: 1h\n</code></pre> <p>This source discovers all images matching <code>amdenterpriseai/aim-*</code> from Docker Hub and creates an AIMClusterModel for each.</p>"},{"location":"aim/concepts/model-sources/#configuration","title":"Configuration","text":""},{"location":"aim/concepts/model-sources/#registry","title":"Registry","text":"<p>The <code>registry</code> field specifies which container registry to query. Defaults to <code>docker.io</code> if not specified.</p> <pre><code>spec:\n  registry: ghcr.io  # or docker.io, gcr.io, etc.\n</code></pre>"},{"location":"aim/concepts/model-sources/#filters","title":"Filters","text":"<p>Filters define which images to discover. Each filter specifies a pattern with optional version constraints and exclusions. Multiple filters are combined with OR logic.</p>"},{"location":"aim/concepts/model-sources/#repository-patterns","title":"Repository Patterns","text":"<p>Match repositories using wildcards:</p> <pre><code>spec:\n  filters:\n    - image: amdenterpriseai/aim-*\n</code></pre>"},{"location":"aim/concepts/model-sources/#repository-with-specific-tag","title":"Repository with Specific Tag","text":"<p>Match a specific tag:</p> <pre><code>spec:\n  filters:\n    - image: silogen/aim-llama:1.0.0\n</code></pre>"},{"location":"aim/concepts/model-sources/#full-uri","title":"Full URI","text":"<p>Override the registry for specific filters:</p> <pre><code>spec:\n  registry: docker.io\n  filters:\n    - image: ghcr.io/silogen/aim-google-gemma-3-1b-it:0.8.1-rc1\n</code></pre>"},{"location":"aim/concepts/model-sources/#full-uri-with-wildcard","title":"Full URI with Wildcard","text":"<p>Override registry and use wildcards:</p> <pre><code>spec:\n  registry: ghcr.io\n  filters:\n    - image: silogen/aim-*\n</code></pre>"},{"location":"aim/concepts/model-sources/#version-constraints","title":"Version Constraints","text":"<p>Use semantic version constraints to filter tags. Supports both global and per-filter version constraints.</p>"},{"location":"aim/concepts/model-sources/#global-version-constraints","title":"Global Version Constraints","text":"<p>Apply to all filters:</p> <pre><code>spec:\n  registry: ghcr.io\n  filters:\n    - image: silogen/aim-llama\n    - image: silogen/aim-mistral\n  versions:\n    - \"&gt;=1.0.0\"\n    - \"&lt;2.0.0\"\n</code></pre>"},{"location":"aim/concepts/model-sources/#per-filter-version-constraints","title":"Per-Filter Version Constraints","text":"<p>Override global constraints for specific filters:</p> <pre><code>spec:\n  registry: ghcr.io\n  versions:\n    - \"&gt;=1.0.0\"  # global default\n  filters:\n    - image: silogen/aim-llama\n      versions:\n        - \"&gt;=2.0.0\"  # overrides global for this filter\n    - image: silogen/aim-mistral\n      # uses global constraint\n</code></pre>"},{"location":"aim/concepts/model-sources/#version-syntax","title":"Version Syntax","text":"<p>Constraints use standard semver syntax:</p> <ul> <li><code>&gt;=1.0.0</code> - Version 1.0.0 or higher</li> <li><code>&lt;2.0.0</code> - Below version 2.0.0</li> <li><code>~1.2.0</code> - Patch updates only (1.2.x)</li> <li><code>^1.0.0</code> - Minor updates allowed (1.x.x)</li> </ul> <p>Prerelease versions (e.g., <code>0.8.1-rc1</code>) are supported:</p> <pre><code>versions:\n  - \"&gt;=0.8.1-rc1\"  # includes prereleases\n</code></pre> <p>Non-semver tags (e.g., <code>latest</code>, <code>dev</code>) are silently skipped when version constraints are specified.</p>"},{"location":"aim/concepts/model-sources/#exclusions","title":"Exclusions","text":"<p>Exclude specific repositories from matching:</p> <pre><code>spec:\n  filters:\n    - image: amdenterpriseai/aim-*\n      exclude:\n        - amdenterpriseai/aim-base\n        - amdenterpriseai/aim-experimental\n</code></pre> <p>Exclusions match repository names exactly (not including the registry).</p>"},{"location":"aim/concepts/model-sources/#sync-interval","title":"Sync Interval","text":"<p>Control how often the source syncs with the registry:</p> <pre><code>spec:\n  syncInterval: 30m  # supports: 15m, 1h, 2h30m, etc.\n</code></pre> <p>Default is <code>1h</code>. Minimum recommended interval is <code>15m</code> to avoid rate limiting.</p>"},{"location":"aim/concepts/model-sources/#private-registries","title":"Private Registries","text":"<p>Authenticate to private registries using imagePullSecrets:</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: ghcr-secret\n  namespace: kaiwo-system  # operator namespace\ntype: kubernetes.io/dockerconfigjson\ndata:\n  .dockerconfigjson: BASE64_CONFIG\n---\napiVersion: aim.silogen.ai/v1alpha1\nkind: AIMClusterModelSource\nmetadata:\n  name: private-models\nspec:\n  registry: ghcr.io\n  imagePullSecrets:\n    - name: ghcr-secret\n  filters:\n    - image: myorg/private-model-*\n</code></pre> <p>Secrets must exist in the operator namespace (typically <code>kaiwo-system</code>).</p>"},{"location":"aim/concepts/model-sources/#github-container-registry-ghcr-authentication","title":"GitHub Container Registry (GHCR) Authentication","text":"<p>For GitHub Container Registry, use a GitHub Personal Access Token (PAT) with the minimal required scope:</p> <p>Required Scope: - <code>read:packages</code> - Read access to container packages</p> <p>Recommended: Use Fine-Grained Personal Access Tokens</p> <ol> <li>Create a fine-grained PAT at: https://github.com/settings/tokens</li> <li>Set repository access or organization permissions</li> <li>Grant only <code>read:packages</code> permission</li> <li>Set expiration date</li> <li>Create the secret:</li> </ol> <pre><code>kubectl create secret docker-registry ghcr-secret \\\n  --docker-server=ghcr.io \\\n  --docker-username=YOUR_GITHUB_USERNAME \\\n  --docker-password=YOUR_GITHUB_PAT \\\n  --namespace=kaiwo-system\n</code></pre> <p>Security Best Practices: - Use fine-grained PATs instead of classic PATs when possible - Grant minimal permissions (<code>read:packages</code> only) - Set expiration dates on tokens - Rotate tokens regularly - Use separate tokens for different environments (dev/staging/prod) - Enable encryption at rest for Kubernetes Secrets in production - Limit Secret access via RBAC to only the operator namespace</p> <p>Token Scopes to Avoid: - \u274c <code>repo</code> - Grants read/write access to repositories (too broad) - \u274c <code>write:packages</code> - Write access not needed for discovery - \u274c <code>admin:org</code> - Organization admin access (unnecessary) - \u274c <code>delete:packages</code> - Delete permission (unnecessary risk)</p>"},{"location":"aim/concepts/model-sources/#max-models-limit","title":"Max Models Limit","text":"<p>Control the maximum number of models created to prevent runaway resource creation:</p> <pre><code>spec:\n  maxModels: 100  # default: 100, range: 1-10000\n  filters:\n    - image: org/very-broad-pattern-*\n</code></pre> <p>When the limit is reached:</p> <ul> <li>No new models are created, even if more matching images exist</li> <li>Existing models are never deleted</li> <li>Status shows <code>modelsLimitReached: true</code></li> <li><code>availableModels</code> shows total images found vs <code>discoveredModels</code> created</li> </ul> <p>Use Cases:</p> <ul> <li>Prevent accidental model explosion from overly broad filters</li> <li>Enforce resource quotas in multi-tenant environments</li> <li>Limit cluster resource consumption during initial sync</li> </ul> <p>Example Status:</p> <pre><code>status:\n  status: Ready\n  discoveredModels: 100\n  availableModels: 250\n  modelsLimitReached: true\n  conditions:\n    - type: MaxModelsLimitReached\n      status: \"True\"\n      message: \"Model creation limit reached (100 models created). 150 available images not created as models.\"\n</code></pre>"},{"location":"aim/concepts/model-sources/#status","title":"Status","text":"<p>The status field tracks sync progress and discovered models:</p> <pre><code>kubectl get aimclustermodelsource\n</code></pre> <pre><code>NAME             STATUS   MODELS   LASTSYNC             AGE\nsilogen-models   Ready    12       2025-01-15T10:30:00  2d\n</code></pre>"},{"location":"aim/concepts/model-sources/#status-values","title":"Status Values","text":"<ul> <li>Pending: Waiting for initial sync</li> <li>Progressing: Sync in progress</li> <li>Ready: All filters succeeded</li> <li>Degraded: Some filters failed, but others succeeded</li> <li>Failed: All filters failed</li> </ul>"},{"location":"aim/concepts/model-sources/#detailed-status","title":"Detailed Status","text":"<pre><code>kubectl get aimclustermodelsource silogen-models -o yaml\n</code></pre> <p>Key status fields:</p> <ul> <li><code>status</code>: Overall state (Ready, Degraded, Failed, etc.)</li> <li><code>discoveredModels</code>: Count of AIMClusterModel resources created</li> <li><code>availableModels</code>: Total count of images matching filters in registry</li> <li><code>modelsLimitReached</code>: Boolean indicating if maxModels limit was reached</li> <li><code>lastSyncTime</code>: Timestamp of last successful sync</li> <li><code>conditions</code>: Detailed conditions including Ready, Degraded, and MaxModelsLimitReached</li> </ul>"},{"location":"aim/concepts/model-sources/#examples","title":"Examples","text":""},{"location":"aim/concepts/model-sources/#docker-hub-with-wildcards","title":"Docker Hub with Wildcards","text":"<pre><code>apiVersion: aim.silogen.ai/v1alpha1\nkind: AIMClusterModelSource\nmetadata:\n  name: dockerhub-models\nspec:\n  registry: docker.io\n  filters:\n    - image: amdenterpriseai/aim-*\n      exclude:\n        - amdenterpriseai/aim-base\n  syncInterval: 2h\n</code></pre>"},{"location":"aim/concepts/model-sources/#github-container-registry-with-version-constraints","title":"GitHub Container Registry with Version Constraints","text":"<pre><code>apiVersion: aim.silogen.ai/v1alpha1\nkind: AIMClusterModelSource\nmetadata:\n  name: ghcr-stable-models\nspec:\n  registry: ghcr.io\n  filters:\n    - image: silogen/aim-llama\n    - image: silogen/aim-mistral\n  versions:\n    - \"&gt;=1.0.0\"\n    - \"&lt;2.0.0\"\n  syncInterval: 1h\n</code></pre>"},{"location":"aim/concepts/model-sources/#multiple-registries","title":"Multiple Registries","text":"<pre><code>apiVersion: aim.silogen.ai/v1alpha1\nkind: AIMClusterModelSource\nmetadata:\n  name: multi-registry-models\nspec:\n  registry: docker.io  # default\n  filters:\n    - image: amdenterpriseai/aim-*  # uses docker.io\n    - image: ghcr.io/silogen/aim-*  # overrides to ghcr.io\n  syncInterval: 1h\n</code></pre>"},{"location":"aim/concepts/model-sources/#private-registry-with-authentication","title":"Private Registry with Authentication","text":"<pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: private-registry-creds\n  namespace: kaiwo-system\ntype: kubernetes.io/dockerconfigjson\ndata:\n  .dockerconfigjson: BASE64_ENCODED_CONFIG\n---\napiVersion: aim.silogen.ai/v1alpha1\nkind: AIMClusterModelSource\nmetadata:\n  name: private-models\nspec:\n  registry: private.registry.io\n  imagePullSecrets:\n    - name: private-registry-creds\n  filters:\n    - image: myorg/model-*\n      versions:\n        - \"&gt;=1.0.0\"\n  syncInterval: 1h\n</code></pre>"},{"location":"aim/concepts/model-sources/#specific-versions-only","title":"Specific Versions Only","text":"<pre><code>apiVersion: aim.silogen.ai/v1alpha1\nkind: AIMClusterModelSource\nmetadata:\n  name: specific-versions\nspec:\n  registry: ghcr.io\n  filters:\n    - image: silogen/aim-llama:1.0.0\n    - image: silogen/aim-llama:1.1.0\n    - image: silogen/aim-mistral:2.0.0\n  syncInterval: 6h\n</code></pre>"},{"location":"aim/concepts/model-sources/#lifecycle","title":"Lifecycle","text":""},{"location":"aim/concepts/model-sources/#created-models","title":"Created Models","text":"<p>Model sources create AIMClusterModel resources with auto-generated names based on the image URI. These models are owned by the source via an owner reference.</p> <p>Created models have discovery enabled by default and will automatically create service templates if the image includes recommended deployment metadata.</p>"},{"location":"aim/concepts/model-sources/#append-only","title":"Append-Only","text":"<p>Model sources follow an append-only lifecycle during normal operation. Once created, models are never deleted by the source, even if:</p> <ul> <li>The image is removed from the registry</li> <li>The filter is changed or removed</li> </ul> <p>This ensures running services aren't disrupted when registry contents change.</p>"},{"location":"aim/concepts/model-sources/#ownership-and-deletion","title":"Ownership and Deletion","text":"<p>Created models have an owner reference to the source. When you delete the source, Kubernetes will automatically delete all models that were created by it.</p> <p>This cascading deletion happens via Kubernetes garbage collection. To prevent accidentally disrupting running services, consider the impact before deleting a model source.</p> <p>If you need to stop tracking specific models:</p> <ol> <li>Update the source filters to exclude those models</li> <li>Delete the unwanted models manually:</li> </ol> <pre><code>kubectl delete aimclustermodel &lt;model-name&gt;\n</code></pre> <p>Note: You cannot selectively clean up models while keeping the source unchanged - any models matching the active filters will be recreated on the next sync.</p>"},{"location":"aim/concepts/model-sources/#troubleshooting","title":"Troubleshooting","text":""},{"location":"aim/concepts/model-sources/#no-models-discovered","title":"No Models Discovered","text":"<p>Check the source status:</p> <pre><code>kubectl get aimclustermodelsource &lt;name&gt; -o yaml\n</code></pre> <p>Common causes:</p> <ul> <li>No images match the filters</li> <li>Registry is unreachable</li> <li>Authentication failed (check imagePullSecrets)</li> <li>Version constraints too restrictive</li> </ul>"},{"location":"aim/concepts/model-sources/#degraded-status","title":"Degraded Status","text":"<p>Some filters failed while others succeeded. Check conditions:</p> <pre><code>kubectl get aimclustermodelsource &lt;name&gt; -o jsonpath='{.status.conditions}'\n</code></pre> <p>Look for error messages indicating which filters failed and why.</p>"},{"location":"aim/concepts/model-sources/#failed-status","title":"Failed Status","text":"<p>All filters failed. Common causes:</p> <ul> <li>Invalid registry hostname</li> <li>Missing or invalid imagePullSecrets</li> <li>Network connectivity issues</li> <li>Registry catalog API not supported (for wildcard filters)</li> </ul>"},{"location":"aim/concepts/model-sources/#wildcard-filters-not-working","title":"Wildcard Filters Not Working","text":"<p>Wildcard filters require registry catalog API support. In addition, support for GitHub Container Registry (ghcr.io) is added via the user of their REST API.</p>"},{"location":"aim/concepts/model-sources/#related-documentation","title":"Related Documentation","text":"<ul> <li>Models - Understanding AIMClusterModel and AIMModel resources</li> <li>Templates - Auto-generated service templates</li> <li>Runtime Config - Authentication and discovery configuration</li> </ul>"},{"location":"aim/concepts/models/","title":"AIM Models","text":"<p>AIM Model resources form a catalog that maps logical model identifiers to specific container images. This document explains the model resource types, discovery mechanism, and lifecycle.</p>"},{"location":"aim/concepts/models/#overview","title":"Overview","text":"<p>Model resources serve two purposes:</p> <ol> <li>Registry: Translate abstract model references into concrete container images</li> <li>Version control: Update which container serves a model without changing service configurations</li> </ol>"},{"location":"aim/concepts/models/#cluster-vs-namespace-scope","title":"Cluster vs Namespace Scope","text":""},{"location":"aim/concepts/models/#aimclustermodel","title":"AIMClusterModel","text":"<p>Cluster-scoped models are typically installed by administrators through GitOps workflows or Helm charts. They represent curated model catalogs maintained by platform teams or model publishers.</p> <p>Cluster models provide a consistent baseline across all namespaces. Any namespace can reference a cluster model unless it defines a namespace-scoped model with the same name, which takes precedence.</p> <p>Discovery for cluster models runs in the operator namespace (default: <code>kaiwo-system</code>). Auto-generated templates are created as cluster-scoped resources.</p>"},{"location":"aim/concepts/models/#aimmodel","title":"AIMModel","text":"<p>Namespace-scoped models allow teams to:</p> <ul> <li>Define team-specific model variants</li> <li>Override cluster-level definitions for testing</li> <li>Control model access at the namespace level</li> </ul> <p>When both cluster and namespace models exist with the same <code>metadata.name</code>, the namespace resource takes precedence within that namespace.</p> <p>Discovery for namespace models runs in the model's namespace. Auto-generated templates are created as namespace-scoped resources.</p>"},{"location":"aim/concepts/models/#model-specification","title":"Model Specification","text":"<p>An AIM Model uses <code>metadata.name</code> as the canonical model identifier:</p> <pre><code>apiVersion: aim.silogen.ai/v1alpha1\nkind: AIMClusterModel\nmetadata:\n  name: meta-llama-3-8b-instruct\nspec:\n  image: ghcr.io/silogen/aim-meta-llama-llama-3-1-8b-instruct:0.7.0\n  discovery:\n    enabled: true\n    autoCreateTemplates: true\n  resources:\n    limits:\n      cpu: \"8\"\n      memory: 64Gi\n    requests:\n      cpu: \"4\"\n      memory: 32Gi\n</code></pre>"},{"location":"aim/concepts/models/#fields","title":"Fields","text":"Field Purpose <code>image</code> Container image URI implementing this model. The operator inspects this image during discovery. <code>discovery</code> Controls metadata extraction and automatic template generation. Discovery is attempted automatically. <code>discovery.autoCreateTemplates</code> When true (default), creates ServiceTemplates from recommended deployments published by the image. <code>defaultServiceTemplate</code> Default template name to use when services reference this model without specifying a template. Optional. <code>imagePullSecrets</code> Secrets for pulling the container image during discovery and inference. Must exist in the same namespace as the model (or operator namespace for cluster models). <code>serviceAccountName</code> Service account to use for discovery jobs and metadata extraction. If empty, uses the default service account. <code>resources</code> Default resource requirements. These serve as baseline values that templates and services can override."},{"location":"aim/concepts/models/#discovery-mechanism","title":"Discovery Mechanism","text":"<p>Discovery is an automatic process that extracts metadata from container images and creates templates.</p>"},{"location":"aim/concepts/models/#discovery-process","title":"Discovery Process","text":"<p>When discovery is enabled:</p> <ol> <li> <p>Job Creation: The controller creates a Kubernetes Job in the appropriate namespace (operator namespace for cluster images, image namespace for namespace images)</p> </li> <li> <p>Image Inspection: The job pulls the container image using credentials from the referenced runtime config and extracts:</p> <ul> <li>Required model artifact sources (Hugging Face Hub references, etc.)</li> <li>GPU requirements and recommended deployment configurations</li> <li>Runtime metadata from container labels</li> </ul> </li> <li> <p>Metadata Storage: Extracted metadata is written to <code>status.discoveredMetadata</code></p> </li> <li> <p>Template Generation: If <code>autoCreateTemplates: true</code>, the controller examines the image's recommended deployments and creates corresponding ServiceTemplate resources</p> </li> </ol>"},{"location":"aim/concepts/models/#required-labels","title":"Required Labels","text":"<p>AIM discovery expects container images to include specific labels. Official AIM container images include:</p> <ul> <li><code>org.amd.silogen.model.canonicalName</code>: Model identifier</li> <li><code>org.amd.silogen.model.deployments</code>: JSON array of recommended deployment configurations</li> </ul> <p>Missing required labels causes the <code>MetadataExtracted</code> condition to flip to <code>False</code> and marks the model resource <code>Failed</code>.</p>"},{"location":"aim/concepts/models/#lifecycle-and-status","title":"Lifecycle and Status","text":""},{"location":"aim/concepts/models/#status-field","title":"Status Field","text":"<p>The <code>status</code> field tracks discovery progress:</p> Field Description <code>status</code> Enum: <code>Pending</code>, <code>Progressing</code>, <code>Ready</code>, <code>Degraded</code>, <code>Failed</code> <code>conditions</code> Detailed conditions including <code>RuntimeResolved</code> and <code>MetadataExtracted</code> <code>resolvedRuntimeConfig</code> Metadata about the runtime config that was resolved (name, namespace, scope, UID) <code>imageMetadata</code> Extracted metadata from the container image including model and OCI metadata"},{"location":"aim/concepts/models/#status-values","title":"Status Values","text":"<ul> <li>Pending: Initial state, waiting for reconciliation</li> <li>Progressing: Discovery job running or templates being created</li> <li>Ready: Discovery succeeded and all auto-generated templates are healthy</li> <li>Degraded: Discovery succeeded but some templates have issues</li> <li>Failed: Discovery failed or required labels missing</li> </ul>"},{"location":"aim/concepts/models/#conditions","title":"Conditions","text":"<p>RuntimeResolved: Reports whether runtime config resolution succeeded. Reasons:</p> <ul> <li><code>RuntimeResolved</code>: Runtime configuration was successfully resolved</li> <li><code>RuntimeConfigMissing</code>: The explicitly referenced runtime config was not found</li> <li><code>DefaultRuntimeConfigMissing</code>: The implicit default runtime config was not found (warning, allows reconciliation to continue)</li> </ul> <p>MetadataExtracted: Reports whether image inspection succeeded. Reasons:</p> <ul> <li><code>MetadataExtracted</code>: Discovery completed successfully</li> <li><code>MetadataExtractionFailed</code>: Discovery job failed or required labels missing from image</li> </ul>"},{"location":"aim/concepts/models/#toggling-discovery","title":"Toggling Discovery","text":"<p>You can enable discovery after image creation:</p> <pre><code>kubectl edit aimclustermodel meta-llama-3-8b-instruct\n# Set spec.discovery.enabled: true\n</code></pre> <p>The controller runs extraction on the next reconciliation and updates status accordingly.</p> <p>Disabling discovery after templates exist leaves templates in place. The <code>TemplatesAutoGenerated</code> condition remains <code>True</code>.</p>"},{"location":"aim/concepts/models/#resource-resolution","title":"Resource Resolution","text":"<p>When services reference a model, the controller merges resources from multiple sources:</p> <ol> <li>Service-level: <code>AIMService.spec.resources</code> (highest precedence)</li> <li>Template-level: <code>AIMServiceTemplate.spec.resources</code></li> <li>Model-level: <code>AIMModel.spec.resources</code> (baseline)</li> </ol> <p>If GPU quantities remain unset after merging, the controller copies them from discovery metadata recorded on the template (<code>status.profile.metadata.gpu_count</code>).</p>"},{"location":"aim/concepts/models/#model-lookup","title":"Model Lookup","text":"<p>For namespace-scoped lookups (from templates or services in a namespace):</p> <ol> <li>Check for <code>AIMModel</code> in the same namespace</li> <li>Fall back to <code>AIMClusterModel</code> with the same name</li> </ol> <p>This allows namespace models to override cluster baselines.</p>"},{"location":"aim/concepts/models/#examples","title":"Examples","text":""},{"location":"aim/concepts/models/#cluster-model-with-discovery","title":"Cluster Model with Discovery","text":"<pre><code>apiVersion: aim.silogen.ai/v1alpha1\nkind: AIMClusterModel\nmetadata:\n  name: meta-llama-3-8b-instruct\nspec:\n  image: ghcr.io/example/llama-3.1-8b-instruct:v1.2.0\n  runtimeConfigName: platform-default\n  discovery:\n    enabled: true\n    autoCreateTemplates: true\n  resources:\n    limits:\n      cpu: \"8\"\n      memory: 64Gi\n      nvidia.com/gpu: \"1\"\n    requests:\n      cpu: \"4\"\n      memory: 32Gi\n      nvidia.com/gpu: \"1\"\n</code></pre>"},{"location":"aim/concepts/models/#namespace-model-without-discovery","title":"Namespace Model Without Discovery","text":"<pre><code>apiVersion: aim.silogen.ai/v1alpha1\nkind: AIMModel\nmetadata:\n  name: meta-llama-3-8b-dev\n  namespace: ml-team\nspec:\n  image: ghcr.io/ml-team/llama-dev:latest\n  runtimeConfigName: ml-team\n  defaultServiceTemplate: custom-template-name\n  discovery:\n    enabled: false  # skip discovery and auto-templates\n  resources:\n    limits:\n      cpu: \"6\"\n      memory: 48Gi\n</code></pre>"},{"location":"aim/concepts/models/#enabling-discovery-for-private-container-images","title":"Enabling Discovery for Private Container Images","text":"<pre><code># Secret in namespace\napiVersion: v1\nkind: Secret\nmetadata:\n  name: private-registry\n  namespace: ml-team\ntype: kubernetes.io/dockerconfigjson\ndata:\n  .dockerconfigjson: BASE64_CONFIG\n---\n# Runtime config in namespace\napiVersion: aim.silogen.ai/v1alpha1\nkind: AIMRuntimeConfig\nmetadata:\n  name: default\n  namespace: ml-team\nspec:\n  serviceAccountName: aim-runtime\n  imagePullSecrets:\n    - name: private-registry\n---\n# Model with discovery\napiVersion: aim.silogen.ai/v1alpha1\nkind: AIMModel\nmetadata:\n  name: proprietary-model\n  namespace: ml-team\nspec:\n  image: private.registry/models/proprietary:v1\n  runtimeConfigName: default  # uses config above\n  discovery:\n    enabled: true\n</code></pre>"},{"location":"aim/concepts/models/#troubleshooting","title":"Troubleshooting","text":""},{"location":"aim/concepts/models/#discovery-job-fails","title":"Discovery Job Fails","text":"<p>Check the job logs:</p> <pre><code># For cluster images\nkubectl -n kaiwo-system logs -l job-name=&lt;image-name&gt;-discovery\n\n# For namespace images\nkubectl -n &lt;namespace&gt; logs -l job-name=&lt;image-name&gt;-discovery\n</code></pre> <p>Common causes:</p> <ul> <li>Missing or invalid imagePullSecrets</li> <li>Image doesn't exist or tag is invalid</li> <li>Required labels missing from image</li> </ul>"},{"location":"aim/concepts/models/#templates-not-auto-created","title":"Templates Not Auto-Created","text":"<p>Check the model status:</p> <pre><code>kubectl get aimclustermodel &lt;name&gt; -o yaml\n# or\nkubectl -n &lt;namespace&gt; get aimmodel &lt;name&gt; -o yaml\n</code></pre> <p>Look for:</p> <ul> <li><code>discovery.enabled: false</code> - discovery is disabled</li> <li><code>discovery.autoCreateTemplates: false</code> - auto-creation disabled</li> <li><code>TemplatesAutoGenerated</code> condition with reason <code>NoRecommendedTemplates</code></li> </ul>"},{"location":"aim/concepts/models/#metadataextracted-condition-false","title":"MetadataExtracted Condition False","text":"<p>The container image is missing required labels or the discovery job failed. Check:</p> <pre><code>kubectl get aimclustermodel &lt;name&gt; -o jsonpath='{.status.conditions[?(@.type==\"MetadataExtracted\")]}'\n</code></pre> <p>Inspect the container image labels:</p> <pre><code>docker pull &lt;image&gt;\ndocker inspect &lt;image&gt; --format='{{json .Config.Labels}}'\n</code></pre>"},{"location":"aim/concepts/models/#auto-creation-from-services","title":"Auto-Creation from Services","text":"<p>When a service uses <code>spec.model.image</code> directly (instead of <code>spec.model.ref</code>), AIM automatically creates a model resource if one doesn't already exist with that image URI.</p>"},{"location":"aim/concepts/models/#creation-scope","title":"Creation Scope","text":"<p>The runtime config's <code>spec.model.creationScope</code> field controls whether the auto-created model is cluster-scoped or namespace-scoped:</p> <pre><code># In runtime config\nspec:\n  model:\n    creationScope: Cluster  # creates AIMClusterModel\n    # OR\n    creationScope: Namespace  # creates AIMModel in service's namespace\n</code></pre>"},{"location":"aim/concepts/models/#discovery-for-auto-created-models","title":"Discovery for Auto-Created Models","text":"<p>The runtime config's <code>spec.model.autoDiscovery</code> field controls whether auto-created models run discovery:</p> <pre><code>spec:\n  model:\n    autoDiscovery: true  # auto-created models run discovery and create templates\n</code></pre>"},{"location":"aim/concepts/models/#example","title":"Example","text":"<p>Service using direct image reference:</p> <pre><code>apiVersion: aim.silogen.ai/v1alpha1\nkind: AIMService\nmetadata:\n  name: my-service\n  namespace: ml-team\nspec:\n  model:\n    image: ghcr.io/example/my-model:v1.0.0\n  runtimeConfigName: default\n</code></pre> <p>If the runtime config has <code>creationScope: Cluster</code> and <code>autoDiscovery: true</code>, AIM creates:</p> <pre><code>apiVersion: aim.silogen.ai/v1alpha1\nkind: AIMClusterModel\nmetadata:\n  name: auto-&lt;hash-of-image&gt;\nspec:\n  image: ghcr.io/example/my-model:v1.0.0\n  discovery:\n    enabled: true\n    autoCreateTemplates: true\n</code></pre>"},{"location":"aim/concepts/models/#related-documentation","title":"Related Documentation","text":"<ul> <li>Templates - Understanding ServiceTemplates and discovery</li> <li>Runtime Config Concepts - Resolution details including model creation</li> <li>Services Usage - Deploying services</li> </ul>"},{"location":"aim/concepts/models/#note-on-terminology","title":"Note on Terminology","text":"<p>AIM Model resources (<code>AIMModel</code> and <code>AIMClusterModel</code>) define the mapping between model identifiers and container images. While we sometimes refer to the \"model catalog\" conceptually, the Kubernetes resources are always <code>AIMModel</code> and <code>AIMClusterModel</code>.</p>"},{"location":"aim/concepts/runtime-config/","title":"Runtime Configuration Architecture","text":"<p>Runtime configurations provide storage defaults and routing parameters. This document explains the resolution algorithm, inheritance model, and status tracking.</p>"},{"location":"aim/concepts/runtime-config/#resolution-model","title":"Resolution Model","text":"<p>The AIM operator resolves runtime settings from two Custom Resource Definitions:</p> <ul> <li><code>AIMClusterRuntimeConfig</code>: Cluster-wide defaults that apply across namespaces, useful for single-tenant clusters</li> <li><code>AIMRuntimeConfig</code>: Namespace-scoped configuration including authentication secrets, useful for multi-tenant clusters</li> </ul>"},{"location":"aim/concepts/runtime-config/#resolution-algorithm","title":"Resolution Algorithm","text":"<p>When a workload references <code>runtimeConfigName: my-config</code>:</p> <ol> <li>The controller first looks for <code>AIMRuntimeConfig</code> named <code>my-config</code> in the workload's namespace</li> <li>If found, the namespace config is used exclusively</li> <li>If not found, the controller falls back to <code>AIMClusterRuntimeConfig</code> named <code>my-config</code></li> <li>The resolved configuration is published in the consumer's <code>status.effectiveRuntimeConfig</code></li> </ol> <p>When <code>runtimeConfigName</code> is omitted, the controller resolves a config named <code>default</code>. If this is not found, no error is raised. However, if a config that is not named <code>default</code> is specified, it must exist, otherwise an error is raised.</p>"},{"location":"aim/concepts/runtime-config/#effective-runtime-config-tracking","title":"Effective Runtime Config Tracking","text":"<p>The resolved configuration is published in <code>status.effectiveRuntimeConfig</code> with: - Reference to the source object (namespace or cluster scope) - Hash of the spec for change detection</p>"},{"location":"aim/concepts/runtime-config/#namespace-config-status","title":"Namespace Config Status","text":"<pre><code>status:\n  effectiveRuntimeConfig:\n    namespaceRef:\n      kind: AIMRuntimeConfig\n      namespace: ml-team\n      name: default\n      scope: Namespace\n    hash: 792403ad\u2026\n</code></pre>"},{"location":"aim/concepts/runtime-config/#cluster-config-status","title":"Cluster Config Status","text":"<pre><code>status:\n  effectiveRuntimeConfig:\n    clusterRef:\n      kind: AIMClusterRuntimeConfig\n      name: default\n      scope: Cluster\n    hash: 5f8a9b2c\u2026\n</code></pre> <p>Only one ref (namespace or cluster) is present, never both.</p>"},{"location":"aim/concepts/runtime-config/#resources-supporting-runtime-config","title":"Resources Supporting Runtime Config","text":"<p>The following AIM resources accept <code>runtimeConfigName</code>:</p> <ul> <li><code>AIMModel</code> / <code>AIMClusterModel</code></li> <li><code>AIMServiceTemplate</code> / <code>AIMClusterServiceTemplate</code></li> <li><code>AIMService</code></li> <li><code>AIMTemplateCache</code></li> </ul> <p>Each resource independently resolves its runtime config and publishes the result in status.</p>"},{"location":"aim/concepts/runtime-config/#configuration-scoping","title":"Configuration Scoping","text":""},{"location":"aim/concepts/runtime-config/#cluster-runtime-configuration","title":"Cluster Runtime Configuration","text":"<p><code>AIMClusterRuntimeConfig</code> captures non-secret defaults shared across namespaces:</p> <pre><code>apiVersion: aim.silogen.ai/v1alpha1\nkind: AIMClusterRuntimeConfig\nmetadata:\n  name: default\nspec:\n  defaultStorageClassName: fast-nvme\n</code></pre> <p>Use cases: - Platform-wide storage class defaults - Shared routing configurations for clusters without multi-tenancy</p> <p>Limitations: - Cannot enforce namespace-specific policies</p>"},{"location":"aim/concepts/runtime-config/#namespace-runtime-configuration","title":"Namespace Runtime Configuration","text":"<p><code>AIMRuntimeConfig</code> provides namespace-specific configuration including authentication:</p> <pre><code>apiVersion: aim.silogen.ai/v1alpha1\nkind: AIMRuntimeConfig\nmetadata:\n  name: default\n  namespace: ml-team\nspec:\n  defaultStorageClassName: team-ssd\n  routing:\n    enabled: true\n    gatewayRef:\n      name: kserve-gateway\n      namespace: kgateway-system\n    pathTemplate: \"/{.metadata.namespace}/{.metadata.labels['team']}\"\n</code></pre> <p>Use cases: - Namespace-level routing policies - Custom storage classes per team</p>"},{"location":"aim/concepts/runtime-config/#routing-templates","title":"Routing Templates","text":"<p>Runtime configs can supply a reusable HTTP route template via <code>spec.routing.pathTemplate</code>. The template is rendered against the <code>AIMService</code> object using JSONPath expressions.</p>"},{"location":"aim/concepts/runtime-config/#template-syntax","title":"Template Syntax","text":"<pre><code>spec:\n  routing:\n    pathTemplate: \"/{.metadata.namespace}/{.metadata.labels['team']}/{.spec.aimImageName}/\"\n</code></pre>"},{"location":"aim/concepts/runtime-config/#rendering-process","title":"Rendering Process","text":"<p>During reconciliation:</p> <ol> <li>Evaluation: Each placeholder (e.g., <code>{.metadata.namespace}</code>) is evaluated with JSONPath</li> <li>Validation: Missing fields, invalid expressions, or multi-value results fail the render</li> <li>Normalization: Each path segment is:</li> <li>Lowercased</li> <li>RFC 3986 encoded</li> <li>De-duplicated (multiple slashes collapsed)</li> <li>Length Check: Final path must be \u2264 200 characters</li> <li>Trailing Slash: Removed</li> </ol>"},{"location":"aim/concepts/runtime-config/#rendering-failures","title":"Rendering Failures","text":"<p>A rendered path that:</p> <ul> <li>Exceeds 200 characters</li> <li>Contains invalid JSONPath</li> <li>References missing labels/fields</li> </ul> <p>...degrades the <code>AIMService</code> with reason <code>PathTemplateInvalid</code> and skips HTTPRoute creation. The InferenceService remains intact.</p>"},{"location":"aim/concepts/runtime-config/#precedence","title":"Precedence","text":"<p>Services evaluate path templates in this order:</p> <ol> <li><code>AIMService.spec.routing.pathTemplate</code> (highest precedence)</li> <li>Runtime config's <code>spec.routing.pathTemplate</code></li> <li>Default: <code>/&lt;namespace&gt;/&lt;service-uid&gt;</code></li> </ol> <p>This allows:</p> <ul> <li>Runtime configs: Set namespace-wide path conventions</li> <li>Services: Override with specific paths when needed</li> </ul>"},{"location":"aim/concepts/runtime-config/#example","title":"Example","text":"<p>Runtime config with path template:</p> <pre><code>apiVersion: aim.silogen.ai/v1alpha1\nkind: AIMRuntimeConfig\nmetadata:\n  name: default\n  namespace: ml-team\nspec:\n  routing:\n    enabled: true\n    gatewayRef:\n      name: inference-gateway\n      namespace: gateways\n    pathTemplate: \"/ml/{.metadata.namespace}/{.metadata.labels['project']}\"\n</code></pre> <p>Service using template:</p> <pre><code>apiVersion: aim.silogen.ai/v1alpha1\nkind: AIMService\nmetadata:\n  name: llama-chat\n  namespace: ml-team\n  labels:\n    project: conversational-ai\nspec:\n  model:\n    ref: meta-llama-3-8b\n  # routing.pathTemplate omitted - uses runtime config template\n</code></pre> <p>Rendered path: <code>/ml/ml-team/conversational-ai</code></p> <p>Service with override:</p> <pre><code>spec:\n  model:\n    ref: meta-llama-3-8b\n  routing:\n    pathTemplate: \"/custom/{.metadata.name}\"\n</code></pre> <p>Rendered path: <code>/custom/llama-chat</code> (runtime config template ignored)</p>"},{"location":"aim/concepts/runtime-config/#error-and-warning-behavior","title":"Error and Warning Behavior","text":""},{"location":"aim/concepts/runtime-config/#missing-explicit-config","title":"Missing Explicit Config","text":"<p>When a workload explicitly references a non-existent config:</p> <pre><code>spec:\n  runtimeConfigName: non-existent\n</code></pre> <p>Result: - Reconciliation fails - Workload reports <code>ConfigResolved=False</code> (or equivalent failure condition) - Reconciliation retries until the config appears</p>"},{"location":"aim/concepts/runtime-config/#missing-default-config","title":"Missing Default Config","text":"<p>When the implicit <code>default</code> config doesn't exist:</p> <p>Result: - Controller emits event: <code>DefaultRuntimeConfigNotFound</code> - Reconciliation continues without overrides - Workloads relying on private registries fail later unless a namespace config supplies credentials</p> <p>This allows workloads without special requirements to proceed even when no default config exists.</p>"},{"location":"aim/concepts/runtime-config/#label-propagation","title":"Label Propagation","text":"<p>Runtime configurations support automatic label propagation from parent AIM resources to their child Kubernetes resources. This feature helps maintain consistent metadata across the resource hierarchy for tracking, cost allocation, and compliance purposes.</p>"},{"location":"aim/concepts/runtime-config/#configuration","title":"Configuration","text":"<p>Label propagation is configured in the runtime config's <code>labelPropagation</code> section:</p> <pre><code>apiVersion: aim.silogen.ai/v1alpha1\nkind: AIMRuntimeConfig\nmetadata:\n  name: default\n  namespace: ml-team\nspec:\n  labelPropagation:\n    enabled: true\n    match:\n      - \"org.example/cost-center\"\n      - \"org.example/team\"\n      - \"compliance.example/*\"  # Wildcard matches any label with this prefix\n</code></pre>"},{"location":"aim/concepts/runtime-config/#propagation-behavior","title":"Propagation Behavior","text":"<p>When enabled, labels matching the specified patterns are automatically copied from parent resources to child resources:</p> <ul> <li>AIMService \u2192 InferenceService, HTTPRoute, PVCs, auto-created AIMModel</li> <li>AIMTemplateCache \u2192 AIMModelCache resources</li> <li>AIMModelCache \u2192 PVCs, download Jobs</li> <li>AIMModel/AIMClusterModel \u2192 auto-created AIMServiceTemplates</li> <li>AIMServiceTemplate \u2192 AIMTemplateCache</li> <li>AIMClusterModelSource \u2192 auto-created AIMClusterModel resources</li> </ul>"},{"location":"aim/concepts/runtime-config/#pattern-matching","title":"Pattern Matching","text":"<p>The <code>match</code> field accepts exact label keys or wildcard patterns:</p> <ul> <li><code>\"org.example/team\"</code> - Matches exactly this label key</li> <li><code>\"org.example/*\"</code> - Matches any label with the prefix <code>org.example/</code></li> <li><code>\"compliance.*/severity\"</code> - Matches labels like <code>compliance.sec/severity</code>, <code>compliance.audit/severity</code></li> </ul>"},{"location":"aim/concepts/runtime-config/#special-handling","title":"Special Handling","text":"<p>For Job resources, propagated labels are applied to both: 1. The Job's metadata labels 2. The Job's PodTemplateSpec labels (enabling pod-level tracking)</p>"},{"location":"aim/concepts/runtime-config/#example-use-case","title":"Example Use Case","text":"<p>A typical configuration for multi-tenant cost tracking:</p> <pre><code>apiVersion: aim.silogen.ai/v1alpha1\nkind: AIMClusterRuntimeConfig\nmetadata:\n  name: default\nspec:\n  labelPropagation:\n    enabled: true\n    match:\n      - \"org.example/cost-center\"\n      - \"org.example/department\"\n      - \"org.example/project\"\n</code></pre> <p>When users create an AIMService with these labels:</p> <pre><code>apiVersion: aim.silogen.ai/v1alpha1\nkind: AIMService\nmetadata:\n  name: llama-chat\n  namespace: ml-team\n  labels:\n    org.example/cost-center: \"eng-ml\"\n    org.example/department: \"engineering\"\n    org.example/project: \"chatbot-v2\"\nspec:\n  model:\n    ref: meta-llama-3-8b\n</code></pre> <p>The operator propagates these labels to the InferenceService, HTTPRoute, and any PVCs created for the service, enabling cost tracking and chargeback at the infrastructure level.</p>"},{"location":"aim/concepts/runtime-config/#operator-namespace","title":"Operator Namespace","text":"<p>The AIM controllers determine the operator namespace from the <code>AIM_OPERATOR_NAMESPACE</code> environment variable (default: <code>kaiwo-system</code>).</p> <p>Cluster-scoped workflows such as: - Cluster template discovery - Cluster image inspection - Auto-generated cluster templates</p> <p>...run auxiliary pods in this namespace and resolve namespaced runtime configs there.</p>"},{"location":"aim/concepts/runtime-config/#related-documentation","title":"Related Documentation","text":"<ul> <li>Models - How models use runtime configs for discovery and auto-creation</li> <li>Templates - Template discovery and runtime config resolution</li> <li>Services Usage - Practical service configuration</li> </ul>"},{"location":"aim/concepts/templates/","title":"Service Templates","text":"<p>Service Templates define runtime configurations for models and serve as a discovery cache. This document explains the template architecture, discovery mechanism, derivation algorithm, and lifecycle management.</p>"},{"location":"aim/concepts/templates/#overview","title":"Overview","text":"<p>Templates fulfill two roles:</p> <ol> <li>Runtime Configuration: Define optimization goals (latency vs throughput), numeric precision, and GPU requirements</li> <li>Discovery Cache: Store model artifact metadata to avoid repeated discovery operations</li> </ol> <p>The discovery cache function is critical. When a template is created, the operator inspects the container to determine which model artifacts must be downloaded. This information is stored in <code>status.modelSources[]</code> and reused by services and caching mechanisms.</p>"},{"location":"aim/concepts/templates/#cluster-vs-namespace-scope","title":"Cluster vs Namespace Scope","text":""},{"location":"aim/concepts/templates/#aimclusterservicetemplate","title":"AIMClusterServiceTemplate","text":"<p>Cluster-scoped templates are typically installed by administrators as part of model catalog bundles. They arrive through GitOps workflows, Helm installations, or operator bundles.</p> <p>Key characteristics:</p> <ul> <li>Cannot enable caching directly (caching is namespace-specific)</li> <li>Can be cached into namespaces using <code>AIMTemplateCache</code> resources</li> <li>Discovery runs in the operator namespace (default: <code>kaiwo-system</code>)</li> <li>Provide baseline runtime profiles maintained by platform teams</li> </ul>"},{"location":"aim/concepts/templates/#aimservicetemplate","title":"AIMServiceTemplate","text":"<p>Namespace-scoped templates are created by ML engineers and data scientists for custom runtime profiles.</p> <p>Key characteristics:</p> <ul> <li>Can enable model caching via <code>spec.caching.enabled</code></li> <li>Support namespace-specific secrets and authentication</li> <li>Discovery runs in the template's namespace</li> <li>Allow teams to customize configurations beyond cluster baselines</li> </ul>"},{"location":"aim/concepts/templates/#template-specification","title":"Template Specification","text":"<pre><code>apiVersion: aim.silogen.ai/v1alpha1\nkind: AIMServiceTemplate\nmetadata:\n  name: llama-3-8b-throughput\n  namespace: ml-research\nspec:\n  modelName: meta-llama-3-8b-instruct\n  runtimeConfigName: ml-research\n  metric: throughput\n  precision: fp8\n  gpuSelector:\n    count: 2\n    model: MI300X\n  env:\n    - name: HF_TOKEN\n      valueFrom:\n        secretKeyRef:\n          name: huggingface-creds\n          key: token\n  imagePullSecrets:\n    - name: registry-credentials\n</code></pre>"},{"location":"aim/concepts/templates/#common-fields","title":"Common Fields","text":"Field Description <code>modelName</code> Model identifier referencing an <code>AIMModel</code> or <code>AIMClusterModel</code> by <code>metadata.name</code>. Immutable after creation. <code>runtimeConfigName</code> Runtime configuration for storage defaults and discovery settings. Defaults to <code>default</code>. <code>metric</code> Optimization goal: <code>latency</code> (interactive) or <code>throughput</code> (batch processing). Immutable after creation. <code>precision</code> Numeric precision: <code>auto</code>, <code>fp4</code>, <code>fp8</code>, <code>fp16</code>, <code>fp32</code>, <code>bf16</code>, <code>int4</code>, <code>int8</code>. Immutable after creation. <code>gpuSelector.count</code> Number of GPUs per replica. Immutable after creation. <code>gpuSelector.model</code> GPU type (e.g., <code>MI300X</code>, <code>MI325X</code>). Immutable after creation. <code>imagePullSecrets</code> Secrets for pulling container images during discovery and inference. Must exist in the same namespace (or operator namespace for cluster templates). <code>serviceAccountName</code> Service account for discovery jobs and inference pods. If empty, uses the default service account. <code>resources</code> Container resource requirements. These override model defaults. <code>modelSources</code> Static model sources (optional). When provided, discovery is skipped and these sources are used directly. See Static Model Sources below."},{"location":"aim/concepts/templates/#namespace-specific-fields","title":"Namespace-Specific Fields","text":"Field Description <code>env</code> Environment variables for model downloads (typically authentication tokens). <code>caching</code> Caching configuration for namespace-scoped templates. When enabled, models are cached on startup."},{"location":"aim/concepts/templates/#discovery-as-cache","title":"Discovery as Cache","text":""},{"location":"aim/concepts/templates/#discovery-process","title":"Discovery Process","text":"<p>When a template is created or its spec changes:</p> <ol> <li> <p>Job Creation: The controller creates a Kubernetes Job using the container image referenced by <code>modelName</code> (resolved via <code>AIMModel</code> or <code>AIMClusterModel</code>)</p> </li> <li> <p>Dry-Run Inspection: The job runs the container in dry-run mode, examining model requirements without downloading large files</p> </li> <li> <p>Metadata Extraction: The job outputs:</p> <ul> <li>Model source URIs (often Hugging Face Hub references)</li> <li>Expected sizes in bytes</li> <li>Engine arguments and environment variables</li> </ul> </li> <li> <p>Status Update: Discovered information is written to <code>status.modelSources[]</code> and <code>status.profile</code></p> </li> </ol> <p>Discovery completes in seconds. The cached metadata remains available for all services referencing this template.</p>"},{"location":"aim/concepts/templates/#discovery-location","title":"Discovery Location","text":"<ul> <li>Cluster templates: Discovery runs in the operator namespace (default: <code>kaiwo-system</code>)</li> <li>Namespace templates: Discovery runs in the template's namespace</li> </ul> <p>This allows namespace templates to access namespace-specific secrets during discovery.</p>"},{"location":"aim/concepts/templates/#model-sources","title":"Model Sources","text":"<p>The <code>status.modelSources[]</code> array is the primary discovery output:</p> <pre><code>status:\n  modelSources:\n    - name: meta-llama/Llama-3.1-8B-Instruct\n      source: hf://meta-llama/Llama-3.1-8B-Instruct\n      sizeBytes: 17179869184\n    - name: tokenizer\n      source: hf://meta-llama/Llama-3.1-8B-Instruct/tokenizer.json\n      sizeBytes: 2097152\n</code></pre> <p>Services reference this array when determining runtime requirements.</p>"},{"location":"aim/concepts/templates/#static-model-sources","title":"Static Model Sources","text":"<p>Templates can optionally provide static model sources in <code>spec.modelSources</code> instead of relying on discovery. When static sources are provided:</p> <ol> <li>Discovery is skipped: No discovery job is created</li> <li>Sources are used directly: The provided sources are copied to <code>status.modelSources[]</code></li> <li>Faster startup: Templates become <code>Ready</code> immediately without waiting for discovery</li> <li>Manual maintenance: Sources must be updated manually when the model changes</li> </ol> <p>This is useful when:</p> <ul> <li>Discovery is not available or not needed</li> <li>Model sources are already known and stable</li> <li>You want to avoid the discovery job overhead</li> <li>Working with custom or non-standard container images</li> </ul> <p>Example with static sources:</p> <pre><code>apiVersion: aim.silogen.ai/v1alpha1\nkind: AIMServiceTemplate\nmetadata:\n  name: llama-3-8b-static\n  namespace: ml-research\nspec:\n  modelName: meta-llama-3-8b-instruct\n  metric: latency\n  precision: fp16\n  gpuSelector:\n    count: 1\n    model: MI300X\n  modelSources:\n    - name: meta-llama/Llama-3.1-8B-Instruct\n      sourceURI: hf://meta-llama/Llama-3.1-8B-Instruct\n      size: 16Gi\n    - name: tokenizer\n      sourceURI: hf://meta-llama/Llama-3.1-8B-Instruct/tokenizer.json\n      size: 2Mi\n</code></pre> <p>When <code>spec.modelSources</code> is provided, the template moves directly to <code>Ready</code> status without running a discovery job.</p>"},{"location":"aim/concepts/templates/#discovery-job-limits","title":"Discovery Job Limits","text":"<p>The AIM operator enforces a global limit of 10 concurrent discovery jobs across the entire cluster. This prevents resource exhaustion when many templates are created simultaneously.</p> <p>When this limit is reached:</p> <ul> <li>New templates wait in <code>Pending</code> status with reason <code>AwaitingDiscovery</code></li> <li>Discovery jobs are queued and run as existing jobs complete</li> <li>Services referencing waiting templates remain in <code>Starting</code> status</li> </ul> <p>To avoid delays:</p> <ul> <li>Use static model sources when discovery is not needed</li> <li>Stagger template creation when deploying many models at once</li> <li>Consider whether cluster-scoped templates can be shared across namespaces</li> </ul>"},{"location":"aim/concepts/templates/#template-derivation","title":"Template Derivation","text":"<p>Services can specify runtime overrides without creating explicit templates. The controller automatically derives namespace-scoped templates incorporating these overrides.</p>"},{"location":"aim/concepts/templates/#derivation-algorithm","title":"Derivation Algorithm","text":"<p>When <code>AIMService.spec.overrides</code> is specified:</p> <ol> <li> <p>Base Template Resolution: The controller resolves the base template using automatic selection or explicit <code>templateRef</code></p> </li> <li> <p>Hash Computation: A SHA256 hash is computed from the override structure (metric, precision, gpuSelector) to ensure deterministic naming</p> </li> <li> <p>Name Generation: The derived name is <code>&lt;base-template&gt;-ovr-&lt;hash-suffix&gt;</code>, truncated to fit Kubernetes 63-character limit</p> </li> <li> <p>Template Search: The controller searches for an existing template (namespace or cluster scope) matching the derived spec</p> </li> <li> <p>Creation: If no match exists, a new namespace-scoped template is created with:</p> </li> <li>Labels:<ul> <li><code>app.kubernetes.io/managed-by: aim</code></li> <li><code>aim.silogen.ai/derived-template: \"true\"</code></li> </ul> </li> <li>Ownership: The service owns the derived template (OwnerReference set)</li> <li> <p>Cascade Deletion: Deleting the service automatically deletes the derived template</p> </li> <li> <p>Discovery: The derived template undergoes discovery like any other template</p> </li> <li> <p>Sharing: Multiple services with identical overrides share the same derived template (the hash ensures they generate the same name)</p> </li> </ol> <p>Important notes: - Derived templates are always created in the service's namespace, even if the base template is cluster-scoped - The <code>aim.silogen.ai/derived-template: \"true\"</code> label distinguishes auto-created templates from manually created ones - Deterministic SHA256 naming prevents duplicate templates and enables template reuse across reconciliations - Services can reference derived templates by name after they're created, but this is not recommended as names may change</p>"},{"location":"aim/concepts/templates/#example","title":"Example","text":"<p>Service with overrides:</p> <pre><code>apiVersion: aim.silogen.ai/v1alpha1\nkind: AIMService\nmetadata:\n  name: chat-service\n  namespace: ml-team\nspec:\n  model:\n    ref: meta-llama-3-8b\n  templateRef: base-template\n  overrides:\n    metric: throughput\n    precision: fp16\n</code></pre> <p>Derived template created:</p> <pre><code>apiVersion: aim.silogen.ai/v1alpha1\nkind: AIMServiceTemplate\nmetadata:\n  name: base-template-ovr-8fa3c921\n  namespace: ml-team\n  labels:\n    app.kubernetes.io/managed-by: aim\n    aim.silogen.ai/derived-template: \"true\"\nspec:\n  modelName: meta-llama-3-8b\n  metric: throughput     # from override\n  precision: fp16        # from override\n  # other fields copied from base template\n</code></pre>"},{"location":"aim/concepts/templates/#template-status","title":"Template Status","text":""},{"location":"aim/concepts/templates/#status-fields","title":"Status Fields","text":"Field Type Description <code>observedGeneration</code> int64 Most recent generation observed <code>status</code> enum <code>Pending</code>, <code>Progressing</code>, <code>NotAvailable</code>, <code>Ready</code>, <code>Degraded</code>, <code>Failed</code> <code>conditions</code> []Condition Detailed conditions: <code>Discovered</code>, <code>CacheWarm</code>, <code>Ready</code>, <code>Progressing</code>, <code>Failure</code> <code>resolvedRuntimeConfig</code> object Metadata about the runtime config that was resolved (name, namespace, scope, UID) <code>resolvedImage</code> object Metadata about the model image that was resolved (name, namespace, scope, UID) <code>modelSources</code> []ModelSource Discovered or static model artifacts with URIs and sizes <code>profile</code> JSON Complete discovery result with engine arguments and metadata"},{"location":"aim/concepts/templates/#status-lifecycle","title":"Status Lifecycle","text":"<ul> <li>Pending: Template created, discovery not yet started</li> <li>Progressing: Discovery job running or cache warming in progress</li> <li>NotAvailable: Template cannot run because required GPU resources are not present in the cluster</li> <li>Ready: Discovery succeeded (or static sources provided), template ready for use</li> <li>Degraded: Template is partially functional but has issues</li> <li>Failed: Discovery encountered terminal errors</li> </ul> <p>Services wait for templates to reach <code>Ready</code> before deploying.</p>"},{"location":"aim/concepts/templates/#conditions","title":"Conditions","text":"<p>Discovered: Reports discovery status. Reasons:</p> <ul> <li><code>ProfilesDiscovered</code>: Discovery completed successfully and runtime profiles were extracted</li> <li><code>AwaitingDiscovery</code>: Discovery job has been created and is waiting to run</li> <li><code>DiscoveryFailed</code>: Discovery job failed (check job logs for details)</li> </ul> <p>CacheWarm: Reports caching status (namespace-scoped templates only). Reasons:</p> <ul> <li><code>Warm</code>: All model sources have been cached successfully</li> <li><code>WarmRequested</code>: Caching has been enabled but not yet started</li> <li><code>Warming</code>: Cache warming is in progress</li> <li><code>WarmFailed</code>: Cache warming failed</li> </ul> <p>Ready: Reports overall readiness</p> <ul> <li><code>True</code> when template is ready for use (discovered and, if requested, cache warmed)</li> <li><code>False</code> during discovery, cache warming, or after failures</li> </ul> <p>Progressing: Indicates active reconciliation</p> <ul> <li><code>True</code> when the controller is actively processing discovery or cache operations</li> <li><code>False</code> when template has reached a stable state</li> </ul> <p>Failure: Reports terminal failures</p> <ul> <li><code>True</code> when an unrecoverable error has occurred</li> <li>Includes detailed reason and message</li> </ul>"},{"location":"aim/concepts/templates/#auto-creation-from-model-discovery","title":"Auto-Creation from Model Discovery","text":"<p>When AIM Models have <code>spec.discovery.enabled: true</code> and <code>spec.discovery.autoCreateTemplates: true</code>, the controller creates templates from the model's recommended deployments.</p> <p>These auto-created templates:</p> <ul> <li>Use naming from the recommended deployment metadata</li> <li>Include preset metric, precision, and GPU requirements</li> <li>Undergo discovery like manually created templates</li> <li>Are managed by the model controller</li> </ul>"},{"location":"aim/concepts/templates/#template-selection","title":"Template Selection","text":"<p>When <code>AIMService.spec.templateRef</code> is omitted, the controller automatically selects a template:</p> <ol> <li>Enumeration: Find all templates referencing the model (either by <code>spec.model.ref</code> or matching the auto-created model from <code>spec.model.image</code>)</li> <li>Filtering: Exclude templates not in <code>Ready</code> status</li> <li>GPU Filtering: Exclude templates requiring GPUs not present in the cluster</li> <li>Override Matching: If service specifies overrides, filter by matching metric/precision/GPU selector</li> <li>Selection: If exactly one candidate remains, select it</li> </ol> <p>If zero or multiple candidates remain, the service reports a failure condition explaining the issue.</p>"},{"location":"aim/concepts/templates/#examples","title":"Examples","text":""},{"location":"aim/concepts/templates/#cluster-template-latency-optimized","title":"Cluster Template - Latency Optimized","text":"<pre><code>apiVersion: aim.silogen.ai/v1alpha1\nkind: AIMClusterServiceTemplate\nmetadata:\n  name: llama-3-8b-latency\nspec:\n  modelName: meta-llama-3-8b-instruct\n  runtimeConfigName: platform-default\n  metric: latency\n  precision: fp16\n  gpuSelector:\n    count: 1\n    model: MI300X\n</code></pre>"},{"location":"aim/concepts/templates/#namespace-template","title":"Namespace Template","text":"<pre><code>apiVersion: aim.silogen.ai/v1alpha1\nkind: AIMServiceTemplate\nmetadata:\n  name: llama-3-8b-throughput\n  namespace: ml-research\nspec:\n  modelName: meta-llama-3-8b-instruct\n  runtimeConfigName: ml-research\n  metric: throughput\n  precision: fp8\n  gpuSelector:\n    count: 2\n    model: MI300X\n  env:\n    - name: HF_TOKEN\n      valueFrom:\n        secretKeyRef:\n          name: hf-creds\n          key: token\n</code></pre>"},{"location":"aim/concepts/templates/#derived-template-from-service-override","title":"Derived Template from Service Override","text":"<p>Service:</p> <pre><code>spec:\n  model:\n    ref: meta-llama-3-8b\n  overrides:\n    metric: throughput\n    gpuSelector:\n      count: 4\n      model: MI325X\n</code></pre> <p>Auto-created derived template (conceptual):</p> <pre><code>apiVersion: aim.silogen.ai/v1alpha1\nkind: AIMServiceTemplate\nmetadata:\n  name: &lt;base&gt;-ovr-a1b2c3d4\n  namespace: ml-team\n  labels:\n    aim.silogen.ai/derived-template: \"true\"\nspec:\n  modelName: meta-llama-3-8b\n  metric: throughput\n  gpuSelector:\n    count: 4\n    model: MI325X\n</code></pre>"},{"location":"aim/concepts/templates/#troubleshooting","title":"Troubleshooting","text":""},{"location":"aim/concepts/templates/#template-stuck-in-progressing","title":"Template Stuck in Progressing","text":"<p>Check discovery job status:</p> <pre><code># Cluster template\nkubectl -n kaiwo-system get job -l aim.silogen.ai/template=&lt;template-name&gt;\n\n# Namespace template\nkubectl -n &lt;namespace&gt; get job -l aim.silogen.ai/template=&lt;template-name&gt;\n</code></pre> <p>View job logs:</p> <pre><code>kubectl -n &lt;namespace&gt; logs job/&lt;job-name&gt;\n</code></pre> <p>Common issues:</p> <ul> <li>Image pull failures (missing/invalid imagePullSecrets)</li> <li>Container crashes during dry-run</li> <li>Runtime config missing</li> </ul>"},{"location":"aim/concepts/templates/#modelsources-empty-after-discovery","title":"ModelSources Empty After Discovery","text":"<p>Check the template status conditions:</p> <pre><code>kubectl -n &lt;namespace&gt; get aimservicetemplate &lt;name&gt; -o jsonpath='{.status.conditions[?(@.type==\"Discovered\")]}'\n</code></pre> <p>The container image may not be a valid AIM container image or may not publish model sources correctly.</p>"},{"location":"aim/concepts/templates/#derived-templates-not-created","title":"Derived Templates Not Created","text":"<p>Check service status:</p> <pre><code>kubectl -n &lt;namespace&gt; get aimservice &lt;name&gt; -o yaml\n</code></pre> <p>Look for:</p> <ul> <li>Failure conditions explaining why derivation failed</li> <li><code>resolvedTemplate</code> showing which template was selected</li> </ul> <p>Ensure the base template exists and is available.</p>"},{"location":"aim/concepts/templates/#related-documentation","title":"Related Documentation","text":"<ul> <li>Models - Understanding the model catalog and discovery</li> <li>Runtime Config Concepts - Resolution algorithm</li> <li>Model Caching - Cache lifecycle and deletion behavior</li> <li>Services Usage - Deploying services with templates</li> </ul>"},{"location":"aim/usage/kv-cache/","title":"Using KV Cache","text":"<p>This guide shows how to configure and use KV cache with your inference services.</p>"},{"location":"aim/usage/kv-cache/#quick-start","title":"Quick Start","text":"<p>The simplest way to enable KV cache is to let the <code>AIMService</code> create one automatically:</p> <pre><code>apiVersion: aim.silogen.ai/v1alpha1\nkind: AIMService\nmetadata:\n  name: llama-chat\n  namespace: ml-team\nspec:\n  model:\n    image: ghcr.io/silogen/aim-meta-llama-llama-3-1-8b-instruct:0.7.0\n  kvCache:\n    type: redis  # Automatically creates 'kvcache-llama-chat'\n</code></pre> <p>This creates an <code>AIMKVCache</code> resource with default settings (1Gi storage, default storage class, Redis backend).</p>"},{"location":"aim/usage/kv-cache/#configuration-options","title":"Configuration Options","text":""},{"location":"aim/usage/kv-cache/#custom-storage-size","title":"Custom Storage Size","text":"<p>Specify storage size based on your model and workload:</p> <pre><code>spec:\n  model:\n    image: ghcr.io/silogen/aim-meta-llama-llama-3-1-70b-instruct:0.7.0\n  kvCache:\n    type: redis\n    storage:\n      size: 100Gi  # Larger model needs more cache storage\n</code></pre>"},{"location":"aim/usage/kv-cache/#custom-storage-class","title":"Custom Storage Class","text":"<p>Use a specific storage class for better performance:</p> <pre><code>spec:\n  model:\n    image: ghcr.io/silogen/aim-meta-llama-llama-3-1-8b-instruct:0.7.0\n  kvCache:\n    type: redis\n    storage:\n      size: 50Gi\n      storageClassName: fast-ssd  # Use your high-performance storage class\n</code></pre>"},{"location":"aim/usage/kv-cache/#custom-access-modes","title":"Custom Access Modes","text":"<p>Specify persistent volume access modes (defaults to ReadWriteOnce):</p> <pre><code>spec:\n  model:\n    image: ghcr.io/silogen/aim-meta-llama-llama-3-1-8b-instruct:0.7.0\n  kvCache:\n    type: redis\n    storage:\n      size: 50Gi\n      accessModes:\n        - ReadWriteOnce\n</code></pre>"},{"location":"aim/usage/kv-cache/#sharing-kv-cache","title":"Sharing KV Cache","text":"<p>Multiple services can share a single KV cache for better resource utilization.</p>"},{"location":"aim/usage/kv-cache/#step-1-create-a-standalone-kv-cache","title":"Step 1: Create a Standalone KV Cache","text":"<pre><code>apiVersion: aim.silogen.ai/v1alpha1\nkind: AIMKVCache\nmetadata:\n  name: shared-cache\n  namespace: ml-team\nspec:\n  kvCacheType: redis\n  storage:\n    size: 200Gi\n    storageClassName: fast-ssd\n</code></pre>"},{"location":"aim/usage/kv-cache/#step-2-reference-from-multiple-services","title":"Step 2: Reference from Multiple Services","text":"<pre><code>---\napiVersion: aim.silogen.ai/v1alpha1\nkind: AIMService\nmetadata:\n  name: llama-chat\n  namespace: ml-team\nspec:\n  model:\n    image: ghcr.io/silogen/aim-meta-llama-llama-3-1-8b-instruct:0.7.0\n  kvCache:\n    name: shared-cache  # References existing cache\n---\napiVersion: aim.silogen.ai/v1alpha1\nkind: AIMService\nmetadata:\n  name: llama-completion\n  namespace: ml-team\nspec:\n  model:\n    image: ghcr.io/silogen/aim-meta-llama-llama-3-1-8b-instruct:0.7.0\n  kvCache:\n    name: shared-cache  # Same cache, shared across services\n</code></pre>"},{"location":"aim/usage/kv-cache/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"aim/usage/kv-cache/#custom-lmcache-configuration","title":"Custom LMCache Configuration","text":"<p>By default, Kaiwo generates a standard LMCache configuration file for your service. For advanced use cases, you can provide a custom LMCache configuration by specifying the <code>lmCacheConfig</code> field. This allows you to fine-tune caching behavior, serialization methods, and other LMCache-specific settings.</p>"},{"location":"aim/usage/kv-cache/#using-the-service_url-placeholder","title":"Using the {SERVICE_URL} Placeholder","text":"<p>When specifying a custom configuration, you should use the <code>{SERVICE_URL}</code> placeholder for the <code>remote_url</code> field instead of hardcoding the cache endpoint. Kaiwo will automatically replace this placeholder with the actual KV cache service URL at runtime.</p> <p>Example with custom configuration:</p> <pre><code>apiVersion: aim.silogen.ai/v1alpha1\nkind: AIMService\nmetadata:\n  name: llama-chat\n  namespace: ml-team\nspec:\n  model:\n    image: ghcr.io/silogen/aim-meta-llama-llama-3-1-8b-instruct:0.7.0\n  kvCache:\n    type: redis\n    storage:\n      size: 50Gi\n    lmCacheConfig: |\n      local_cpu: true\n      chunk_size: 256\n      max_local_cpu_size: 2.0\n      remote_url: \"{SERVICE_URL}\"\n      remote_serde: \"cachegen\"\n</code></pre> <p>The <code>{SERVICE_URL}</code> placeholder will be automatically replaced with the actual Redis service URL (e.g., <code>redis://kvcache-llama-chat-redis-svc:6379</code>).</p>"},{"location":"aim/usage/kv-cache/#configuration-options_1","title":"Configuration Options","text":"<p>Common LMCache configuration options include:</p> Field Type Description Default <code>local_cpu</code> boolean Enable local CPU RAM cache for fast access <code>true</code> <code>chunk_size</code> integer Size of cache chunks in tokens <code>50</code> <code>max_local_cpu_size</code> float Maximum size (GB) for local CPU cache <code>1.0</code> <code>remote_url</code> string URL of the remote cache backend (use <code>{SERVICE_URL}</code>) - <code>remote_serde</code> string Serialization method: <code>\"naive\"</code> or <code>\"cachegen\"</code> <code>\"naive\"</code> <code>pipelined_backend</code> boolean Enable pipelined backend for better performance <code>false</code> <code>save_decode_cache</code> boolean Whether to cache decode phase KV pairs <code>false</code>"},{"location":"aim/usage/kv-cache/#default-configuration","title":"Default Configuration","text":"<p>When <code>lmCacheConfig</code> is not specified, the following default configuration is used:</p> <pre><code>local_cpu: true\nchunk_size: 50\nmax_local_cpu_size: 1.0\nremote_url: \"{SERVICE_URL}\"  # Automatically filled in\nremote_serde: \"naive\"\n</code></pre>"},{"location":"aim/usage/kv-cache/#optimized-configuration-example","title":"Optimized Configuration Example","text":"<p>For high-throughput workloads, you might want to increase chunk size and local cache:</p> <pre><code>spec:\n  model:\n    image: ghcr.io/silogen/aim-meta-llama-llama-3-1-70b-instruct:0.7.0\n  kvCache:\n    type: redis\n    storage:\n      size: 100Gi\n    lmCacheConfig: |\n      local_cpu: true\n      chunk_size: 256\n      max_local_cpu_size: 5.0\n      remote_url: \"{SERVICE_URL}\"\n      remote_serde: \"cachegen\"\n</code></pre> <p>Key tuning considerations:</p> <ul> <li><code>chunk_size</code>: Larger chunks (256) can improve cache hit rates for longer prompts but use more memory</li> <li><code>max_local_cpu_size</code>: Increase for better local cache hit rates (monitor actual usage)</li> <li><code>remote_serde</code>: Use <code>\"cachegen\"</code> for better compression and network efficiency</li> </ul>"},{"location":"aim/usage/kv-cache/#complete-working-example","title":"Complete Working Example","text":"<p>For a complete working example with test assertions, see the custom-lmcache-config test which demonstrates:</p> <ul> <li>Using the <code>{SERVICE_URL}</code> placeholder in a custom configuration</li> <li>Verification that the placeholder is correctly replaced with the actual Redis service URL</li> <li>Custom LMCache settings including <code>chunk_size</code>, <code>remote_serde</code></li> </ul>"},{"location":"aim/usage/kv-cache/#storage-sizing-guide","title":"Storage Sizing Guide","text":"<p>Choose storage size based on your model and expected usage:</p>"},{"location":"aim/usage/kv-cache/#small-models-7b-parameters","title":"Small Models (&lt; 7B parameters)","text":"<pre><code>kvCache:\n  type: redis\n  storage:\n    size: 10Gi  # Sufficient for most workloads\n</code></pre> <p>Use cases: Chat, simple completion, low-to-medium traffic</p>"},{"location":"aim/usage/kv-cache/#medium-models-7b-70b-parameters","title":"Medium Models (7B - 70B parameters)","text":"<pre><code>kvCache:\n  type: redis\n  storage:\n    size: 50Gi  # Balanced for typical usage\n</code></pre> <p>Use cases: Production chat, RAG applications, moderate traffic</p>"},{"location":"aim/usage/kv-cache/#large-models-70b-parameters","title":"Large Models (&gt; 70B parameters)","text":"<pre><code>kvCache:\n  type: redis\n  storage:\n    size: 100Gi  # Start here and scale up as needed\n</code></pre> <p>Use cases: High-volume production, long contexts, batch processing</p>"},{"location":"aim/usage/kv-cache/#calculating-size","title":"Calculating Size","text":"<p>For more precise sizing, use this formula:</p> <pre><code>Storage (GB) \u2248 Model_Size (B) \u00d7 Context_Length (tokens) \u00d7 Batch_Size \u00d7 0.001\n</code></pre> <p>Example for Llama 70B with 4K context and batch size 8: <pre><code>70 \u00d7 4000 \u00d7 8 \u00d7 0.001 = 2,240 MB \u2248 3 GB (minimum)\n</code></pre></p> <p>Add overhead and growth buffer: 3 GB \u00d7 20 = 60 GB recommended</p>"},{"location":"aim/usage/kv-cache/#monitoring-and-management","title":"Monitoring and Management","text":""},{"location":"aim/usage/kv-cache/#check-kv-cache-status","title":"Check KV Cache Status","text":"<pre><code>kubectl get aimkvcache -n ml-team\n</code></pre> <p>Output: <pre><code>NAME              TYPE    STATUS   READY   AGE\nkvcache-llama     redis   Ready    1       5m\nshared-cache      redis   Ready    1       10m\n</code></pre></p> <p>For more details including endpoint information: <pre><code>kubectl get aimkvcache -n ml-team -o wide\n</code></pre></p> <p>Output: <pre><code>NAME              TYPE    STATUS   READY   ENDPOINT                         AGE\nkvcache-llama     redis   Ready    1       redis://kvcache-llama-svc:6379   5m\nshared-cache      redis   Ready    1       redis://shared-cache-svc:6379    10m\n</code></pre></p>"},{"location":"aim/usage/kv-cache/#view-detailed-status","title":"View Detailed Status","text":"<pre><code>kubectl describe aimkvcache kvcache-llama -n ml-team\n</code></pre> <p>This shows additional information including: - Ready replicas (e.g., \"1/1\") - Storage size allocated - Connection endpoint - Recent conditions and events - Last error (if any)</p>"},{"location":"aim/usage/kv-cache/#check-storage-usage","title":"Check Storage Usage","text":"<pre><code>kubectl get pvc -n ml-team -l app.kubernetes.io/managed-by=aimkvcache-controller\n</code></pre>"},{"location":"aim/usage/kv-cache/#view-backend-logs","title":"View Backend Logs","text":"<pre><code># Get the StatefulSet name from the AIMKVCache status\nkubectl logs -n ml-team kvcache-llama-statefulset-0\n</code></pre>"},{"location":"aim/usage/kv-cache/#troubleshooting","title":"Troubleshooting","text":""},{"location":"aim/usage/kv-cache/#kv-cache-stuck-in-progressing","title":"KV Cache Stuck in Progressing","text":"<p>Check if the StatefulSet pod is running:</p> <pre><code>kubectl get pods -n ml-team -l app.kubernetes.io/name=aimkvcache\n</code></pre> <p>Check for storage issues:</p> <pre><code>kubectl describe pvc -n ml-team\n</code></pre> <p>Common causes: - No default storage class configured - Insufficient storage quota - Storage class not available</p>"},{"location":"aim/usage/kv-cache/#kv-cache-status-failed","title":"KV Cache Status Failed","text":"<p>View the conditions for error details:</p> <pre><code>kubectl get aimkvcache kvcache-llama -n ml-team -o jsonpath='{.status.conditions}'\n</code></pre> <p>Check StatefulSet events:</p> <pre><code>kubectl describe statefulset -n ml-team kvcache-llama-statefulset\n</code></pre>"},{"location":"aim/usage/kv-cache/#service-cant-connect-to-kv-cache","title":"Service Can't Connect to KV Cache","text":"<p>Verify the service endpoint:</p> <pre><code>kubectl get svc -n ml-team -l app.kubernetes.io/name=aimkvcache\n</code></pre> <p>Check AIMService status for KVCache readiness:</p> <pre><code>kubectl get aimservice llama-chat -n ml-team -o jsonpath='{.status.conditions[?(@.type==\"KVCacheReady\")]}'\n</code></pre>"},{"location":"aim/usage/kv-cache/#best-practices","title":"Best Practices","text":""},{"location":"aim/usage/kv-cache/#1-use-shared-caches-for-related-services","title":"1. Use Shared Caches for Related Services","text":"<p>Share KV cache across services that use the same model or have overlapping prompt patterns:</p> <pre><code># Good: Multiple chat services using the same model share a cache\nkvCache:\n  name: llama-8b-shared-cache\n</code></pre>"},{"location":"aim/usage/kv-cache/#2-size-conservatively-then-scale","title":"2. Size Conservatively, Then Scale","text":"<p>Start with recommended sizes and monitor actual usage:</p> <pre><code># Start with 50Gi for a 70B model\nstorage:\n  size: 50Gi\n</code></pre> <p>Then scale up if needed based on monitoring.</p>"},{"location":"aim/usage/kv-cache/#3-use-fast-storage-classes","title":"3. Use Fast Storage Classes","text":"<p>KV cache performance depends on storage speed:</p> <pre><code>storage:\n  size: 100Gi\n  storageClassName: premium-ssd  # Use SSD-backed storage\n</code></pre>"},{"location":"aim/usage/kv-cache/#4-monitor-storage-capacity","title":"4. Monitor Storage Capacity","text":"<p>Set up alerts before storage fills up:</p> <pre><code># Check PVC usage regularly\nkubectl get pvc -n ml-team\n</code></pre>"},{"location":"aim/usage/kv-cache/#5-plan-for-failover","title":"5. Plan for Failover","text":"<p>Create multiple KV caches for critical workloads:</p> <pre><code># Primary service\nkvCache:\n  name: primary-cache\n\n# Failover service (optional)\nkvCache:\n  name: secondary-cache\n</code></pre>"},{"location":"aim/usage/kv-cache/#default-behavior","title":"Default Behavior","text":"<p>When configuration is omitted, the following defaults apply:</p> Field Default Value Notes <code>kvCacheType</code> <code>redis</code> Currently only Redis is supported <code>storage.size</code> <code>1Gi</code> Minimum recommended for Redis <code>storage.storageClassName</code> <code>nil</code> Uses cluster default storage class <code>storage.accessModes</code> <code>[ReadWriteOnce]</code> Standard for single-node access"},{"location":"aim/usage/kv-cache/#see-also","title":"See Also","text":"<ul> <li>KV Cache Concepts - Architecture and design</li> <li>Deploying Inference Services - AIMService configuration</li> <li>Models - Model configuration and optimization</li> </ul>"},{"location":"aim/usage/services/","title":"Deploying Inference Services","text":"<p><code>AIMService</code> is the primary resource for deploying inference endpoints. It combines a model image, optional runtime configuration, and HTTP routing to produce a production-ready inference service.</p>"},{"location":"aim/usage/services/#quick-start","title":"Quick Start","text":"<p>The minimal service requires just an AIM container image:</p> <pre><code>apiVersion: aim.silogen.ai/v1alpha1\nkind: AIMService\nmetadata:\n  name: llama-chat\n  namespace: ml-team\nspec:\n  model:\n    image: ghcr.io/silogen/aim-meta-llama-llama-3-1-8b-instruct:0.7.0\n</code></pre> <p>This creates an inference service using the default runtime configuration and automatically selected profile.</p>"},{"location":"aim/usage/services/#common-configuration","title":"Common Configuration","text":""},{"location":"aim/usage/services/#scaling","title":"Scaling","text":"<p>Control the number of replicas:</p> <pre><code>spec:\n  model:\n    image: ghcr.io/silogen/aim-meta-llama-llama-3-1-8b-instruct:0.7.0\n  replicas: 3\n</code></pre>"},{"location":"aim/usage/services/#autoscaling","title":"Autoscaling","text":"<p>AIMService supports automatic scaling based on custom metrics using KEDA (Kubernetes Event-driven Autoscaling). This enables your inference services to scale dynamically based on real-time demand.</p>"},{"location":"aim/usage/services/#basic-autoscaling","title":"Basic Autoscaling","text":"<p>Enable autoscaling by specifying minimum and maximum replica counts:</p> <pre><code>spec:\n  model:\n    image: ghcr.io/silogen/aim-meta-llama-llama-3-1-8b-instruct:0.7.0\n  minReplicas: 1\n  maxReplicas: 5\n</code></pre> <p>This configures KEDA to manage scaling between 1 and 5 replicas. Without custom metrics, KEDA uses default scaling behavior.</p>"},{"location":"aim/usage/services/#custom-metrics-with-opentelemetry","title":"Custom Metrics with OpenTelemetry","text":"<p>For precise control over scaling behavior, configure custom metrics from the inference runtime. vLLM exposes metrics via OpenTelemetry that can drive scaling decisions:</p> <pre><code>spec:\n  model:\n    image: ghcr.io/silogen/aim-meta-llama-llama-3-1-8b-instruct:0.7.0\n  minReplicas: 1\n  maxReplicas: 3\n  autoScaling:\n    metrics:\n      - type: PodMetric\n        podmetric:\n          metric:\n            backend: \"opentelemetry\"\n            metricNames:\n              - vllm:num_requests_running\n            query: \"vllm:num_requests_running\"\n            operationOverTime: \"avg\"\n          target:\n            type: Value\n            value: \"1\"\n</code></pre> <p>This configuration scales based on the average number of running requests across pods. When the average exceeds 1, KEDA scales up; when it drops below, KEDA scales down.</p>"},{"location":"aim/usage/services/#metric-configuration-options","title":"Metric Configuration Options","text":"Field Description Default <code>backend</code> Metrics backend to use <code>opentelemetry</code> <code>serverAddress</code> Address of the metrics server <code>keda-otel-scaler.keda.svc:4317</code> <code>metricNames</code> List of metrics to collect from pods - <code>query</code> Query to retrieve metrics from the backend - <code>operationOverTime</code> Aggregation operation: <code>last_one</code>, <code>avg</code>, <code>max</code>, <code>min</code>, <code>rate</code>, <code>count</code> <code>last_one</code>"},{"location":"aim/usage/services/#target-types","title":"Target Types","text":"Type Description Field <code>Value</code> Scale based on absolute metric value <code>value</code> <code>AverageValue</code> Scale based on average value across pods <code>averageValue</code> <code>Utilization</code> Scale based on percentage utilization (resource metrics only) <code>averageUtilization</code>"},{"location":"aim/usage/services/#common-vllm-metrics","title":"Common vLLM Metrics","text":"<p>These metrics are commonly used for autoscaling vLLM-based inference services:</p> Metric Description Scaling Use Case <code>vllm:num_requests_running</code> Number of requests currently being processed Scale based on concurrent load <code>vllm:num_requests_waiting</code> Number of requests waiting in queue Scale based on queue depth"},{"location":"aim/usage/services/#how-it-works","title":"How It Works","text":"<p>When autoscaling is configured, AIMService:</p> <ol> <li>Creates a KServe InferenceService with the <code>serving.kserve.io/autoscalerClass: keda</code> annotation</li> <li>KEDA creates a <code>ScaledObject</code> that monitors the specified metrics</li> <li>KEDA creates and manages an <code>HorizontalPodAutoscaler</code> (HPA) based on the ScaledObject</li> <li>The HPA scales the deployment between <code>minReplicas</code> and <code>maxReplicas</code> based on metric values</li> </ol>"},{"location":"aim/usage/services/#monitoring-autoscaling","title":"Monitoring Autoscaling","text":"<p>Check the ScaledObject status:</p> <pre><code>kubectl -n &lt;namespace&gt; get scaledobject &lt;service-name&gt;-predictor -o yaml\n</code></pre> <p>Check the HPA created by KEDA:</p> <pre><code>kubectl -n &lt;namespace&gt; get hpa keda-hpa-&lt;service-name&gt;-predictor\n</code></pre> <p>Watch scaling events in real-time:</p> <pre><code>kubectl -n &lt;namespace&gt; get hpa keda-hpa-&lt;service-name&gt;-predictor -w\n</code></pre> <p>View current metrics:</p> <pre><code>kubectl -n &lt;namespace&gt; describe hpa keda-hpa-&lt;service-name&gt;-predictor\n</code></pre>"},{"location":"aim/usage/services/#prerequisites","title":"Prerequisites","text":"<p>Autoscaling requires:</p> <ul> <li>KEDA installed in the cluster</li> <li>KEDA OpenTelemetry Scaler (<code>keda-otel-scaler</code>) deployed if using OpenTelemetry metrics</li> <li>OpenTelemetry Collector configured to scrape metrics from inference pods</li> </ul>"},{"location":"aim/usage/services/#resource-limits","title":"Resource Limits","text":"<p>Override default resource allocations:</p> <pre><code>spec:\n  model:\n    image: ghcr.io/silogen/aim-meta-llama-llama-3-1-8b-instruct:0.7.0\n  resources:\n    limits:\n      cpu: \"8\"\n      memory: 64Gi\n    requests:\n      cpu: \"4\"\n      memory: 32Gi\n</code></pre>"},{"location":"aim/usage/services/#runtime-overrides","title":"Runtime Overrides","text":"<p>Customize optimization settings:</p> <pre><code>spec:\n  model:\n    image: ghcr.io/silogen/aim-meta-llama-llama-3-1-8b-instruct:0.7.0\n  overrides:\n    metric: throughput      # or 'latency' for interactive workloads\n    precision: fp16         # fp4, fp8, fp16, bf16, int4, int8, auto\n    gpuSelector:\n      count: 2\n      model: MI300X\n</code></pre> <p>Please note that not all configurations may be supported on each AIM image.</p>"},{"location":"aim/usage/services/#runtime-configuration","title":"Runtime Configuration","text":"<p>Reference a specific runtime configuration for credentials and defaults:</p> <pre><code>spec:\n  model:\n    image: ghcr.io/silogen/aim-meta-llama-llama-3-1-8b-instruct:0.7.0\n  runtimeConfigName: team-config  # defaults to 'default' if omitted\n</code></pre> <p>Runtime configurations provide: - Routing defaults</p> <p>See Runtime Configuration for details.</p>"},{"location":"aim/usage/services/#kv-cache","title":"KV Cache","text":""},{"location":"aim/usage/services/#creating-a-new-kv-cache","title":"Creating a New KV Cache","text":"<p>The service automatically creates a KV cache when you specify the <code>type</code>:</p> <pre><code>spec:\n  model:\n    image: ghcr.io/silogen/aim-meta-llama-llama-3-1-8b-instruct:0.7.0\n  kvCache:\n    type: redis  # Creates 'kvcache-llama-chat' automatically\n</code></pre> <p>With custom storage:</p> <pre><code>spec:\n  model:\n    image: ghcr.io/silogen/aim-meta-llama-llama-3-1-70b-instruct:0.7.0\n  kvCache:\n    type: redis\n    storage:\n      size: 100Gi                  # Minimum 1Gi, adjust based on model size\n      storageClassName: fast-ssd   # Optional, uses cluster default if omitted\n</code></pre>"},{"location":"aim/usage/services/#referencing-an-existing-kv-cache","title":"Referencing an Existing KV Cache","text":"<p>Multiple services can share a single KV cache:</p> <pre><code>spec:\n  model:\n    image: ghcr.io/silogen/aim-meta-llama-llama-3-1-8b-instruct:0.7.0\n  kvCache:\n    name: shared-cache  # References existing AIMKVCache resource\n</code></pre> <p>This is useful when running multiple services with the same model or overlapping use cases.</p> <p>See KV Cache for detailed configuration and sizing guidance.</p>"},{"location":"aim/usage/services/#http-routing","title":"HTTP Routing","text":"<p>Enable external HTTP access through Gateway API:</p> <pre><code>spec:\n  model:\n    image: ghcr.io/silogen/aim-meta-llama-llama-3-1-8b-instruct:0.7.0\n  routing:\n    enabled: true\n    gatewayRef:\n      name: inference-gateway\n      namespace: gateways\n</code></pre>"},{"location":"aim/usage/services/#custom-paths","title":"Custom Paths","text":"<p>Override the default path using templates:</p> <pre><code>spec:\n  model:\n    image: ghcr.io/silogen/aim-meta-llama-llama-3-1-8b-instruct:0.7.0\n  routing:\n    enabled: true\n    gatewayRef:\n      name: inference-gateway\n      namespace: gateways\n    pathTemplate: \"/{.metadata.namespace}/chat/{.metadata.name}\"\n</code></pre> <p>Templates use JSONPath expressions wrapped in <code>{...}</code>: - <code>{.metadata.namespace}</code> - service namespace - <code>{.metadata.name}</code> - service name - <code>{.metadata.labels['team']}</code> - label value (label must exist)</p> <p>The final path is lowercased, URL-encoded, and limited to 200 characters.</p> <p>Note: If a label or field doesn't exist, the service will enter a degraded state. Ensure all referenced fields are present.</p>"},{"location":"aim/usage/services/#authentication","title":"Authentication","text":"<p>For models requiring authentication (e.g., gated Hugging Face models):</p> <pre><code>spec:\n  model:\n    image: ghcr.io/silogen/aim-meta-llama-llama-3-1-8b-instruct:0.7.0\n  env:\n    - name: HF_TOKEN\n      valueFrom:\n        secretKeyRef:\n          name: huggingface-creds\n          key: token\n</code></pre> <p>For private container registries:</p> <pre><code>spec:\n  model:\n    image: ghcr.io/silogen/aim-meta-llama-llama-3-1-8b-instruct:0.7.0\n  imagePullSecrets:\n    - name: registry-credentials\n</code></pre>"},{"location":"aim/usage/services/#monitoring-service-status","title":"Monitoring Service Status","text":"<p>Check service readiness:</p> <pre><code>kubectl -n &lt;namespace&gt; get aimservice &lt;name&gt;\n</code></pre> <p>View detailed status:</p> <pre><code>kubectl -n &lt;namespace&gt; describe aimservice &lt;name&gt;\n</code></pre>"},{"location":"aim/usage/services/#status-values","title":"Status Values","text":"<p>The <code>status</code> field shows the overall service state:</p> <ul> <li>Pending: Initial state, resolving model and template references</li> <li>Starting: Creating infrastructure (InferenceService, routing, caches)</li> <li>Running: Service is ready and serving traffic</li> <li>Degraded: Service is running but has warnings (e.g., routing issues, template not optimal)</li> <li>Failed: Service cannot start due to terminal errors</li> </ul>"},{"location":"aim/usage/services/#status-fields","title":"Status Fields","text":"Field Description <code>status</code> Overall service status (Pending, Starting, Running, Degraded, Failed) <code>observedGeneration</code> Most recent generation observed by the controller <code>conditions</code> Detailed conditions tracking different aspects of service lifecycle <code>resolvedRuntimeConfig</code> Metadata about the runtime config that was resolved (name, namespace, scope, UID) <code>resolvedImage</code> Metadata about the model image that was resolved (name, namespace, scope, UID) <code>resolvedTemplate</code> Metadata about the template that was selected (name, namespace, scope, UID) <code>routing</code> Observed routing configuration including the rendered HTTP path"},{"location":"aim/usage/services/#conditions","title":"Conditions","text":"<p>Services track detailed conditions to help diagnose issues:</p> <p>Resolved: Model and template validation - <code>True</code>: Model and template have been validated and a runtime profile has been selected - <code>False</code>: Model or template not found, or validation failed - Reasons: <code>Resolved</code>, <code>TemplateNotFound</code>, <code>ModelNotFound</code>, <code>ModelNotReady</code>, <code>TemplateSelectionAmbiguous</code></p> <p>CacheReady: Model caching status - <code>True</code>: Required caches are present or warmed as requested - <code>False</code>: Caches are not ready - Reasons: <code>CacheWarm</code>, <code>WaitingForCache</code>, <code>CacheWarming</code>, <code>CacheFailed</code></p> <p>RuntimeReady: KServe InferenceService status - <code>True</code>: The underlying KServe InferenceService is ready and serving traffic - <code>False</code>: InferenceService is not ready - Reasons: <code>RuntimeReady</code>, <code>CreatingRuntime</code>, <code>RuntimeFailed</code></p> <p>RoutingReady: HTTP routing status - <code>True</code>: HTTPRoute has been created and routing is configured - <code>False</code>: Routing is not ready or disabled - Reasons: <code>RouteReady</code>, <code>ConfiguringRoute</code>, <code>RouteFailed</code>, <code>PathTemplateInvalid</code></p> <p>Ready: Overall readiness - <code>True</code>: Service is fully ready to serve traffic (all other conditions are True) - <code>False</code>: Service is not ready</p> <p>Progressing: Active reconciliation - <code>True</code>: Controller is actively reconciling towards readiness - <code>False</code>: Service has reached a stable state</p> <p>Failure: Terminal failures - <code>True</code>: An unrecoverable error has occurred - Includes detailed reason and message</p>"},{"location":"aim/usage/services/#example-status","title":"Example Status","text":"<pre><code>$ kubectl -n ml-team get aimservice llama-chat -o yaml\n</code></pre> <pre><code>status:\n  status: Running\n  observedGeneration: 1\n  conditions:\n    - type: Resolved\n      status: \"True\"\n      reason: Resolved\n      message: \"Model and template resolved successfully\"\n    - type: CacheReady\n      status: \"True\"\n      reason: CacheWarm\n      message: \"Model sources cached\"\n    - type: RuntimeReady\n      status: \"True\"\n      reason: RuntimeReady\n      message: \"InferenceService is ready\"\n    - type: RoutingReady\n      status: \"True\"\n      reason: RouteReady\n      message: \"HTTPRoute configured\"\n    - type: Ready\n      status: \"True\"\n      reason: Ready\n      message: \"Service is ready\"\n  resolvedRuntimeConfig:\n    name: default\n    namespace: ml-team\n    scope: Namespace\n    kind: aim.silogen.ai/v1alpha1/AIMRuntimeConfig\n  resolvedImage:\n    name: meta-llama-3-8b\n    namespace: ml-team\n    scope: Namespace\n    kind: aim.silogen.ai/v1alpha1/AIMModel\n  resolvedTemplate:\n    name: llama-3-8b-latency\n    scope: Cluster\n    kind: aim.silogen.ai/v1alpha1/AIMClusterServiceTemplate\n  routing:\n    path: /ml-team/llama-chat\n</code></pre>"},{"location":"aim/usage/services/#complete-example","title":"Complete Example","text":"<pre><code>apiVersion: aim.silogen.ai/v1alpha1\nkind: AIMService\nmetadata:\n  name: llama-chat\n  namespace: ml-team\n  labels:\n    team: research\nspec:\n  model:\n    ref: meta-llama-3-8b\n  templateRef: llama-3-8b-latency\n  runtimeConfigName: team-config\n  replicas: 2\n  resources:\n    limits:\n      cpu: \"6\"\n      memory: 48Gi\n  overrides:\n    metric: throughput\n    precision: fp16\n    gpuSelector:\n      count: 2\n      model: MI300X\n  routing:\n    enabled: true\n    gatewayRef:\n      name: inference-gateway\n      namespace: gateways\n    pathTemplate: \"/team/{.metadata.labels['team']}/chat\"\n  env:\n    - name: HF_TOKEN\n      valueFrom:\n        secretKeyRef:\n          name: huggingface-creds\n          key: token\n</code></pre>"},{"location":"aim/usage/services/#model-caching","title":"Model Caching","text":"<p>Enable model caching to pre-download model artifacts:</p> <pre><code>spec:\n  model:\n    image: ghcr.io/silogen/aim-meta-llama-llama-3-1-8b-instruct:0.7.0\n  cacheModel: true\n</code></pre> <p>When <code>cacheModel: true</code>:</p> <ol> <li>An <code>AIMTemplateCache</code> is created for the service's template, if it doesn't already exist</li> <li>The AIMTemplate will create <code>AIMModelCache</code> resources that download model artifacts to PVCs</li> <li>The service waits for caches to become Available before starting</li> <li>Cached models are mounted directly into the inference container</li> </ol>"},{"location":"aim/usage/services/#cache-preservation-on-deletion","title":"Cache Preservation on Deletion","text":"<p>When you delete an <code>AIMService</code>:</p> <ul> <li>Available caches are preserved - they can be reused by future services</li> <li>Non-available caches are cleaned up - failed or incomplete downloads are removed</li> </ul> <p>This means if you recreate the same service, it will immediately use the existing cached models without re-downloading.</p> <p>See Model Caching for detailed information on cache lifecycle and management.</p>"},{"location":"aim/usage/services/#troubleshooting","title":"Troubleshooting","text":""},{"location":"aim/usage/services/#service-stuck-in-pending","title":"Service stuck in Pending","text":"<p>Check if the runtime config exists: <pre><code>kubectl -n &lt;namespace&gt; get aimruntimeconfig\n</code></pre></p> <p>Check if templates are available: <pre><code>kubectl -n &lt;namespace&gt; get aimservicetemplate\nkubectl get aimclusterservicetemplate\n</code></pre></p>"},{"location":"aim/usage/services/#routing-not-working","title":"Routing not working","text":"<p>Verify the HTTPRoute was created: <pre><code>kubectl -n &lt;namespace&gt; get httproute &lt;service-name&gt;-route\n</code></pre></p> <p>Check for path template errors in status: <pre><code>kubectl -n &lt;namespace&gt; get aimservice &lt;name&gt; -o jsonpath='{.status.conditions[?(@.type==\"RoutingReady\")]}'\n</code></pre></p>"},{"location":"aim/usage/services/#model-not-found","title":"Model not found","text":"<p>Verify the model exists: <pre><code>kubectl -n &lt;namespace&gt; get aimmodel &lt;model-name&gt;\nkubectl get aimclustermodel &lt;model-name&gt;\n</code></pre></p> <p>If using <code>spec.model.image</code> directly, verify the image URI is accessible and the runtime config is properly configured for model creation.</p>"},{"location":"aim/usage/services/#related-documentation","title":"Related Documentation","text":"<ul> <li>KV Cache - Configure KV caching for improved performance</li> <li>Runtime Configuration - Configure runtime settings and credentials</li> <li>Models - Understanding the model catalog</li> <li>Templates - Deep dive on templates and discovery</li> <li>Model Caching - Cache lifecycle and deletion behavior</li> </ul>"},{"location":"general/main-components/","title":"Main Components","text":"<p>Kaiwo consists of two main components:</p> <ul> <li>Kaiwo CLI: A command-line interface for submitting and managing workloads to the Kaiwo Operator.</li> <li>Kaiwo Operator: A Kubernetes operator that manages the scheduling and execution of workloads on GPU nodes.   The Kaiwo Operator is responsible for managing the lifecycle of workloads, including scheduling, resource allocation, and monitoring. It leverages the power of Ray and Kueue to provide efficient job queueing and scheduling.</li> </ul>"},{"location":"general/releases/","title":"Releases","text":"<p>Kaiwo releases can be found on the Kaiwo releases page. </p> <p>Each release includes a changelog that lists the new features, bug fixes, and other changes made in that version. In terms of assets, each release includes the following:</p> <ul> <li>install.yaml: The install.yaml file is used to install Kaiwo Operator on your system. For more information on how to install Kaiwo Operator, please refer to the installation guide.</li> <li>kaiwo: The Kaiwo CLI tool, which is the second main component of the Kaiwo project. This is single binary. We release it for all platforms.</li> <li>workloads.zip: The workloads.zip file contains a set of example workloads that can be used to test and demonstrate the capabilities of Kaiwo. These workloads are designed to be easy to use and can be deployed on any Kubernetes cluster. For more information on how to use the workloads, please refer to the quickstart guide for AI Scientists.</li> <li>Source code: The source code for the Kaiwo project is available on GitHub. You can download the source code for any release from the releases page. The source code is licensed under the Apache 2.0 license, which allows you to use, modify, and distribute the code as long as you comply with the terms of the license.</li> </ul>"},{"location":"general/support/","title":"Support","text":"<p>For support please open an issue on Github. We strive to respond to all issues as soon as possible. Please provide as much detail as possible about the issue you are experiencing, including any error messages or screenshots. This will help us to assist you more effectively.</p>"},{"location":"reference/labels/","title":"Label propagation","text":"<p>In order to facilitate logical label propagation, the Kaiwo controller propagates labels from the Kaiwo objects to the target workload objects.</p>"},{"location":"reference/labels/#from-created-kaiwo-resource","title":"From created Kaiwo resource","text":"<p>If you directly create a Kaiwo resource, such as the following job, the labels are taken from two locations, <code>metadata.labels</code>, which are propagated to the downstream resource's metadata field, and <code>spec.podTemplateLabels</code>, which are propagated to the downstream resources' pod template label field(s).</p> <pre><code>apiVersion: kaiwo.silogen.ai/v1alpha1\nkind: KaiwoJob\nmetadata:\n  name: my-job\n  labels:\n    key1: value1\nspec:\n  user: my-user\n  queue: my-queue\n  podTemplateSpecLabels:\n    key2: value2\n</code></pre> <p>The following batch job would get created</p> <pre><code>apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: my-job\n  labels:\n    key1: value1\n    kueue.x-k8s.io/queue-name: my-queue\n    kaiwo.silogen.ai/type: job\n    kaiwo.silogen.ai/run-id: \"kaiwo-job-UUID\"\n    kaiwo.silogen.ai/user: my-user\n    kaiwo.silogen.ai/name: my-job\nspec:\n  template:\n    metadata:\n      labels:\n        key2: value2\n        kaiwo.silogen.ai/type: job\n        kaiwo.silogen.ai/run-id: \"kaiwo-job-UUID\"\n        kaiwo.silogen.ai/user: my-user\n        kaiwo.silogen.ai/name: my-job\n</code></pre> <p>Which in turn would create the following Pod</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: my-job-&lt;hash&gt;\n  labels:\n    key2: value2\n    kaiwo.silogen.ai/type: job\n    kaiwo.silogen.ai/run-id: \"kaiwo-job-UUID\"\n    kaiwo.silogen.ai/user: my-user\n    kaiwo.silogen.ai/name: my-job\n</code></pre> <p>Info</p> <p>If you define your job or service spec inline inside the Kaiwo resource definition, these are preserved. However, any label that begins with <code>kaiwo.silogen.ai/</code> may be overwritten, if it clashes with a kaiwo system label such as the ones define above.</p>"},{"location":"reference/labels/#from-directly-created-resource-with-a-kaiwo-label","title":"From directly created resource with a Kaiwo label","text":"<p>If you create a resource such as a batch Job directly and assign the <code>kaiwo.silogen.ai/managed: true</code> label, similar logic is applied.</p> <p>If you create a Job such as </p> <pre><code>apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: my-job\n  labels:\n    key1: value1\n    kaiwo.silogen.ai/managed: \"true\"\n    kueue.x-k8s.io/queue-name: my-queue\nspec:\n  template:\n    metadata:\n      labels:\n        key2: value2\n</code></pre> <p>This will update the job with the <code>kaiwo.silogen.ai/</code> system labels:</p> <pre><code>apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: my-job\n  labels:\n    key1: value1\n    kaiwo.silogen.ai/managed: \"true\"\n    kueue.x-k8s.io/queue-name: my-queue\n    kaiwo.silogen.ai/type: job\n    kaiwo.silogen.ai/run-id: \"kaiwo-job-UUID\"\n    kaiwo.silogen.ai/user: my-user\n    kaiwo.silogen.ai/name: my-job\nspec:\n  template:\n    metadata:\n      labels:\n        key2: value2\n        kaiwo.silogen.ai/type: job\n        kaiwo.silogen.ai/run-id: \"kaiwo-job-UUID\"\n        kaiwo.silogen.ai/user: my-user\n        kaiwo.silogen.ai/name: my-job\n</code></pre> <p>and create a KaiwoJob:</p> <pre><code>apiVersion: kaiwo.silogen.ai/v1alpha1\nkind: KaiwoJob\nmetadata:\n  name: my-job\n  labels:\n    key1: value1\n    kaiwo.silogen.ai/managed: \"true\"\nspec:\n  queue: my-queue\n</code></pre> <p>Again, if you try to include any protected <code>kaiwo.silogen.ai/</code> labels, these will be overwritten.</p>"},{"location":"reference/crds/aim.silogen.ai/","title":"API Reference","text":""},{"location":"reference/crds/aim.silogen.ai/#packages","title":"Packages","text":"<ul> <li>aim.silogen.ai/v1alpha1</li> </ul>"},{"location":"reference/crds/aim.silogen.ai/#aimsilogenaiv1alpha1","title":"aim.silogen.ai/v1alpha1","text":"<p>Package v1alpha1 contains API Schema definitions for the AIM v1alpha1 API group.</p>"},{"location":"reference/crds/aim.silogen.ai/#resource-types","title":"Resource Types","text":"<ul> <li>AIMClusterModel</li> <li>AIMClusterModelList</li> <li>AIMClusterModelSource</li> <li>AIMClusterModelSourceList</li> <li>AIMClusterRuntimeConfig</li> <li>AIMClusterRuntimeConfigList</li> <li>AIMClusterServiceTemplate</li> <li>AIMClusterServiceTemplateList</li> <li>AIMKVCache</li> <li>AIMKVCacheList</li> <li>AIMModel</li> <li>AIMModelCache</li> <li>AIMModelCacheList</li> <li>AIMModelList</li> <li>AIMRuntimeConfig</li> <li>AIMRuntimeConfigList</li> <li>AIMService</li> <li>AIMServiceList</li> <li>AIMServiceTemplate</li> <li>AIMServiceTemplateList</li> <li>AIMTemplateCache</li> <li>AIMTemplateCacheList</li> </ul>"},{"location":"reference/crds/aim.silogen.ai/#aimclustermodel","title":"AIMClusterModel","text":"<p>AIMClusterModel is the Schema for cluster-scoped AIM model catalog entries.</p> <p>Appears in: - AIMClusterModelList</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.silogen.ai/v1alpha1</code> <code>kind</code> string <code>AIMClusterModel</code> <code>metadata</code> ObjectMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>spec</code> AIMModelSpec <code>status</code> AIMModelStatus"},{"location":"reference/crds/aim.silogen.ai/#aimclustermodellist","title":"AIMClusterModelList","text":"<p>AIMClusterModelList contains a list of AIMClusterModel.</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.silogen.ai/v1alpha1</code> <code>kind</code> string <code>AIMClusterModelList</code> <code>metadata</code> ListMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>items</code> AIMClusterModel array"},{"location":"reference/crds/aim.silogen.ai/#aimclustermodelsource","title":"AIMClusterModelSource","text":"<p>AIMClusterModelSource automatically discovers and syncs AI model images from container registries.</p> <p>Appears in: - AIMClusterModelSourceList</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.silogen.ai/v1alpha1</code> <code>kind</code> string <code>AIMClusterModelSource</code> <code>metadata</code> ObjectMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>spec</code> AIMClusterModelSourceSpec <code>status</code> AIMClusterModelSourceStatus"},{"location":"reference/crds/aim.silogen.ai/#aimclustermodelsourcelist","title":"AIMClusterModelSourceList","text":"<p>AIMClusterModelSourceList contains a list of AIMClusterModelSource.</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.silogen.ai/v1alpha1</code> <code>kind</code> string <code>AIMClusterModelSourceList</code> <code>metadata</code> ListMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>items</code> AIMClusterModelSource array"},{"location":"reference/crds/aim.silogen.ai/#aimclustermodelsourcespec","title":"AIMClusterModelSourceSpec","text":"<p>AIMClusterModelSourceSpec defines the desired state of AIMClusterModelSource.</p> <p>Appears in: - AIMClusterModelSource</p> Field Description Default Validation <code>registry</code> string Registry to sync from (e.g., docker.io, ghcr.io, gcr.io).Defaults to docker.io if not specified. docker.io <code>imagePullSecrets</code> LocalObjectReference array ImagePullSecrets contains references to secrets for authenticating to private registries.Secrets must exist in the operator namespace (typically kaiwo-system).Used for both registry catalog listing and image metadata extraction. <code>filters</code> ModelSourceFilter array Filters define which images to discover and sync.Each filter specifies an image pattern with optional version constraints and exclusions.Multiple filters are combined with OR logic (any match includes the image). MaxItems: 100 MinItems: 1  <code>syncInterval</code> Duration SyncInterval defines how often to sync with the registry.Defaults to 1h. Minimum recommended interval is 15m to avoid rate limiting.Format: duration string (e.g., \"30m\", \"1h\", \"2h30m\"). 1h <code>versions</code> string array Versions specifies global semantic version constraints applied to all filters.Individual filters can override this with their own version constraints.Constraints use semver syntax: &gt;=1.0.0, &lt;2.0.0, ~1.2.0, ^1.0.0, etc.Non-semver tags (e.g., \"latest\", \"dev\") are silently skipped.Version ranges work on all registries (including ghcr.io, gcr.io) when combined withexact repository names (no wildcards). The controller uses the Tags List API to fetchall tags for the repository and filters them by the semver constraint.Example: registry=ghcr.io, filters=[{image: \"silogen/aim-llama\"}], versions=[\"&gt;=1.0.0\"]will fetch all tags from ghcr.io/silogen/aim-llama and include only those &gt;=1.0.0. <code>maxModels</code> integer MaxModels is the maximum number of AIMClusterModel resources to create from this source.Once this limit is reached, no new models will be created, even if more matching images are discovered.Existing models are never deleted.This prevents runaway model creation from overly broad filters. 100 Maximum: 10000 Minimum: 1"},{"location":"reference/crds/aim.silogen.ai/#aimclustermodelsourcestatus","title":"AIMClusterModelSourceStatus","text":"<p>AIMClusterModelSourceStatus defines the observed state of AIMClusterModelSource.</p> <p>Appears in: - AIMClusterModelSource</p> Field Description Default Validation <code>status</code> string Status represents the overall state of the model source. Enum: [Pending Starting Progressing Ready Running Degraded NotAvailable Failed]  <code>lastSyncTime</code> Time LastSyncTime is the timestamp of the last successful registry sync.Updated after each successful sync operation. <code>discoveredModels</code> integer DiscoveredModels is the count of AIMClusterModel resources managed by this source.Includes both existing and newly created models. <code>availableModels</code> integer AvailableModels is the total count of images discovered in the registry that match the filters.This may be higher than DiscoveredModels if maxModels limit was reached. <code>modelsLimitReached</code> boolean ModelsLimitReached indicates whether the maxModels limit has been reached.When true, no new models will be created even if more matching images are discovered. <code>conditions</code> Condition array Conditions represent the latest available observations of the source's state.Standard conditions: Ready, Syncing, RegistryReachable. <code>observedGeneration</code> integer ObservedGeneration reflects the generation of the most recently observed spec."},{"location":"reference/crds/aim.silogen.ai/#aimclusterruntimeconfig","title":"AIMClusterRuntimeConfig","text":"<p>AIMClusterRuntimeConfig defines cluster-scoped runtime defaults for AIM resources.</p> <p>Appears in: - AIMClusterRuntimeConfigList</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.silogen.ai/v1alpha1</code> <code>kind</code> string <code>AIMClusterRuntimeConfig</code> <code>metadata</code> ObjectMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>spec</code> AIMClusterRuntimeConfigSpec <code>status</code> AIMRuntimeConfigStatus"},{"location":"reference/crds/aim.silogen.ai/#aimclusterruntimeconfiglist","title":"AIMClusterRuntimeConfigList","text":"<p>AIMClusterRuntimeConfigList contains a list of AIMClusterRuntimeConfig.</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.silogen.ai/v1alpha1</code> <code>kind</code> string <code>AIMClusterRuntimeConfigList</code> <code>metadata</code> ListMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>items</code> AIMClusterRuntimeConfig array"},{"location":"reference/crds/aim.silogen.ai/#aimclusterruntimeconfigspec","title":"AIMClusterRuntimeConfigSpec","text":"<p>AIMClusterRuntimeConfigSpec defines cluster-wide defaults for AIM resources.</p> <p>Appears in: - AIMClusterRuntimeConfig</p> Field Description Default Validation <code>defaultStorageClassName</code> string DefaultStorageClassName specifies the storage class to use for model caches and PVCswhen the consuming resource (AIMModelCache, AIMTemplateCache, AIMServiceTemplate) does notspecify a storage class. If this field is empty, the cluster's default storage class is used. <code>model</code> AIMModelConfig Model controls model creation and discovery defaults. <code>routing</code> AIMRuntimeRoutingConfig Routing controls HTTP routing defaults applied to AIM resources.When set, these defaults are used for AIMService resources that enable routingbut do not specify their own routing configuration. <code>pvcHeadroomPercent</code> integer PVCHeadroomPercent specifies the percentage of extra space to add to PVCsfor model storage. This accounts for filesystem overhead and temporary filesduring model loading. The value represents a percentage (e.g., 10 means 10% extra space).If not specified, defaults to 10%. Minimum: 0  <code>labelPropagation</code> AIMRuntimeConfigLabelPropagationSpec LabelPropagation controls how labels from parent AIM resources are propagated to child resources.When enabled, labels matching the specified patterns are automatically copied from parent resources(e.g., AIMService, AIMTemplateCache) to their child resources (e.g., Deployments, Services, PVCs).This is useful for propagating organizational metadata like cost centers, team identifiers,or compliance labels through the resource hierarchy. <code>env</code> EnvVar array Env specifies environment variables to use for the runtime config.These variables are used for the runtime config and are not propagated to child resources.If configmaps or secrets are referenced, they need to exist in the namespace referencing this runtime config.For cluster scoped runtime configs, any referenced configmaps or secrets need to exist in the system namespace."},{"location":"reference/crds/aim.silogen.ai/#aimclusterservicetemplate","title":"AIMClusterServiceTemplate","text":"<p>Appears in: - AIMClusterServiceTemplateList</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.silogen.ai/v1alpha1</code> <code>kind</code> string <code>AIMClusterServiceTemplate</code> <code>metadata</code> ObjectMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>spec</code> AIMClusterServiceTemplateSpec <code>status</code> AIMServiceTemplateStatus"},{"location":"reference/crds/aim.silogen.ai/#aimclusterservicetemplatelist","title":"AIMClusterServiceTemplateList","text":"Field Description Default Validation <code>apiVersion</code> string <code>aim.silogen.ai/v1alpha1</code> <code>kind</code> string <code>AIMClusterServiceTemplateList</code> <code>metadata</code> ListMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>items</code> AIMClusterServiceTemplate array"},{"location":"reference/crds/aim.silogen.ai/#aimclusterservicetemplatespec","title":"AIMClusterServiceTemplateSpec","text":"<p>AIMClusterServiceTemplateSpec defines the desired state of AIMClusterServiceTemplate (cluster-scoped).</p> <p>A cluster-scoped template that selects a runtime profile for a given AIM model.</p> <p>Appears in: - AIMClusterServiceTemplate</p> Field Description Default Validation <code>modelName</code> string ModelName is the model name. Matches <code>metadata.name</code> of an AIMModel or AIMClusterModel. Immutable.Example: <code>meta/llama-3-8b:1.1+20240915</code> MinLength: 1  <code>metric</code> AIMMetric Metric selects the optimization goal.- <code>latency</code>: prioritize low end\u2011to\u2011end latency- <code>throughput</code>: prioritize sustained requests/second Enum: [latency throughput]  <code>precision</code> AIMPrecision Precision selects the numeric precision used by the runtime. Enum: [auto fp4 fp8 fp16 fp32 bf16 int4 int8]  <code>gpuSelector</code> AIMGpuSelector GpuSelector specifies GPU requirements for each replica.Defines the GPU count and model type required for deployment.This field is immutable after creation. <code>runtimeConfigName</code> string RuntimeConfigName references the AIM runtime configuration (by name) to use for this template. default <code>imagePullSecrets</code> LocalObjectReference array ImagePullSecrets lists secrets containing credentials for pulling container images.These secrets are used for:- Discovery dry-run jobs that inspect the model container- Pulling the image for inference servicesThe secrets are merged with any model or runtime config defaults.For namespace-scoped templates, secrets must exist in the same namespace.For cluster-scoped templates, secrets must exist in the operator namespace. <code>serviceAccountName</code> string ServiceAccountName specifies the Kubernetes service account to use for workloads related to this template.This includes discovery dry-run jobs and inference services created from this template.If empty, the default service account for the namespace is used. <code>resources</code> ResourceRequirements Resources defines the default container resource requirements applied to services derived from this template.Service-specific values override the template defaults. <code>modelSources</code> AIMModelSource array ModelSources specifies the model artifacts required to run this template.When provided, the discovery dry-run will be skipped and these sources will be used directly.This allows users to explicitly declare model dependencies without requiring a discovery job.If omitted, a discovery job will be run to automatically determine the required model sources. <code>profileId</code> string ProfileId is the specific AIM profile ID that this template should use"},{"location":"reference/crds/aim.silogen.ai/#aimdiscoveryprofilemetadata","title":"AIMDiscoveryProfileMetadata","text":"<p>AIMDiscoveryProfileMetadata describes the characteristics of a discovered deployment profile.</p> <p>Appears in: - AIMDiscoveryProfile</p> Field Description Default Validation <code>engine</code> string Engine identifies the inference engine used for this profile (e.g., \"vllm\", \"tgi\"). <code>gpu</code> string GPU specifies the GPU model this profile is optimized for (e.g., \"MI300X\", \"MI325X\"). <code>gpu_count</code> integer GPUCount indicates how many GPUs are required per replica for this profile. <code>metric</code> AIMMetric Metric indicates the optimization goal for this profile (\"latency\" or \"throughput\"). Enum: [latency throughput]  <code>precision</code> AIMPrecision Precision specifies the numeric precision used in this profile (e.g., \"fp16\", \"fp8\"). Enum: [bf16 fp16 fp8 int8 int4 fp4 fp32 auto]  <code>type</code> AIMProfileType Type specifies the optimization level of this profile"},{"location":"reference/crds/aim.silogen.ai/#aimgpuselector","title":"AIMGpuSelector","text":"<p>AIMGpuSelector specifies GPU requirements for a deployment. It defines the number and type of GPUs needed for each replica.</p> <p>Appears in: - AIMClusterServiceTemplateSpec - AIMRuntimeParameters - AIMServiceOverrides - AIMServiceTemplateSpec - AIMServiceTemplateSpecCommon</p> Field Description Default Validation <code>count</code> integer Count is the number of GPU resources requested per replica.Must be at least 1. Minimum: 1  <code>model</code> string Model is the GPU model name required for this deployment.Examples: \"MI300X\", \"MI325X\" MinLength: 1  <code>resourceName</code> string ResourceName is the Kubernetes resource name for GPU resources.Defaults to \"amd.com/gpu\" if not specified. amd.com/gpu"},{"location":"reference/crds/aim.silogen.ai/#aimkvcache","title":"AIMKVCache","text":"<p>AIMKVCache is the Schema for the KV caches API</p> <p>Appears in: - AIMKVCacheList</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.silogen.ai/v1alpha1</code> <code>kind</code> string <code>AIMKVCache</code> <code>metadata</code> ObjectMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>spec</code> AIMKVCacheSpec <code>status</code> AIMKVCacheStatus"},{"location":"reference/crds/aim.silogen.ai/#aimkvcachelist","title":"AIMKVCacheList","text":"<p>AIMKVCacheList contains a list of AIMKVCache</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.silogen.ai/v1alpha1</code> <code>kind</code> string <code>AIMKVCacheList</code> <code>metadata</code> ListMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>items</code> AIMKVCache array"},{"location":"reference/crds/aim.silogen.ai/#aimkvcachespec","title":"AIMKVCacheSpec","text":"<p>AIMKVCacheSpec defines the desired state of AIMKVCache</p> <p>Appears in: - AIMKVCache</p> Field Description Default Validation <code>kvCacheType</code> string KVCacheType specifies the type of key-value cache to create redis Enum: [redis]  <code>image</code> string Image specifies the container image to use for the KV cache service.If not specified, defaults to appropriate images based on KVCacheType:- redis: redis:7.2.4 <code>env</code> EnvVar array Env specifies environment variables to set in the KV cache container.If not specified (nil), no additional environment variables are set.If explicitly set to an empty array, no environment variables are added. <code>storage</code> StorageSpec Storage defines the persistent storage configuration for the KV cache <code>resources</code> ResourceRequirements Resources defines the resource requirements for the KV cache container.If not specified, defaults to 1 CPU and 1Gi memory for both requests and limits."},{"location":"reference/crds/aim.silogen.ai/#aimkvcachestatus","title":"AIMKVCacheStatus","text":"<p>AIMKVCacheStatus defines the observed state of AIMKVCache</p> <p>Appears in: - AIMKVCache</p> Field Description Default Validation <code>observedGeneration</code> integer <code>conditions</code> Condition array Conditions represent the latest available observations of the KV cache's state <code>status</code> AIMKVCacheStatusEnum Status represents the current status of the KV cache Pending Enum: [Pending Progressing Ready Failed]  <code>statefulSetName</code> string StatefulSetName represents the name of the created statefulset <code>serviceName</code> string ServiceName represents the name of the created service <code>endpoint</code> string Endpoint provides the connection information for accessing the KV cache.Format depends on the backend type (e.g., \"redis://service-name:6379\" for Redis). <code>replicas</code> integer Replicas is the total number of replicas configured for the StatefulSet. <code>readyReplicas</code> integer ReadyReplicas is the number of pods that are ready and serving traffic. <code>storageSize</code> string StorageSize represents the total storage capacity allocated for the KV cache.This reflects the size specified in the PersistentVolumeClaim. <code>lastError</code> string LastError contains details about the most recent error encountered.This field is cleared when the error is resolved."},{"location":"reference/crds/aim.silogen.ai/#aimkvcachestatusenum","title":"AIMKVCacheStatusEnum","text":"<p>Underlying type: string</p> <p>Validation: - Enum: [Pending Progressing Ready Failed]</p> <p>Appears in: - AIMKVCacheStatus</p> Field Description <code>Pending</code> AIMKVCacheStatusPending denotes that the KV cache is being created <code>Progressing</code> AIMKVCacheStatusProgressing denotes that the KV cache is being deployed <code>Ready</code> AIMKVCacheStatusReady denotes that the KV cache is ready to be used <code>Failed</code> AIMKVCacheStatusFailed denotes that the KV cache deployment has failed"},{"location":"reference/crds/aim.silogen.ai/#aimmetric","title":"AIMMetric","text":"<p>Underlying type: string</p> <p>AIMMetric enumerates the targeted service characteristic</p> <p>Validation: - Enum: [latency throughput]</p> <p>Appears in: - AIMClusterServiceTemplateSpec - AIMDiscoveryProfileMetadata - AIMProfileMetadata - AIMRuntimeParameters - AIMServiceOverrides - AIMServiceTemplateSpec - AIMServiceTemplateSpecCommon</p> Field Description <code>latency</code> <code>throughput</code>"},{"location":"reference/crds/aim.silogen.ai/#aimmodel","title":"AIMModel","text":"<p>AIMModel is the Schema for namespace-scoped AIM model catalog entries.</p> <p>Appears in: - AIMModelList</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.silogen.ai/v1alpha1</code> <code>kind</code> string <code>AIMModel</code> <code>metadata</code> ObjectMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>spec</code> AIMModelSpec <code>status</code> AIMModelStatus"},{"location":"reference/crds/aim.silogen.ai/#aimmodelcache","title":"AIMModelCache","text":"<p>AIMModelCache is the Schema for the modelcaches API</p> <p>Appears in: - AIMModelCacheList</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.silogen.ai/v1alpha1</code> <code>kind</code> string <code>AIMModelCache</code> <code>metadata</code> ObjectMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>spec</code> AIMModelCacheSpec <code>status</code> AIMModelCacheStatus"},{"location":"reference/crds/aim.silogen.ai/#aimmodelcachelist","title":"AIMModelCacheList","text":"<p>AIMModelCacheList contains a list of AIMModelCache</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.silogen.ai/v1alpha1</code> <code>kind</code> string <code>AIMModelCacheList</code> <code>metadata</code> ListMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>items</code> AIMModelCache array"},{"location":"reference/crds/aim.silogen.ai/#aimmodelcachespec","title":"AIMModelCacheSpec","text":"<p>AIMModelCacheSpec defines the desired state of AIMModelCache</p> <p>Appears in: - AIMModelCache</p> Field Description Default Validation <code>sourceUri</code> string SourceURI is the source of the model to be downloaded. This is the onlyidentifier MinLength: 1 Pattern: <code>^(hf\\|s3)://[^ \\t\\r\\n]+$</code> <code>storageClassName</code> string StorageClassName specifies the storage class for the cache volume <code>size</code> Quantity Size specifies the size of the cache volume <code>env</code> EnvVar array Env lists the environment variables to use for authentication when downloading models.These variables are used for authentication with model registries (e.g., HuggingFace tokens). <code>modelDownloadImage</code> string ModelDownloadImage is the image used to download the model kserve/storage-initializer:v0.16.0 <code>imagePullSecrets</code> LocalObjectReference array ImagePullSecrets references secrets for pulling AIM container images. <code>runtimeConfigName</code> string RuntimeConfigName references the AIM runtime configuration (by name) to use for this model cache.This determines PVC headroom and other runtime settings. default"},{"location":"reference/crds/aim.silogen.ai/#aimmodelcachestatus","title":"AIMModelCacheStatus","text":"<p>AIMModelCacheStatus defines the observed state of AIMModelCache</p> <p>Appears in: - AIMModelCache</p> Field Description Default Validation <code>observedGeneration</code> integer <code>conditions</code> Condition array Conditions represent the latest available observations of the model cache's state <code>status</code> AIMModelCacheStatusEnum Status represents the current status of the model cache Pending Enum: [Pending Progressing Available Failed]  <code>lastUsed</code> Time LastUsed represents the last time a model was deployed that used this cache <code>persistentVolumeClaim</code> string PersistentVolumeClaim represents the name of the created PVC"},{"location":"reference/crds/aim.silogen.ai/#aimmodelcachestatusenum","title":"AIMModelCacheStatusEnum","text":"<p>Underlying type: string</p> <p>Validation: - Enum: [Pending Progressing Available Failed]</p> <p>Appears in: - AIMModelCacheStatus - AIMResolvedModelCache</p> Field Description <code>Pending</code> AIMModelCacheStatusPending denotes that the model cache has not been created yet <code>Progressing</code> AIMModelCacheStatusProgressing denotes that the model cache is currently being filled <code>Available</code> AIMModelCacheStatusAvailable denotes that a model cache is filled and ready to be used <code>Failed</code> AIMModelCacheStatusFailed denotes that the model cache has failed. A more detailed reason will be available in the conditions."},{"location":"reference/crds/aim.silogen.ai/#aimmodelconfig","title":"AIMModelConfig","text":"<p>AIMModelConfig controls model creation and discovery behavior.</p> <p>Appears in: - AIMClusterRuntimeConfigSpec - AIMRuntimeConfigCommon - AIMRuntimeConfigSpec - AIMServiceSpec</p> Field Description Default Validation <code>autoDiscovery</code> boolean AutoDiscovery controls whether models run discovery by default.When true, models run discovery jobs to extract metadata and auto-create templates.When false, discovery is skipped. Discovery failures are non-fatal and reported via conditions. true"},{"location":"reference/crds/aim.silogen.ai/#aimmodeldiscoveryconfig","title":"AIMModelDiscoveryConfig","text":"<p>AIMModelDiscoveryConfig controls discovery behavior for a model.</p> <p>Appears in: - AIMModelSpec</p> Field Description Default Validation <code>enabled</code> boolean Enabled controls whether discovery runs for this model.When unset (nil), uses the runtime config's model.autoDiscovery setting.When true, discovery always runs regardless of runtime config.When false, discovery never runs regardless of runtime config. <code>autoCreateTemplates</code> boolean AutoCreateTemplates controls whether templates are auto-created from discovery results.When unset, templates are created if discovery succeeds and returns recommended deployments.When false, discovery runs but templates are not created (metadata extraction only).When true, templates are always created from discovery results."},{"location":"reference/crds/aim.silogen.ai/#aimmodellist","title":"AIMModelList","text":"<p>AIMModelList contains a list of AIMModel.</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.silogen.ai/v1alpha1</code> <code>kind</code> string <code>AIMModelList</code> <code>metadata</code> ListMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>items</code> AIMModel array"},{"location":"reference/crds/aim.silogen.ai/#aimmodelsource","title":"AIMModelSource","text":"<p>AIMModelSource describes a model artifact that must be downloaded for inference. Discovery extracts these from the container's configuration to enable caching and validation.</p> <p>Appears in: - AIMClusterServiceTemplateSpec - AIMServiceTemplateSpec - AIMServiceTemplateSpecCommon - AIMServiceTemplateStatus - AIMTemplateCacheSpec</p> Field Description Default Validation <code>name</code> string Name is a human-readable identifier for this model artifact.May be empty if the source represents the primary model. <code>sourceUri</code> string SourceURI is the location from which the model should be downloaded.Supported schemes:- hf://org/model - Hugging Face Hub model- s3://bucket/key - S3-compatible storage Pattern: <code>^(hf\\|s3)://[^ \\t\\r\\n]+$</code> <code>size</code> Quantity Size is the expected storage space required for this model artifact.Used for PVC sizing and capacity planning during cache creation."},{"location":"reference/crds/aim.silogen.ai/#aimmodelspec","title":"AIMModelSpec","text":"<p>AIMModelSpec defines the desired state of AIMModel.</p> <p>Appears in: - AIMClusterModel - AIMModel</p> Field Description Default Validation <code>image</code> string Image is the container image URI for this AIM model.This image is inspected by the operator to select runtime profiles used by templates.Discovery behavior is controlled by the discovery field and runtime config's AutoDiscovery setting. MinLength: 1  <code>discovery</code> AIMModelDiscoveryConfig Discovery controls discovery behavior for this model.When unset, uses runtime config defaults. <code>defaultServiceTemplate</code> string DefaultServiceTemplate is the default template to use for this image, if the user does not provide any <code>runtimeConfigName</code> string RuntimeConfigName references the AIM runtime configuration (by name) to use for this image.The runtime config controls discovery behavior and model creation scope. default <code>imagePullSecrets</code> LocalObjectReference array ImagePullSecrets lists secrets containing credentials for pulling the model container image.These secrets are used for:- OCI registry metadata extraction during discovery- Pulling the image for inference servicesThe secrets are merged with any runtime config defaults.For namespace-scoped models, secrets must exist in the same namespace.For cluster-scoped models, secrets must exist in the operator namespace. <code>serviceAccountName</code> string ServiceAccountName specifies the Kubernetes service account to use for workloads related to this model.This includes metadata extraction jobs and any other model-related operations.If empty, the default service account for the namespace is used. <code>resources</code> ResourceRequirements Resources defines the default resource requirements for services using this image.Template- or service-level values override these defaults."},{"location":"reference/crds/aim.silogen.ai/#aimmodelstatus","title":"AIMModelStatus","text":"<p>AIMModelStatus defines the observed state of AIMModel.</p> <p>Appears in: - AIMClusterModel - AIMModel</p> Field Description Default Validation <code>observedGeneration</code> integer ObservedGeneration is the most recent generation observed by the controller <code>status</code> AIMModelStatusEnum Status represents the overall status of the image based on its templates Pending Enum: [Pending Progressing Ready NotAvailable Degraded Failed]  <code>conditions</code> Condition array Conditions represent the latest available observations of the model's state <code>resolvedRuntimeConfig</code> AIMResolvedRuntimeConfig ResolvedRuntimeConfig captures metadata about the runtime config that was resolved. <code>imageMetadata</code> ImageMetadata ImageMetadata is the metadata extracted from an AIM image"},{"location":"reference/crds/aim.silogen.ai/#aimmodelstatusenum","title":"AIMModelStatusEnum","text":"<p>Underlying type: string</p> <p>AIMModelStatusEnum represents the overall status of an AIMModel.</p> <p>Validation: - Enum: [Pending Progressing Ready NotAvailable Degraded Failed]</p> <p>Appears in: - AIMModelStatus</p> Field Description <code>Pending</code> AIMModelStatusPending indicates the image has been created but template generation has not started. <code>Progressing</code> AIMModelStatusProgressing indicates one or more templates are still being discovered. <code>Ready</code> AIMModelStatusReady indicates all templates are available and ready. <code>NotAvailable</code> AIMModelStatusNotAvailable indicates all templates are not available (e.g., required GPUs not present in cluster). <code>Degraded</code> AIMModelStatusDegraded indicates one or more templates are degraded or failed. <code>Failed</code> AIMModelStatusFailed indicates all templates are degraded or failed."},{"location":"reference/crds/aim.silogen.ai/#aimprecision","title":"AIMPrecision","text":"<p>Underlying type: string</p> <p>AIMPrecision enumerates supported numeric precisions</p> <p>Validation: - Enum: [bf16 fp16 fp8 int8 int4 fp4 fp32 auto]</p> <p>Appears in: - AIMClusterServiceTemplateSpec - AIMDiscoveryProfileMetadata - AIMProfileMetadata - AIMRuntimeParameters - AIMServiceOverrides - AIMServiceTemplateSpec - AIMServiceTemplateSpecCommon</p> Field Description <code>auto</code> <code>fp4</code> <code>fp8</code> <code>fp16</code> <code>fp32</code> <code>bf16</code> <code>int4</code> <code>int8</code>"},{"location":"reference/crds/aim.silogen.ai/#aimprofile","title":"AIMProfile","text":"<p>AIMProfile contains the cached discovery results for a template. This is the processed and validated version of AIMDiscoveryProfile that is stored in the template's status after successful discovery.</p> <p>The profile serves as a cache of runtime configuration, eliminating the need to re-run discovery for each service that uses this template. Services and caching mechanisms reference this cached profile for deployment parameters and model sources.</p> <p>See discovery.go for AIMDiscoveryProfile (the raw discovery output) and the relationship between these types.</p> <p>Appears in: - AIMServiceTemplateStatus</p> Field Description Default Validation <code>engine_args</code> JSON EngineArgs contains runtime-specific engine configuration as a free-form JSON object.The structure depends on the inference engine being used (e.g., vLLM, TGI).These arguments are passed to the runtime container to configure model loading and inference. Schemaless: {}  <code>env_vars</code> object (keys:string, values:string) EnvVars contains environment variables required by the runtime for this profile.These may include engine-specific settings, optimization flags, or hardware configuration. <code>metadata</code> AIMProfileMetadata Refer to Kubernetes API documentation for fields of <code>metadata</code>."},{"location":"reference/crds/aim.silogen.ai/#aimprofilemetadata","title":"AIMProfileMetadata","text":"<p>AIMProfileMetadata describes the characteristics of a cached deployment profile. This is identical to AIMDiscoveryProfileMetadata but exists in the template status namespace.</p> <p>Appears in: - AIMProfile - AIMServiceResolvedTemplateProfile</p> Field Description Default Validation <code>engine</code> string Engine identifies the inference engine used for this profile (e.g., \"vllm\", \"tgi\"). <code>gpu</code> string GPU specifies the GPU model this profile is optimized for (e.g., \"MI300X\", \"MI325X\"). <code>gpuCount</code> integer GPUCount indicates how many GPUs are required per replica for this profile. <code>metric</code> AIMMetric Metric indicates the optimization goal for this profile (\"latency\" or \"throughput\"). Enum: [latency throughput]  <code>precision</code> AIMPrecision Precision specifies the numeric precision used in this profile (e.g., \"fp16\", \"fp8\"). Enum: [bf16 fp16 fp8 int8 int4 fp4 fp32 auto]  <code>type</code> AIMProfileType Type specifies the designation of the profile"},{"location":"reference/crds/aim.silogen.ai/#aimprofiletype","title":"AIMProfileType","text":"<p>Underlying type: string</p> <p>Appears in: - AIMDiscoveryProfileMetadata - AIMProfileMetadata</p> Field Description <code>optimized</code> <code>unoptimized</code> <code>preview</code>"},{"location":"reference/crds/aim.silogen.ai/#aimresolutionscope","title":"AIMResolutionScope","text":"<p>Underlying type: string</p> <p>AIMResolutionScope describes the scope of a resolved reference.</p> <p>Validation: - Enum: [Namespace Cluster Merged Unknown]</p> <p>Appears in: - AIMResolvedReference - AIMResolvedRuntimeConfig - AIMServiceResolvedTemplate</p> Field Description <code>Namespace</code> AIMResolutionScopeNamespace denotes a namespace-scoped resource. <code>Cluster</code> AIMResolutionScopeCluster denotes a cluster-scoped resource. <code>Merged</code> AIMResolutionScopeMerged denotes that both cluster and namespace configs were merged. <code>Unknown</code> AIMResolutionScopeUnknown denotes that the scope could not be determined."},{"location":"reference/crds/aim.silogen.ai/#aimresolvedmodelcache","title":"AIMResolvedModelCache","text":"<p>AIMResolvedModelCache contains reference info and status for a cached model.</p> <p>Appears in: - AIMServiceStatus - AIMTemplateCacheStatus</p> Field Description Default Validation <code>uid</code> string UID of the AIMModelCache resource <code>name</code> string Name of the AIMModelCache resource <code>model</code> string Model is the name of the model that is cached <code>status</code> AIMModelCacheStatusEnum Status of the model cache Enum: [Pending Progressing Available Failed]  <code>persistentVolumeClaim</code> string PersistentVolumeClaim name if available <code>mountPoint</code> string MountPoint is the mount point for the model cache"},{"location":"reference/crds/aim.silogen.ai/#aimresolvedreference","title":"AIMResolvedReference","text":"<p>AIMResolvedReference captures metadata about a resolved reference.</p> <p>Appears in: - AIMResolvedRuntimeConfig - AIMServiceResolvedTemplate - AIMServiceStatus - AIMServiceTemplateStatus</p> Field Description Default Validation <code>name</code> string Name is the resource name that satisfied the reference. <code>namespace</code> string Namespace identifies where the resource was found when namespace-scoped.Empty indicates a cluster-scoped resource. <code>scope</code> AIMResolutionScope Scope indicates whether the resolved resource was namespace or cluster scoped. Enum: [Namespace Cluster Merged Unknown]  <code>kind</code> string Kind is the fully-qualified kind of the resolved reference, when known. <code>uid</code> UID UID captures the unique identifier of the resolved reference, when known."},{"location":"reference/crds/aim.silogen.ai/#aimresolvedruntimeconfig","title":"AIMResolvedRuntimeConfig","text":"<p>AIMResolvedRuntimeConfig captures metadata about the runtime config that was resolved. This follows the same pattern as AIMServiceResolvedTemplate for consistency.</p> <p>Appears in: - AIMModelStatus - AIMServiceStatus - AIMServiceTemplateStatus - AIMTemplateCacheStatus</p> Field Description Default Validation <code>name</code> string Name is the resource name that satisfied the reference. <code>namespace</code> string Namespace identifies where the resource was found when namespace-scoped.Empty indicates a cluster-scoped resource. <code>scope</code> AIMResolutionScope Scope indicates whether the resolved resource was namespace or cluster scoped. Enum: [Namespace Cluster Merged Unknown]  <code>kind</code> string Kind is the fully-qualified kind of the resolved reference, when known. <code>uid</code> UID UID captures the unique identifier of the resolved reference, when known."},{"location":"reference/crds/aim.silogen.ai/#aimruntimeconfig","title":"AIMRuntimeConfig","text":"<p>AIMRuntimeConfig defines namespace-scoped runtime overrides for AIM resources.</p> <p>Appears in: - AIMRuntimeConfigList</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.silogen.ai/v1alpha1</code> <code>kind</code> string <code>AIMRuntimeConfig</code> <code>metadata</code> ObjectMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>spec</code> AIMRuntimeConfigSpec <code>status</code> AIMRuntimeConfigStatus"},{"location":"reference/crds/aim.silogen.ai/#aimruntimeconfigcommon","title":"AIMRuntimeConfigCommon","text":"<p>AIMRuntimeConfigCommon captures configuration fields shared across cluster and namespace scopes. These settings apply to both AIMRuntimeConfig (namespace-scoped) and AIMClusterRuntimeConfig (cluster-scoped).</p> <p>Appears in: - AIMClusterRuntimeConfigSpec - AIMRuntimeConfigSpec - AIMServiceSpec</p> Field Description Default Validation <code>defaultStorageClassName</code> string DefaultStorageClassName specifies the storage class to use for model caches and PVCswhen the consuming resource (AIMModelCache, AIMTemplateCache, AIMServiceTemplate) does notspecify a storage class. If this field is empty, the cluster's default storage class is used. <code>model</code> AIMModelConfig Model controls model creation and discovery defaults. <code>routing</code> AIMRuntimeRoutingConfig Routing controls HTTP routing defaults applied to AIM resources.When set, these defaults are used for AIMService resources that enable routingbut do not specify their own routing configuration. <code>pvcHeadroomPercent</code> integer PVCHeadroomPercent specifies the percentage of extra space to add to PVCsfor model storage. This accounts for filesystem overhead and temporary filesduring model loading. The value represents a percentage (e.g., 10 means 10% extra space).If not specified, defaults to 10%. Minimum: 0  <code>labelPropagation</code> AIMRuntimeConfigLabelPropagationSpec LabelPropagation controls how labels from parent AIM resources are propagated to child resources.When enabled, labels matching the specified patterns are automatically copied from parent resources(e.g., AIMService, AIMTemplateCache) to their child resources (e.g., Deployments, Services, PVCs).This is useful for propagating organizational metadata like cost centers, team identifiers,or compliance labels through the resource hierarchy. <code>env</code> EnvVar array Env specifies environment variables to use for the runtime config.These variables are used for the runtime config and are not propagated to child resources.If configmaps or secrets are referenced, they need to exist in the namespace referencing this runtime config.For cluster scoped runtime configs, any referenced configmaps or secrets need to exist in the system namespace."},{"location":"reference/crds/aim.silogen.ai/#aimruntimeconfiglabelpropagationspec","title":"AIMRuntimeConfigLabelPropagationSpec","text":"<p>Appears in: - AIMClusterRuntimeConfigSpec - AIMRuntimeConfigCommon - AIMRuntimeConfigSpec - AIMServiceSpec</p> Field Description Default Validation <code>enabled</code> boolean Enabled, if true, allows propagating parent labels to all child resources it creates directlyOnly label keys that match the ones in Match are propagated. false <code>match</code> string array Match is a list of label keys that will be propagated to any child resources created.Wildcards are supported, so for example <code>org.my/my-key-*</code> would match any label with that prefix."},{"location":"reference/crds/aim.silogen.ai/#aimruntimeconfiglist","title":"AIMRuntimeConfigList","text":"<p>AIMRuntimeConfigList contains a list of AIMRuntimeConfig.</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.silogen.ai/v1alpha1</code> <code>kind</code> string <code>AIMRuntimeConfigList</code> <code>metadata</code> ListMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>items</code> AIMRuntimeConfig array"},{"location":"reference/crds/aim.silogen.ai/#aimruntimeconfigspec","title":"AIMRuntimeConfigSpec","text":"<p>AIMRuntimeConfigSpec defines namespace-scoped overrides for AIM resources.</p> <p>Appears in: - AIMRuntimeConfig</p> Field Description Default Validation <code>defaultStorageClassName</code> string DefaultStorageClassName specifies the storage class to use for model caches and PVCswhen the consuming resource (AIMModelCache, AIMTemplateCache, AIMServiceTemplate) does notspecify a storage class. If this field is empty, the cluster's default storage class is used. <code>model</code> AIMModelConfig Model controls model creation and discovery defaults. <code>routing</code> AIMRuntimeRoutingConfig Routing controls HTTP routing defaults applied to AIM resources.When set, these defaults are used for AIMService resources that enable routingbut do not specify their own routing configuration. <code>pvcHeadroomPercent</code> integer PVCHeadroomPercent specifies the percentage of extra space to add to PVCsfor model storage. This accounts for filesystem overhead and temporary filesduring model loading. The value represents a percentage (e.g., 10 means 10% extra space).If not specified, defaults to 10%. Minimum: 0  <code>labelPropagation</code> AIMRuntimeConfigLabelPropagationSpec LabelPropagation controls how labels from parent AIM resources are propagated to child resources.When enabled, labels matching the specified patterns are automatically copied from parent resources(e.g., AIMService, AIMTemplateCache) to their child resources (e.g., Deployments, Services, PVCs).This is useful for propagating organizational metadata like cost centers, team identifiers,or compliance labels through the resource hierarchy. <code>env</code> EnvVar array Env specifies environment variables to use for the runtime config.These variables are used for the runtime config and are not propagated to child resources.If configmaps or secrets are referenced, they need to exist in the namespace referencing this runtime config.For cluster scoped runtime configs, any referenced configmaps or secrets need to exist in the system namespace."},{"location":"reference/crds/aim.silogen.ai/#aimruntimeconfigstatus","title":"AIMRuntimeConfigStatus","text":"<p>AIMRuntimeConfigStatus records the resolved config reference surfaced to consumers.</p> <p>Appears in: - AIMClusterRuntimeConfig - AIMRuntimeConfig</p> Field Description Default Validation <code>observedGeneration</code> integer ObservedGeneration is the last reconciled generation. <code>conditions</code> Condition array Conditions communicate reconciliation progress."},{"location":"reference/crds/aim.silogen.ai/#aimruntimeparameters","title":"AIMRuntimeParameters","text":"<p>AIMRuntimeParameters contains the runtime configuration parameters shared across templates and services. Fields use pointers to allow optional usage in different contexts (required in templates, optional in service overrides).</p> <p>Appears in: - AIMClusterServiceTemplateSpec - AIMServiceOverrides - AIMServiceTemplateSpec - AIMServiceTemplateSpecCommon</p> Field Description Default Validation <code>metric</code> AIMMetric Metric selects the optimization goal.- <code>latency</code>: prioritize low end\u2011to\u2011end latency- <code>throughput</code>: prioritize sustained requests/second Enum: [latency throughput]  <code>precision</code> AIMPrecision Precision selects the numeric precision used by the runtime. Enum: [auto fp4 fp8 fp16 fp32 bf16 int4 int8]  <code>gpuSelector</code> AIMGpuSelector GpuSelector specifies GPU requirements for each replica.Defines the GPU count and model type required for deployment.This field is immutable after creation."},{"location":"reference/crds/aim.silogen.ai/#aimruntimeroutingconfig","title":"AIMRuntimeRoutingConfig","text":"<p>AIMRuntimeRoutingConfig configures HTTP routing defaults for inference services. These settings control how Gateway API HTTPRoutes are created and configured.</p> <p>Appears in: - AIMClusterRuntimeConfigSpec - AIMRuntimeConfigCommon - AIMRuntimeConfigSpec - AIMServiceSpec</p> Field Description Default Validation <code>enabled</code> boolean Enabled controls whether HTTP routing is managed for inference services using this config.When true, the operator creates HTTPRoute resources for services that reference this config.When false or unset, routing must be explicitly enabled on each service.This provides a namespace or cluster-wide default that individual services can override. <code>gatewayRef</code> ParentReference GatewayRef specifies the Gateway API Gateway resource that should receive HTTPRoutes.This identifies the parent gateway for routing traffic to inference services.The gateway can be in any namespace (cross-namespace references are supported).If routing is enabled but GatewayRef is not specified, service reconciliation will failwith a validation error. <code>pathTemplate</code> string PathTemplate defines the HTTP path template for routes, evaluated using JSONPath expressions.The template is rendered against the AIMService object to generate unique paths.Example templates:- <code>/\\{.metadata.namespace\\}/\\{.metadata.name\\}</code> - namespace and service name- <code>/\\{.metadata.namespace\\}/\\{.metadata.labels['team']\\}/inference</code> - with label- <code>/models/\\{.spec.aimModelName\\}</code> - based on model nameThe template must:- Use valid JSONPath expressions wrapped in {...}- Reference fields that exist on the service- Produce a path \u2264 200 characters after rendering- Result in valid URL path segments (lowercase, RFC 1123 compliant)If evaluation fails, the service enters Degraded state with PathTemplateInvalid reason.Individual services can override this template via spec.Routing.pathTemplate. <code>annotations</code> object (keys:string, values:string) Annotations defines additional annotations to add to the HTTPRoute resource.These annotations can be used for various purposes such as configuring ingressbehavior, adding metadata, or triggering external integrations.Individual services can override these via spec.routing.annotations. <code>requestTimeout</code> Duration RequestTimeout defines the HTTP request timeout for routes.This sets the maximum duration for a request to complete before timing out.The timeout applies to the entire request/response cycle.If not specified, no timeout is set on the route.Individual services can override this value via spec.routing.requestTimeout."},{"location":"reference/crds/aim.silogen.ai/#aimservice","title":"AIMService","text":"<p>AIMService manages a KServe-based AIM inference service for the selected model and template.</p> <p>Appears in: - AIMServiceList</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.silogen.ai/v1alpha1</code> <code>kind</code> string <code>AIMService</code> <code>metadata</code> ObjectMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>spec</code> AIMServiceSpec <code>status</code> AIMServiceStatus"},{"location":"reference/crds/aim.silogen.ai/#aimserviceautoscaling","title":"AIMServiceAutoScaling","text":"<p>AIMServiceAutoScaling mirrors KServe's AutoScalingSpec for advanced autoscaling configuration. Supports custom metrics from various backends including Prometheus, OpenTelemetry, and KEDA.</p> <p>Appears in: - AIMServiceSpec</p> Field Description Default Validation <code>metrics</code> AIMServiceMetricsSpec array Metrics is a list of metrics spec to be used for autoscaling.Each metric defines a source (Resource, External, or PodMetric) and target values."},{"location":"reference/crds/aim.silogen.ai/#aimservicekvcache","title":"AIMServiceKVCache","text":"<p>AIMServiceKVCache specifies KV cache configuration for the service. The controller will use an existing AIMKVCache if found, otherwise it will create one.</p> <p>Appears in: - AIMServiceSpec</p> Field Description Default Validation <code>name</code> string Name specifies the name of the AIMKVCache resource to use.If an AIMKVCache with this name exists, it will be used.If it doesn't exist, a new AIMKVCache will be created with this name.If not specified, defaults to \"kvcache-{namespace}\". <code>type</code> string Type specifies the type of KV cache backend.Only used when creating a new AIMKVCache (ignored if referencing existing). redis Enum: [redis]  <code>image</code> string Image specifies the container image to use for the KV cache service.Only used when creating a new AIMKVCache (ignored if referencing existing).If not specified, defaults to appropriate images based on Type. <code>env</code> EnvVar array Env specifies environment variables to set in the KV cache container.Only used when creating a new AIMKVCache (ignored if referencing existing).If not specified (nil), no additional environment variables are set.If explicitly set to an empty array, no environment variables are added. <code>storage</code> StorageSpec Storage defines the persistent storage configuration for the KV cache.Only used when creating a new AIMKVCache (ignored if referencing existing). <code>resources</code> ResourceRequirements Resources defines the resource requirements for the KV cache container.Only used when creating a new AIMKVCache (ignored if referencing existing).If not specified, defaults to 1 CPU and 1Gi memory for both requests and limits. <code>lmCacheConfig</code> string LMCacheConfig specifies the custom LMCache configuration YAML content.When specified, this exact configuration is used for the lmcache_config.yaml file.When empty, a default configuration is generated with standard LMCache settings.Note: The remote_url field in custom configs will have the {SERVICE_URL} placeholderreplaced with the actual KV cache service URL."},{"location":"reference/crds/aim.silogen.ai/#aimservicelist","title":"AIMServiceList","text":"<p>AIMServiceList contains a list of AIMService.</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.silogen.ai/v1alpha1</code> <code>kind</code> string <code>AIMServiceList</code> <code>metadata</code> ListMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>items</code> AIMService array"},{"location":"reference/crds/aim.silogen.ai/#aimservicemetrictarget","title":"AIMServiceMetricTarget","text":"<p>AIMServiceMetricTarget defines the target value for a metric. Specifies how the metric value should be interpreted and what target to maintain.</p> <p>Appears in: - AIMServicePodMetricSource</p> Field Description Default Validation <code>type</code> string Type specifies how to interpret the metric value.\"Value\": absolute value target (use Value field)\"AverageValue\": average value across all pods (use AverageValue field)\"Utilization\": percentage utilization for resource metrics (use AverageUtilization field) Enum: [Value AverageValue Utilization]  <code>value</code> string Value is the target value of the metric (as a quantity).Used when Type is \"Value\".Example: \"1\" for 1 request, \"100m\" for 100 millicores <code>averageValue</code> string AverageValue is the target value of the average of the metric across all relevant pods (as a quantity).Used when Type is \"AverageValue\".Example: \"100m\" for 100 millicores per pod <code>averageUtilization</code> integer AverageUtilization is the target value of the average of the resource metric across all relevant pods,represented as a percentage of the requested value of the resource for the pods.Used when Type is \"Utilization\". Only valid for Resource metric source type.Example: 80 for 80% utilization"},{"location":"reference/crds/aim.silogen.ai/#aimservicemetricsspec","title":"AIMServiceMetricsSpec","text":"<p>AIMServiceMetricsSpec defines a single metric for autoscaling. Specifies the metric source type and configuration.</p> <p>Appears in: - AIMServiceAutoScaling</p> Field Description Default Validation <code>type</code> string Type is the type of metric source.Valid values: \"PodMetric\" (per-pod custom metrics). Features to come: Resource, External Enum: [PodMetric]  <code>podmetric</code> AIMServicePodMetricSource PodMetric refers to a metric describing each pod in the current scale target.Used when Type is \"PodMetric\". Supports backends like OpenTelemetry for custom metrics."},{"location":"reference/crds/aim.silogen.ai/#aimservicemodel","title":"AIMServiceModel","text":"<p>AIMServiceModel specifies which model to deploy. Exactly one field must be set.</p> <p>Appears in: - AIMServiceSpec</p> Field Description Default Validation <code>ref</code> string Ref references an existing AIMModel or AIMClusterModel by metadata.name.The controller looks for a namespace-scoped AIMModel first, then falls back to cluster-scoped AIMClusterModel.Example: <code>meta-llama-3-8b</code>. <code>image</code> string Image specifies a container image URI directly.The controller searches for an existing model with this image, or creates one if none exists.The scope of the created model is controlled by the runtime config's ModelCreationScope field.Example: <code>ghcr.io/silogen/llama-3-8b:v1.2.0</code>."},{"location":"reference/crds/aim.silogen.ai/#aimserviceoverrides","title":"AIMServiceOverrides","text":"<p>AIMServiceOverrides allows overriding template parameters at the service level. All fields are optional. When specified, they override the corresponding values from the referenced AIMServiceTemplate.</p> <p>Appears in: - AIMServiceSpec</p> Field Description Default Validation <code>metric</code> AIMMetric Metric selects the optimization goal.- <code>latency</code>: prioritize low end\u2011to\u2011end latency- <code>throughput</code>: prioritize sustained requests/second Enum: [latency throughput]  <code>precision</code> AIMPrecision Precision selects the numeric precision used by the runtime. Enum: [auto fp4 fp8 fp16 fp32 bf16 int4 int8]  <code>gpuSelector</code> AIMGpuSelector GpuSelector specifies GPU requirements for each replica.Defines the GPU count and model type required for deployment.This field is immutable after creation."},{"location":"reference/crds/aim.silogen.ai/#aimservicepodmetric","title":"AIMServicePodMetric","text":"<p>AIMServicePodMetric identifies the pod metric and its backend. Supports multiple metrics backends including OpenTelemetry, Prometheus, etc.</p> <p>Appears in: - AIMServicePodMetricSource</p> Field Description Default Validation <code>backend</code> string Backend defines the metrics backend to use.If not specified, defaults to \"opentelemetry\". opentelemetry Enum: [opentelemetry]  <code>serverAddress</code> string ServerAddress specifies the address of the metrics backend server.If not specified, defaults to \"keda-otel-scaler.keda.svc:4317\" for OpenTelemetry backend. <code>metricNames</code> string array MetricNames specifies which metrics to collect from pods and send to ServerAddress.Example: [\"vllm:num_requests_running\"] <code>query</code> string Query specifies the query to run to retrieve metrics from the backend.The query syntax depends on the backend being used.Example: \"vllm:num_requests_running\" for OpenTelemetry. <code>operationOverTime</code> string OperationOverTime specifies the operation to aggregate metrics over time.Valid values: \"last_one\", \"avg\", \"max\", \"min\", \"rate\", \"count\"Default: \"last_one\""},{"location":"reference/crds/aim.silogen.ai/#aimservicepodmetricsource","title":"AIMServicePodMetricSource","text":"<p>AIMServicePodMetricSource defines pod-level metrics configuration. Specifies the metric identification and target values for pod-based autoscaling.</p> <p>Appears in: - AIMServiceMetricsSpec</p> Field Description Default Validation <code>metric</code> AIMServicePodMetric Metric contains the metric identification and backend configuration.Defines which metrics to collect and how to query them. <code>target</code> AIMServiceMetricTarget Target specifies the target value for the metric.The autoscaler will scale to maintain this target value."},{"location":"reference/crds/aim.silogen.ai/#aimserviceresolvedtemplate","title":"AIMServiceResolvedTemplate","text":"<p>AIMServiceResolvedTemplate retains the historical name while reusing the shared structure.</p> <p>Appears in: - AIMServiceStatus</p> Field Description Default Validation <code>name</code> string Name is the resource name that satisfied the reference. <code>namespace</code> string Namespace identifies where the resource was found when namespace-scoped.Empty indicates a cluster-scoped resource. <code>scope</code> AIMResolutionScope Scope indicates whether the resolved resource was namespace or cluster scoped. Enum: [Namespace Cluster Merged Unknown]  <code>kind</code> string Kind is the fully-qualified kind of the resolved reference, when known. <code>uid</code> UID UID captures the unique identifier of the resolved reference, when known. <code>profile</code> AIMServiceResolvedTemplateProfile Profile is the profile that the resolved template points to"},{"location":"reference/crds/aim.silogen.ai/#aimserviceresolvedtemplateprofile","title":"AIMServiceResolvedTemplateProfile","text":"<p>Appears in: - AIMServiceResolvedTemplate</p> Field Description Default Validation <code>metadata</code> AIMProfileMetadata Refer to Kubernetes API documentation for fields of <code>metadata</code>."},{"location":"reference/crds/aim.silogen.ai/#aimserviceroutingstatus","title":"AIMServiceRoutingStatus","text":"<p>AIMServiceRoutingStatus captures observed routing details.</p> <p>Appears in: - AIMServiceStatus</p> Field Description Default Validation <code>path</code> string Path is the HTTP path prefix used when routing is enabled.Example: <code>/tenant/svc-uuid</code>."},{"location":"reference/crds/aim.silogen.ai/#aimservicespec","title":"AIMServiceSpec","text":"<p>AIMServiceSpec defines the desired state of AIMService.</p> <p>Binds a canonical model to an AIMServiceTemplate and configures replicas, caching behavior, and optional overrides. The template governs the base runtime selection knobs, while the overrides field allows service-specific customization.</p> <p>Appears in: - AIMService</p> Field Description Default Validation <code>model</code> AIMServiceModel Model specifies which model to deploy using one of the available reference methods.Use <code>ref</code> to reference an existing AIMModel/AIMClusterModel by name, or use <code>image</code>to specify a container image URI directly (which will auto-create a model if needed). <code>templateRef</code> string TemplateRef is the name of the AIMServiceTemplate or AIMClusterServiceTemplate to use.The template selects the runtime profile and GPU parameters. <code>template</code> AIMServiceTemplateConfig Template contains the AIMServiceTemplate selection configuration <code>cacheModel</code> boolean CacheModel requests that model sources be cached when starting the serviceif the template itself does not warm the cache.When <code>warmCache: false</code> on the template, this setting ensures caching isperformed before the service becomes ready. false <code>replicas</code> integer Replicas overrides the number of replicas for this service.Other runtime settings remain governed by the template unless overridden. 1 <code>minReplicas</code> integer MinReplicas specifies the minimum number of replicas for autoscaling.Defaults to 1. Scale to zero not supported.When specified with MaxReplicas, enables autoscaling for the service. Minimum: 1  <code>maxReplicas</code> integer MaxReplicas specifies the maximum number of replicas for autoscaling.Required when MinReplicas is set or when AutoScaling configuration is provided. Minimum: 1  <code>autoScaling</code> AIMServiceAutoScaling AutoScaling configures advanced autoscaling behavior using HPA or KEDA.Supports custom metrics from various backends (Prometheus, OpenTelemetry, etc.)When specified, MinReplicas and MaxReplicas should also be set. <code>runtimeConfigName</code> string RuntimeConfigName references the AIM runtime configuration (by name) to use for this service. default <code>resources</code> ResourceRequirements Resources overrides the container resource requirements for this service.When specified, these values take precedence over the template and image defaults. <code>kvCache</code> AIMServiceKVCache KVCache specifies KV cache configuration for the service.When specified, enables LMCache with the configured KV cache backend. <code>overrides</code> AIMServiceOverrides Overrides allows overriding specific template parameters for this service.When specified, these values take precedence over the template values. <code>imagePullSecrets</code> LocalObjectReference array ImagePullSecrets references secrets for pulling AIM container images. <code>serviceAccountName</code> string ServiceAccountName specifies the Kubernetes service account to use for the inference workload.This service account is used by the deployed inference pods.If empty, the default service account for the namespace is used. <code>defaultStorageClassName</code> string DefaultStorageClassName specifies the storage class to use for model caches and PVCswhen the consuming resource (AIMModelCache, AIMTemplateCache, AIMServiceTemplate) does notspecify a storage class. If this field is empty, the cluster's default storage class is used. <code>model</code> AIMModelConfig Model controls model creation and discovery defaults. <code>routing</code> AIMRuntimeRoutingConfig Routing controls HTTP routing defaults applied to AIM resources.When set, these defaults are used for AIMService resources that enable routingbut do not specify their own routing configuration. <code>pvcHeadroomPercent</code> integer PVCHeadroomPercent specifies the percentage of extra space to add to PVCsfor model storage. This accounts for filesystem overhead and temporary filesduring model loading. The value represents a percentage (e.g., 10 means 10% extra space).If not specified, defaults to 10%. Minimum: 0  <code>labelPropagation</code> AIMRuntimeConfigLabelPropagationSpec LabelPropagation controls how labels from parent AIM resources are propagated to child resources.When enabled, labels matching the specified patterns are automatically copied from parent resources(e.g., AIMService, AIMTemplateCache) to their child resources (e.g., Deployments, Services, PVCs).This is useful for propagating organizational metadata like cost centers, team identifiers,or compliance labels through the resource hierarchy. <code>env</code> EnvVar array Env specifies environment variables to use for the runtime config.These variables are used for the runtime config and are not propagated to child resources.If configmaps or secrets are referenced, they need to exist in the namespace referencing this runtime config.For cluster scoped runtime configs, any referenced configmaps or secrets need to exist in the system namespace."},{"location":"reference/crds/aim.silogen.ai/#aimservicestatus","title":"AIMServiceStatus","text":"<p>AIMServiceStatus defines the observed state of AIMService.</p> <p>Appears in: - AIMService</p> Field Description Default Validation <code>observedGeneration</code> integer ObservedGeneration is the most recent generation observed by the controller. <code>conditions</code> Condition array Conditions represent the latest observations of template state. <code>resolvedRuntimeConfig</code> AIMResolvedRuntimeConfig ResolvedRuntimeConfig captures metadata about the runtime config that was resolved. <code>resolvedImage</code> AIMResolvedReference ResolvedImage captures metadata about the image that was resolved. <code>status</code> AIMServiceStatusEnum Status represents the current high\u2011level status of the service lifecycle.Values: <code>Pending</code>, <code>Starting</code>, <code>Running</code>, <code>Failed</code>, <code>Degraded</code>. Pending Enum: [Pending Starting Running Failed Degraded]  <code>routing</code> AIMServiceRoutingStatus Routing surfaces information about the configured HTTP routing, when enabled. <code>resolvedTemplate</code> AIMServiceResolvedTemplate ResolvedTemplate captures metadata about the template that satisfied the reference. <code>resolvedTemplateCache</code> AIMResolvedReference ResolvedTemplateCache captures metadata about the template cache being used, if any. <code>modelCaches</code> object (keys:string, values:AIMResolvedModelCache) ModelCaches maps model names to their resolved AIMModelCache resources if they exist. <code>resolvedKVCache</code> AIMResolvedReference ResolvedKVCache captures metadata about the KV cache being used, if any. <code>templateMatching</code> AIMTemplateMatchingStatus TemplateMatching provides detailed information about template selection,including which templates were evaluated and why each was chosen or rejected."},{"location":"reference/crds/aim.silogen.ai/#aimservicestatusenum","title":"AIMServiceStatusEnum","text":"<p>Underlying type: string</p> <p>AIMServiceStatusEnum defines coarse-grained states for a service.</p> <p>Validation: - Enum: [Pending Starting Running Failed Degraded]</p> <p>Appears in: - AIMServiceStatus</p> Field Description <code>Pending</code> AIMServiceStatusPending denotes that the template has been created and discovery has not yet started. <code>Starting</code> AIMServiceStatusStarting denotes that discovery and/or cache warm is in progress. <code>Running</code> AIMServiceStatusRunning denotes that discovery succeeded and, if requested, caches are warmed. <code>Failed</code> AIMServiceStatusFailed denotes a terminal failure for discovery or warm operations. <code>Degraded</code> AIMServiceStatusDegraded denotes a recoverable failure state."},{"location":"reference/crds/aim.silogen.ai/#aimservicetemplate","title":"AIMServiceTemplate","text":"<p>Appears in: - AIMServiceTemplateList</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.silogen.ai/v1alpha1</code> <code>kind</code> string <code>AIMServiceTemplate</code> <code>metadata</code> ObjectMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>spec</code> AIMServiceTemplateSpec <code>status</code> AIMServiceTemplateStatus"},{"location":"reference/crds/aim.silogen.ai/#aimservicetemplateconfig","title":"AIMServiceTemplateConfig","text":"<p>Appears in: - AIMServiceSpec</p> Field Description Default Validation <code>allowUnoptimized</code> boolean AllowUnoptimized, if true, will allow automatic selection of templates that resolve to an unoptimized profile."},{"location":"reference/crds/aim.silogen.ai/#aimservicetemplatelist","title":"AIMServiceTemplateList","text":"Field Description Default Validation <code>apiVersion</code> string <code>aim.silogen.ai/v1alpha1</code> <code>kind</code> string <code>AIMServiceTemplateList</code> <code>metadata</code> ListMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>items</code> AIMServiceTemplate array"},{"location":"reference/crds/aim.silogen.ai/#aimservicetemplatespec","title":"AIMServiceTemplateSpec","text":"<p>AIMServiceTemplateSpec defines the desired state of AIMServiceTemplate (namespace-scoped).</p> <p>A namespaced and versioned template that selects a runtime profile for a given AIM model (by canonical name). Templates are intentionally narrow: they describe runtime selection knobs for the AIM container and do not redefine the full Kubernetes deployment shape.</p> <p>Appears in: - AIMServiceTemplate</p> Field Description Default Validation <code>modelName</code> string ModelName is the model name. Matches <code>metadata.name</code> of an AIMModel or AIMClusterModel. Immutable.Example: <code>meta/llama-3-8b:1.1+20240915</code> MinLength: 1  <code>metric</code> AIMMetric Metric selects the optimization goal.- <code>latency</code>: prioritize low end\u2011to\u2011end latency- <code>throughput</code>: prioritize sustained requests/second Enum: [latency throughput]  <code>precision</code> AIMPrecision Precision selects the numeric precision used by the runtime. Enum: [auto fp4 fp8 fp16 fp32 bf16 int4 int8]  <code>gpuSelector</code> AIMGpuSelector GpuSelector specifies GPU requirements for each replica.Defines the GPU count and model type required for deployment.This field is immutable after creation. <code>runtimeConfigName</code> string RuntimeConfigName references the AIM runtime configuration (by name) to use for this template. default <code>imagePullSecrets</code> LocalObjectReference array ImagePullSecrets lists secrets containing credentials for pulling container images.These secrets are used for:- Discovery dry-run jobs that inspect the model container- Pulling the image for inference servicesThe secrets are merged with any model or runtime config defaults.For namespace-scoped templates, secrets must exist in the same namespace.For cluster-scoped templates, secrets must exist in the operator namespace. <code>serviceAccountName</code> string ServiceAccountName specifies the Kubernetes service account to use for workloads related to this template.This includes discovery dry-run jobs and inference services created from this template.If empty, the default service account for the namespace is used. <code>resources</code> ResourceRequirements Resources defines the default container resource requirements applied to services derived from this template.Service-specific values override the template defaults. <code>modelSources</code> AIMModelSource array ModelSources specifies the model artifacts required to run this template.When provided, the discovery dry-run will be skipped and these sources will be used directly.This allows users to explicitly declare model dependencies without requiring a discovery job.If omitted, a discovery job will be run to automatically determine the required model sources. <code>profileId</code> string ProfileId is the specific AIM profile ID that this template should use <code>caching</code> AIMTemplateCachingConfig Caching configures model caching behavior for this namespace-scoped template.When enabled, models will be cached using the specified environment variablesduring download. <code>env</code> EnvVar array Env specifies environment variables to use for authentication when downloading models.These variables are used for authentication with model registries (e.g., HuggingFace tokens)."},{"location":"reference/crds/aim.silogen.ai/#aimservicetemplatespeccommon","title":"AIMServiceTemplateSpecCommon","text":"<p>AIMServiceTemplateSpecCommon contains the shared fields for both cluster-scoped and namespace-scoped service templates.</p> <p>Appears in: - AIMClusterServiceTemplateSpec - AIMServiceTemplateSpec</p> Field Description Default Validation <code>modelName</code> string ModelName is the model name. Matches <code>metadata.name</code> of an AIMModel or AIMClusterModel. Immutable.Example: <code>meta/llama-3-8b:1.1+20240915</code> MinLength: 1  <code>metric</code> AIMMetric Metric selects the optimization goal.- <code>latency</code>: prioritize low end\u2011to\u2011end latency- <code>throughput</code>: prioritize sustained requests/second Enum: [latency throughput]  <code>precision</code> AIMPrecision Precision selects the numeric precision used by the runtime. Enum: [auto fp4 fp8 fp16 fp32 bf16 int4 int8]  <code>gpuSelector</code> AIMGpuSelector GpuSelector specifies GPU requirements for each replica.Defines the GPU count and model type required for deployment.This field is immutable after creation. <code>runtimeConfigName</code> string RuntimeConfigName references the AIM runtime configuration (by name) to use for this template. default <code>imagePullSecrets</code> LocalObjectReference array ImagePullSecrets lists secrets containing credentials for pulling container images.These secrets are used for:- Discovery dry-run jobs that inspect the model container- Pulling the image for inference servicesThe secrets are merged with any model or runtime config defaults.For namespace-scoped templates, secrets must exist in the same namespace.For cluster-scoped templates, secrets must exist in the operator namespace. <code>serviceAccountName</code> string ServiceAccountName specifies the Kubernetes service account to use for workloads related to this template.This includes discovery dry-run jobs and inference services created from this template.If empty, the default service account for the namespace is used. <code>resources</code> ResourceRequirements Resources defines the default container resource requirements applied to services derived from this template.Service-specific values override the template defaults. <code>modelSources</code> AIMModelSource array ModelSources specifies the model artifacts required to run this template.When provided, the discovery dry-run will be skipped and these sources will be used directly.This allows users to explicitly declare model dependencies without requiring a discovery job.If omitted, a discovery job will be run to automatically determine the required model sources. <code>profileId</code> string ProfileId is the specific AIM profile ID that this template should use"},{"location":"reference/crds/aim.silogen.ai/#aimservicetemplatestatus","title":"AIMServiceTemplateStatus","text":"<p>AIMServiceTemplateStatus defines the observed state of AIMServiceTemplate.</p> <p>Appears in: - AIMClusterServiceTemplate - AIMServiceTemplate</p> Field Description Default Validation <code>observedGeneration</code> integer ObservedGeneration is the most recent generation observed by the controller. <code>conditions</code> Condition array Conditions represent the latest observations of template state. <code>resolvedRuntimeConfig</code> AIMResolvedRuntimeConfig ResolvedRuntimeConfig captures metadata about the runtime config that was resolved. <code>resolvedModel</code> AIMResolvedReference ResolvedModel captures metadata about the image that was resolved. <code>status</code> AIMTemplateStatusEnum Status represents the current high\u2011level status of the template lifecycle.Values: <code>Pending</code>, <code>Progressing</code>, <code>Ready</code>, <code>Failed</code>, <code>NotAvailable</code>. Pending Enum: [Pending Progressing NotAvailable Ready Degraded Failed]  <code>modelSources</code> AIMModelSource array ModelSources list the models that this template requires to run. These are the models that will becached, if this template is cached. <code>profile</code> AIMProfile Profile contains the full discovery result profile as a free-form JSON object.This includes metadata, engine args, environment variables, and model details."},{"location":"reference/crds/aim.silogen.ai/#aimtemplatecache","title":"AIMTemplateCache","text":"<p>AIMTemplateCache pre-warms model caches for a specified template.</p> <p>Appears in: - AIMTemplateCacheList</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.silogen.ai/v1alpha1</code> <code>kind</code> string <code>AIMTemplateCache</code> <code>metadata</code> ObjectMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>spec</code> AIMTemplateCacheSpec <code>status</code> AIMTemplateCacheStatus"},{"location":"reference/crds/aim.silogen.ai/#aimtemplatecachelist","title":"AIMTemplateCacheList","text":"<p>AIMTemplateCacheList contains a list of AIMTemplateCache.</p> Field Description Default Validation <code>apiVersion</code> string <code>aim.silogen.ai/v1alpha1</code> <code>kind</code> string <code>AIMTemplateCacheList</code> <code>metadata</code> ListMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>items</code> AIMTemplateCache array"},{"location":"reference/crds/aim.silogen.ai/#aimtemplatecachespec","title":"AIMTemplateCacheSpec","text":"<p>AIMTemplateCacheSpec defines the desired state of AIMTemplateCache</p> <p>Appears in: - AIMTemplateCache</p> Field Description Default Validation <code>templateRef</code> string TemplateRef is the name of the AIMServiceTemplate or AIMClusterServiceTemplate to cache.The controller will first look for a namespace-scoped AIMServiceTemplate in the same namespace.If not found, it will look for a cluster-scoped AIMClusterServiceTemplate with the same name.Namespace-scoped templates take priority over cluster-scoped templates. MinLength: 1  <code>env</code> EnvVar array Env specifies environment variables to use for authentication when downloading models.These variables are used for authentication with model registries (e.g., HuggingFace tokens). <code>imagePullSecrets</code> LocalObjectReference array ImagePullSecrets references secrets for pulling AIM container images. <code>storageClassName</code> string StorageClassName is the name for the storage class to use for this cacheIf not set the cluster default will be used <code>downloadImage</code> string The image that should be used to download the modelsIf not set the model cache controller will decide <code>modelSources</code> AIMModelSource array ModelSources are set by the template that wants these cached <code>runtimeConfigName</code> string RuntimeConfigName references the AIM runtime configuration (by name) to use for this template cache. default"},{"location":"reference/crds/aim.silogen.ai/#aimtemplatecachestatus","title":"AIMTemplateCacheStatus","text":"<p>AIMTemplateCacheStatus defines the observed state of AIMTemplateCache</p> <p>Appears in: - AIMTemplateCache</p> Field Description Default Validation <code>observedGeneration</code> integer ObservedGeneration is the most recent generation observed by the controller. <code>conditions</code> Condition array Conditions represent the latest observations of the template cache state. <code>resolvedRuntimeConfig</code> AIMResolvedRuntimeConfig ResolvedRuntimeConfig captures metadata about the runtime config that was resolved. <code>status</code> AIMTemplateCacheStatusEnum Status represents the current high-level status of the template cache. Pending Enum: [Pending Progressing Available Failed]  <code>resolvedTemplateKind</code> string ResolvedTemplateKind indicates whether the template resolved to a namespace-scopedAIMServiceTemplate or cluster-scoped AIMClusterServiceTemplate.Values: \"AIMServiceTemplate\", \"AIMClusterServiceTemplate\" <code>modelCaches</code> object (keys:string, values:AIMResolvedModelCache) ModelCaches maps model names to their resolved AIMModelCache resources."},{"location":"reference/crds/aim.silogen.ai/#aimtemplatecachestatusenum","title":"AIMTemplateCacheStatusEnum","text":"<p>Underlying type: string</p> <p>AIMTemplateCacheStatusEnum defines the status of the template cache.</p> <p>Validation: - Enum: [Pending Progressing Available Failed]</p> <p>Appears in: - AIMTemplateCacheStatus</p> Field Description <code>Pending</code> AIMTemplateCacheStatusPending denotes that the template cache has been created but not yet processed. <code>Progressing</code> AIMTemplateCacheStatusProgressing denotes that the template cache is being warmed. <code>Available</code> AIMTemplateCacheStatusAvailable denotes that the template cache is ready and models are cached. <code>Failed</code> AIMTemplateCacheStatusFailed denotes that the template cache operation has failed."},{"location":"reference/crds/aim.silogen.ai/#aimtemplatecachingconfig","title":"AIMTemplateCachingConfig","text":"<p>AIMTemplateCachingConfig configures model caching behavior for namespace-scoped templates.</p> <p>Appears in: - AIMServiceTemplateSpec</p> Field Description Default Validation <code>enabled</code> boolean Enabled controls whether caching is enabled for this template.Defaults to <code>false</code>. false <code>env</code> EnvVar array Env specifies environment variables to use when downloading the model.These variables are available to the model download process and can be usedto configure download behavior, authentication, proxies, etc."},{"location":"reference/crds/aim.silogen.ai/#aimtemplatecandidateresult","title":"AIMTemplateCandidateResult","text":"<p>AIMTemplateCandidateResult describes why a template was chosen or rejected.</p> <p>Appears in: - AIMTemplateMatchingStatus</p> Field Description Default Validation <code>name</code> string Name is the name of the template. <code>status</code> string Status indicates whether this template was chosen or rejected. Enum: [chosen rejected]  <code>reason</code> string Reason explains why the template was chosen or rejected.Possible rejection reasons:- TemplatePending: Template status is Pending- TemplateDegraded: Template status is Degraded- TemplateFailed: Template status is Failed- TemplateNotAvailable: Template status is NotAvailable- UnoptimizedTemplateFiltered: Template is unoptimized and allowUnoptimized is false- ServiceOverridesNotMatched: Template doesn't match service overrides- RequiredGPUNotInCluster: Template requires a GPU not available in cluster- LowerPreferenceRank: Template passed all filters but scored lower in preference rankingChosen reason:- BestMatch: Template was selected as the best match"},{"location":"reference/crds/aim.silogen.ai/#aimtemplatematchingstatus","title":"AIMTemplateMatchingStatus","text":"<p>AIMTemplateMatchingStatus captures the result of template selection for a service.</p> <p>Appears in: - AIMServiceStatus</p> Field Description Default Validation <code>candidates</code> AIMTemplateCandidateResult array Candidates lists all templates that were evaluated for this service."},{"location":"reference/crds/aim.silogen.ai/#aimtemplatestatusenum","title":"AIMTemplateStatusEnum","text":"<p>Underlying type: string</p> <p>AIMTemplateStatusEnum defines coarse-grained states for a template.</p> <p>Validation: - Enum: [Pending Progressing NotAvailable Ready Degraded Failed]</p> <p>Appears in: - AIMServiceTemplateStatus</p> Field Description <code>Pending</code> AIMTemplateStatusPending denotes that the template has been created and discovery has not yet started. <code>Progressing</code> AIMTemplateStatusProgressing denotes that discovery and/or cache warm is in progress. <code>NotAvailable</code> AIMTemplateStatusNotAvailable denotes that the template cannot run because the required GPU resources are not present in the cluster. <code>Ready</code> AIMTemplateStatusReady denotes that discovery succeeded and, if requested, caches are warmed. <code>Degraded</code> AIMTemplateStatusDegraded denotes that the template is non-functional for some reason, for example that the cluster doesn't have the resources specified. <code>Failed</code> AIMTemplateStatusFailed denotes a terminal failure for discovery or warm operations."},{"location":"reference/crds/aim.silogen.ai/#imagemetadata","title":"ImageMetadata","text":"<p>ImageMetadata contains metadata extracted from or provided for a container image.</p> <p>Appears in: - AIMModelStatus</p> Field Description Default Validation <code>model</code> ModelMetadata Model contains AMD Silogen model-specific metadata. <code>oci</code> OCIMetadata OCI contains standard OCI image metadata. <code>originalLabels</code> JSON OriginalLabels contains the originally parsed metadata from the image registry.This is stored as JSON to preserve the raw label data. Type: object"},{"location":"reference/crds/aim.silogen.ai/#modelmetadata","title":"ModelMetadata","text":"<p>ModelMetadata contains AMD Silogen model-specific metadata extracted from image labels.</p> <p>Appears in: - ImageMetadata</p> Field Description Default Validation <code>canonicalName</code> string CanonicalName is the canonical model identifier (e.g., mistralai/Mixtral-8x22B-Instruct-v0.1).Extracted from: org.amd.silogen.model.canonicalName <code>source</code> string Source is the URL where the model can be found.Extracted from: org.amd.silogen.model.source <code>tags</code> string array Tags are descriptive tags (e.g., [\"text-generation\", \"chat\", \"instruction\"]).Extracted from: org.amd.silogen.model.tags (comma-separated) <code>versions</code> string array Versions lists available versions.Extracted from: org.amd.silogen.model.versions (comma-separated) <code>variants</code> string array Variants lists model variants.Extracted from: org.amd.silogen.model.variants (comma-separated) <code>hfTokenRequired</code> boolean HFTokenRequired indicates if a HuggingFace token is required.Extracted from: org.amd.silogen.hfToken.required <code>title</code> string Title is the Silogen-specific title for the model.Extracted from: org.amd.silogen.title <code>descriptionFull</code> string DescriptionFull is the full description.Extracted from: org.amd.silogen.description.full <code>releaseNotes</code> string ReleaseNotes contains release notes for this version.Extracted from: org.amd.silogen.release.notes <code>recommendedDeployments</code> RecommendedDeployment array RecommendedDeployments contains recommended deployment configurations.Extracted from: org.amd.silogen.model.recommendedDeployments (parsed from JSON array)"},{"location":"reference/crds/aim.silogen.ai/#modelsourcefilter","title":"ModelSourceFilter","text":"<p>ModelSourceFilter defines a pattern for discovering images. Supports multiple formats: - Repository patterns: \"org/repo\" - matches repositories with wildcards - Repository with tag: \"org/repo:1.0.0\" - exact tag match - Full URI: \"ghcr.io/org/repo:1.0.0\" - overrides registry and tag - Full URI with wildcard: \"ghcr.io/org/repo\" - overrides registry, matches pattern</p> <p>Appears in: - AIMClusterModelSourceSpec</p> Field Description Default Validation <code>image</code> string Image pattern with wildcard and full URI support.Supported formats:- Repository pattern: \"amdenterpriseai/aim-\"- Repository with tag: \"silogen/aim-llama:1.0.0\" (overrides versions field)- Full URI: \"ghcr.io/silogen/aim-google-gemma-3-1b-it:0.8.1-rc1\" (overrides spec.registry and versions)- Full URI with wildcard: \"ghcr.io/silogen/aim-\" (overrides spec.registry)When a full URI is specified (including registry like ghcr.io), only images from thatregistry will match. When a tag is included, it takes precedence over the versions field.Wildcard: * matches any sequence of characters. MaxLength: 512  <code>exclude</code> string array Exclude lists specific repository names to skip (exact match on repository name only, not registry).Useful for excluding base images or experimental versions.Examples:- [\"amdenterpriseai/aim-base\", \"amdenterpriseai/aim-experimental\"]- [\"silogen/aim-base\"] - works with \"ghcr.io/silogen/aim-*\" (registry is not checked in exclusion)Note: Exclusions match against repository names (e.g., \"silogen/aim-base\"), not full URIs. <code>versions</code> string array Versions specifies semantic version constraints for this filter.If specified, overrides the global Versions field.Only tags that parse as valid semver are considered (including prereleases like 0.8.1-rc1).Ignored if the Image field includes an explicit tag (e.g., \"repo:1.0.0\").Examples: \"&gt;=1.0.0\", \"&lt;2.0.0\", \"~1.2.0\" (patch updates), \"^1.0.0\" (minor updates)Prerelease versions (e.g., 0.8.1-rc1) are supported and follow semver rules:- 0.8.1-rc1 matches \"&gt;=0.8.0\" (prerelease is part of version 0.8.1)- Use \"&gt;=0.8.1-rc1\" to match only that prerelease or higher- Leave empty to match all tags (including prereleases and non-semver tags)"},{"location":"reference/crds/aim.silogen.ai/#ocimetadata","title":"OCIMetadata","text":"<p>OCIMetadata contains standard OCI image metadata extracted from image labels.</p> <p>Appears in: - ImageMetadata</p> Field Description Default Validation <code>title</code> string Title is the human-readable title.Extracted from: org.opencontainers.image.title <code>description</code> string Description is a brief description.Extracted from: org.opencontainers.image.description <code>licenses</code> string Licenses is the SPDX license identifier(s).Extracted from: org.opencontainers.image.licenses <code>vendor</code> string Vendor is the organization that produced the image.Extracted from: org.opencontainers.image.vendor <code>authors</code> string Authors is contact details of the authors.Extracted from: org.opencontainers.image.authors <code>source</code> string Source is the URL to the source code repository.Extracted from: org.opencontainers.image.source <code>documentation</code> string Documentation is the URL to documentation.Extracted from: org.opencontainers.image.documentation <code>created</code> string Created is the creation timestamp.Extracted from: org.opencontainers.image.created <code>revision</code> string Revision is the source control revision.Extracted from: org.opencontainers.image.revision <code>version</code> string Version is the image version.Extracted from: org.opencontainers.image.version"},{"location":"reference/crds/aim.silogen.ai/#recommendeddeployment","title":"RecommendedDeployment","text":"<p>RecommendedDeployment describes a recommended deployment configuration for a model.</p> <p>Appears in: - ModelMetadata</p> Field Description Default Validation <code>gpuModel</code> string GPUModel is the GPU model name (e.g., MI300X, MI325X) <code>gpuCount</code> integer GPUCount is the number of GPUs required <code>precision</code> string Precision is the recommended precision (e.g., fp8, fp16, bf16) <code>metric</code> string Metric is the optimization target (e.g., latency, throughput) <code>description</code> string Description provides additional context about this deployment configuration <code>profileId</code> string ProfileId is an optional override to select a particular AIM profile by ID"},{"location":"reference/crds/aim.silogen.ai/#storagespec","title":"StorageSpec","text":"<p>StorageSpec defines the persistent storage configuration</p> <p>Appears in: - AIMKVCacheSpec - AIMServiceKVCache</p> Field Description Default Validation <code>size</code> Quantity Size specifies the storage size for the persistent volume.Minimum recommended size is 1Gi for Redis to function properly.If not specified, defaults to 1Gi.WARNING: This field is immutable after creation due to StatefulSet VolumeClaimTemplate limitations. 1Gi <code>storageClassName</code> string StorageClassName specifies the storage class to use for the persistent volume.If not specified, the cluster's default storage class will be used.Ensure your cluster has a default storage class configured or specify one explicitly.WARNING: This field is immutable after creation due to StatefulSet VolumeClaimTemplate limitations. <code>accessModes</code> PersistentVolumeAccessMode array AccessModes specifies the access modes for the persistent volume.Defaults to ReadWriteOnce if not specified.WARNING: This field is immutable after creation due to StatefulSet VolumeClaimTemplate limitations. [ReadWriteOnce]"},{"location":"reference/crds/config.kaiwo.silogen.ai/","title":"API Reference","text":""},{"location":"reference/crds/config.kaiwo.silogen.ai/#packages","title":"Packages","text":"<ul> <li>config.kaiwo.silogen.ai/v1alpha1</li> </ul>"},{"location":"reference/crds/config.kaiwo.silogen.ai/#configkaiwosilogenaiv1alpha1","title":"config.kaiwo.silogen.ai/v1alpha1","text":"<p>Package v1alpha1 contains API Schema definitions for the kaiwo configuration v1alpha1 API group.</p>"},{"location":"reference/crds/config.kaiwo.silogen.ai/#resource-types","title":"Resource Types","text":"<ul> <li>KaiwoConfig</li> <li>KaiwoConfigList</li> </ul>"},{"location":"reference/crds/config.kaiwo.silogen.ai/#kaiwoconfig","title":"KaiwoConfig","text":"<p>KaiwoConfig manages the Kaiwo operator's configuration which can be modified during runtime.</p> <p>Appears in: - KaiwoConfigList</p> Field Description Default Validation <code>apiVersion</code> string <code>config.kaiwo.silogen.ai/v1alpha1</code> <code>kind</code> string <code>KaiwoConfig</code> <code>metadata</code> ObjectMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>spec</code> KaiwoConfigSpec Spec defines the desired state for the Kaiwo operator configuration."},{"location":"reference/crds/config.kaiwo.silogen.ai/#kaiwoconfiglist","title":"KaiwoConfigList","text":"<p>KaiwoConfigList contains a list of KaiwoConfig resources.</p> Field Description Default Validation <code>apiVersion</code> string <code>config.kaiwo.silogen.ai/v1alpha1</code> <code>kind</code> string <code>KaiwoConfigList</code> <code>metadata</code> ListMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>items</code> KaiwoConfig array"},{"location":"reference/crds/config.kaiwo.silogen.ai/#kaiwoconfigspec","title":"KaiwoConfigSpec","text":"<p>KaiwoConfigSpec defines the desired configuration for the Kaiwo operator's configuration. There should typically be only one KaiwoConfig resource in the cluster.</p> <p>Appears in: - KaiwoConfig</p> Field Description Default Validation <code>ray</code> KaiwoRayConfig Ray defines the Ray-specific settings {  } <code>storage</code> KaiwoStorageConfig Storage defines the storage-specific settings {  } <code>nodes</code> KaiwoNodeConfig Nodes defines the node configuration settings {  } <code>scheduling</code> KaiwoSchedulingConfig Scheduling contains the configuration Kaiwo uses for workload scheduling {  } <code>resourceMonitoring</code> KaiwoResourceMonitoringConfig ResourceMonitoring defines the resource-monitoring specific settings {  } <code>defaultClusterQueueName</code> string DefaultClusterQueueName is the name of the default cluster queue that is used for workloads that don't explicitly specify a cluster queue. kaiwo <code>defaultClusterQueueCohortName</code> string DefaultClusterQueueCohortName is the name of the default cohort that is used for the default cluster queue.ClusterQueues in the same cohort can share resources. kaiwo <code>dynamicallyUpdateDefaultClusterQueue</code> boolean DynamicallyUpdateDefaultClusterQueue defines whether the Kaiwo operator should dynamically update default \"kaiwo\" clusterqueue.If set to true, the operator will make sure that the default clusterqueue is always up to date and reflects total resources available.If nodes are added or removed, the operator will update the default clusterqueue to reflect the current state of the cluster. false"},{"location":"reference/crds/config.kaiwo.silogen.ai/#kaiwonodeconfig","title":"KaiwoNodeConfig","text":"<p>Appears in: - KaiwoConfigSpec</p> Field Description Default Validation <code>defaultGpuResourceKey</code> string DefaultGpuResourceKey defines the default GPU resource key that is used to reserve GPU capacity for pods amd.com/gpu <code>defaultGpuTaintKey</code> string DefaultGpuTaintKey is the key that is used to taint GPU nodes kaiwo.silogen.ai/gpu <code>excludeMasterNodesFromNodePools</code> boolean ExcludeMasterNodesFromNodePools allows excluding the master node(s) from the node pools false <code>addTaintsToGpuNodes</code> boolean AddTaintsToGpuNodes if set to true, will add the DefaultGpuTaintKey taint to the GPU nodes false"},{"location":"reference/crds/config.kaiwo.silogen.ai/#kaiworayconfig","title":"KaiwoRayConfig","text":"<p>KaiwoRayConfig contains the Ray-specific configuration that Kaiwo uses.</p> <p>Appears in: - KaiwoConfigSpec</p> Field Description Default Validation <code>defaultRayImage</code> string DefaultRayImage is the image that is used for Ray workloads if no image is provided in the workload CRD ghcr.io/silogen/rocm-ray:6.4 <code>headPodMemory</code> string HeadPodMemory is the amount of memory that is requested for the Ray head pod 16Gi"},{"location":"reference/crds/config.kaiwo.silogen.ai/#kaiworesourcemonitoringconfig","title":"KaiwoResourceMonitoringConfig","text":"<p>KaiwoResourceMonitoringConfig configures the resource monitoring feature. Note that the following must be set as environmental variables inside the Kaiwo controller manager as these cannot be updated without restarting the operator process.</p> <ul> <li>Enabling the resource monitoring feature (<code>RESOURCE_MONITORING_ENABLED=true</code>)</li> <li>Setting the metrics endpoint (<code>RESOURCE_MONITORING_METRICS_ENDPOINT=...</code>)</li> <li>Setting the polling interval (<code>RESOURCE_MONITORING_POLLING_INTERVAL=30s</code>)</li> </ul> <p>Appears in: - KaiwoConfigSpec</p> Field Description Default Validation <code>lowUtilizationThreshold</code> float LowUtilizationThreshold is the threshold which, if the metric goes under, the workload is considered underutilized. The threshold is interpreted as the percentage utilization versus the requested capacity. 1 Minimum: 0  <code>targetNamespaces</code> string array TargetNamespaces is a list of namespaces to apply the monitoring to. If not supplied or empty, all namespaces apart from kube-system will be inspected. However, only pods associated with KaiwoJobs or KaiwoServices are impacted. <code>profile</code> string Profile chooses the target resource to monitor. gpu Enum: [gpu]  <code>terminateUnderutilized</code> boolean TerminateUnderutilized will terminate workloads that are underutilizing resources if set to <code>true</code> false <code>terminateUnderutilizedAfter</code> string TerminateUnderutilizedAfter specifies the duration after which the workload will be terminated if it has been underutilizing resources (for this amount of time) 24h Pattern: <code>^([0-9]+(s\\|m\\|h))+$</code>"},{"location":"reference/crds/config.kaiwo.silogen.ai/#kaiwoschedulingconfig","title":"KaiwoSchedulingConfig","text":"<p>KaiwoSchedulingConfig contains the configuration Kaiwo uses for workload scheduling</p> <p>Appears in: - KaiwoConfigSpec</p> Field Description Default Validation <code>kubeSchedulerName</code> string KubeSchedulerName defines the default scheduler name that is used to schedule the workload kaiwo-scheduler <code>pendingThresholdForPreemption</code> string PendingThresholdForPreemption is the threshold that is used to determine if a workload is awaiting for compute resources to be available.If the workload is requesting GPUs and pending for longer than this threshold, kaiwo will start preempting workloads that have exceeded their duration deadline and are using GPUs of the same vendor as the pending workload. 5m"},{"location":"reference/crds/config.kaiwo.silogen.ai/#kaiwostorageconfig","title":"KaiwoStorageConfig","text":"<p>Appears in: - KaiwoConfigSpec</p> Field Description Default Validation <code>defaultStorageClass</code> string DefaultStorageClass is the storage class that is used for workloads that don't explicitly specify a storage class. <code>defaultDataMountPath</code> string DefaultDataMountPath is the default path for the data storage and downloads that gets mounted in the workload pods.This value can be overwritten in the workload CRD. /workload <code>defaultHfMountPath</code> string DefaultHfMountPath is the default path for the HuggingFace that gets mounted in the workload pods. The <code>HF_HOME</code> environmental variableis also set to this value. This value can be overwritten in the workload CRD. /hf_cache"},{"location":"reference/crds/kaiwo.silogen.ai/","title":"API Reference","text":""},{"location":"reference/crds/kaiwo.silogen.ai/#packages","title":"Packages","text":"<ul> <li>kaiwo.silogen.ai/v1alpha1</li> </ul>"},{"location":"reference/crds/kaiwo.silogen.ai/#kaiwosilogenaiv1alpha1","title":"kaiwo.silogen.ai/v1alpha1","text":"<p>Package v1alpha1 contains API Schema definitions for the kaiwo v1alpha1 API group.</p>"},{"location":"reference/crds/kaiwo.silogen.ai/#resource-types","title":"Resource Types","text":"<ul> <li>KaiwoJob</li> <li>KaiwoJobList</li> <li>KaiwoQueueConfig</li> <li>KaiwoQueueConfigList</li> <li>KaiwoService</li> <li>KaiwoServiceList</li> </ul>"},{"location":"reference/crds/kaiwo.silogen.ai/#azureblobstoragedownloaditem","title":"AzureBlobStorageDownloadItem","text":"<p>AzureBlobStorageDownloadItem defines parameters for downloading data from Azure Blob Storage.</p> <p>Appears in: - DownloadTaskConfig - ObjectStorageDownloadSpec</p> Field Description Default Validation <code>connectionString</code> ValueReference ConnectionString references a Kubernetes Secret containing the Azure Storage connection string. See <code>ValueReference</code>. <code>containers</code> CloudDownloadBucket array Containers lists the Azure Blob Storage containers and the specific files/folders to download from them. See <code>CloudDownloadBucket</code>."},{"location":"reference/crds/kaiwo.silogen.ai/#clouddownloadbucket","title":"CloudDownloadBucket","text":"<p>CloudDownloadBucket represents a specific bucket (S3, GCS) or container (Azure) to download from.</p> <p>Appears in: - AzureBlobStorageDownloadItem - GCSDownloadItem - S3DownloadItem</p> Field Description Default Validation <code>name</code> string Name is the name of the bucket or container. <code>files</code> CloudDownloadFile array Files lists specific files to download from this bucket/container. <code>folders</code> CloudDownloadFolder array Folders lists specific folders (prefixes) to download from this bucket/container."},{"location":"reference/crds/kaiwo.silogen.ai/#clusterqueue","title":"ClusterQueue","text":"<p>ClusterQueue defines the configuration for a Kueue ClusterQueue managed by Kaiwo.</p> <p>Appears in: - KaiwoQueueConfigSpec</p> Field Description Default Validation <code>name</code> string Name specifies the name of the Kueue ClusterQueue resource. <code>spec</code> ClusterQueueSpec Spec contains the desired Kueue <code>ClusterQueueSpec</code>. Kaiwo ensures the corresponding ClusterQueue resource matches this spec. See Kueue documentation for <code>ClusterQueueSpec</code> fields like <code>resourceGroups</code>, <code>cohort</code>, <code>preemption</code>, etc. <code>namespaces</code> string array Namespaces optionally lists Kubernetes namespaces where Kaiwo should automatically create a Kueue <code>LocalQueue</code> resource pointing to this ClusterQueue.If one or more namespaces are provided, the KaiwoQueueConfig controller takes over managing the LocalQueues for this ClusterQueue.Leave this empty if you want to be able to create your own LocalQueues for this ClusterQueue."},{"location":"reference/crds/kaiwo.silogen.ai/#clusterqueuespec","title":"ClusterQueueSpec","text":"<p>Appears in: - ClusterQueue</p> Field Description Default Validation <code>resourceGroups</code> ResourceGroup array resourceGroups describes groups of resources.Each resource group defines the list of resources and a list of flavorsthat provide quotas for these resources.Each resource and each flavor can only form part of one resource group.resourceGroups can be up to 16. MaxItems: 16  <code>cohort</code> CohortReference cohort that this ClusterQueue belongs to. CQs that belong to thesame cohort can borrow unused resources from each other.A CQ can be a member of a single borrowing cohort. A workload submittedto a queue referencing this CQ can borrow quota from any CQ in the cohort.Only quota for the [resource, flavor] pairs listed in the CQ can beborrowed.If empty, this ClusterQueue cannot borrow from any other ClusterQueue andvice versa.A cohort is a name that links CQs together, but it doesn't reference anyobject. <code>queueingStrategy</code> QueueingStrategy QueueingStrategy indicates the queueing strategy of the workloadsacross the queues in this ClusterQueue.Current Supported Strategies:- StrictFIFO: workloads are ordered strictly by creation time.Older workloads that can't be admitted will block admitting newerworkloads even if they fit available quota.- BestEffortFIFO: workloads are ordered by creation time,however older workloads that can't be admitted will not blockadmitting newer workloads that fit existing quota. BestEffortFIFO Enum: [StrictFIFO BestEffortFIFO]  <code>namespaceSelector</code> LabelSelector namespaceSelector defines which namespaces are allowed to submit workloads tothis clusterQueue. Beyond this basic support for policy, a policy agent likeGatekeeper should be used to enforce more advanced policies.Defaults to null which is a nothing selector (no namespaces eligible).If set to an empty selector <code>\\{\\}</code>, then all namespaces are eligible. <code>flavorFungibility</code> FlavorFungibility flavorFungibility defines whether a workload should try the next flavorbefore borrowing or preempting in the flavor being evaluated. {  } <code>preemption</code> ClusterQueuePreemption {  } <code>admissionChecks</code> AdmissionCheckReference array admissionChecks lists the AdmissionChecks required by this ClusterQueue.Cannot be used along with AdmissionCheckStrategy. <code>admissionChecksStrategy</code> AdmissionChecksStrategy admissionCheckStrategy defines a list of strategies to determine which ResourceFlavors require AdmissionChecks.This property cannot be used in conjunction with the 'admissionChecks' property. <code>stopPolicy</code> StopPolicy stopPolicy - if set to a value different from None, the ClusterQueue is considered Inactive, no new reservation beingmade.Depending on its value, its associated workloads will:- None - Workloads are admitted- HoldAndDrain - Admitted workloads are evicted and Reserving workloads will cancel the reservation.- Hold - Admitted workloads will run to completion and Reserving workloads will cancel the reservation. None Enum: [None Hold HoldAndDrain]  <code>fairSharing</code> FairSharing fairSharing defines the properties of the ClusterQueue whenparticipating in FairSharing.  The values are only relevantif FairSharing is enabled in the Kueue configuration."},{"location":"reference/crds/kaiwo.silogen.ai/#commonmetaspec","title":"CommonMetaSpec","text":"<p>CommonMetaSpec defines reusable metadata fields for workloads.</p> <p>Appears in: - KaiwoJobSpec - KaiwoServiceSpec</p> Field Description Default Validation <code>user</code> string User specifies the owner or creator of the workload. It should typically be the user's email address. This value is primarily used for labeling (<code>kaiwo.silogen.ai/user</code>) the generated resources (like Pods, Jobs, Deployments) for identification and filtering (e.g., with <code>kaiwo list --user &lt;email&gt;</code>).In the future, if authentication is enabled, this must be the email address which is checked against authenticated user for match. <code>podTemplateSpecLabels</code> object (keys:string, values:string) PodTemplateSpecLabels allows you to specify custom labels that will be added to the <code>template.metadata.labels</code> section of the generated Pods (within Jobs, Deployments, or RayCluster specs). Standard Kaiwo system labels (like <code>kaiwo.silogen.ai/user</code>, <code>kaiwo.silogen.ai/name</code>, etc.) are added automatically and take precedence if there are conflicts. <code>gpus</code> integer Gpus specifies the total number of GPUs allocated to the workload. See here for more details on how this field impacts scheduling. 0 <code>gpuVendor</code> string GpuVendor specifies the GPU vendor (e.g., amd, nvidia, etc.). See here for more details on how this field impacts scheduling. amd <code>gpuModels</code> string array GpuModels allows you to optionally specify the GPU models that your workload will run on. You can see available models either by using the CLI and running <code>kaiwo status amd/nvidia</code> or by using kubectl command <code>kubectl get nodes -o custom-columns=NAME:.metadata.name,MODEL:.metadata.labels.kaiwo\\/gpu-model</code>This field is used to filter the available nodes for scheduling. You can specify multiple models, and Kaiwo will select the best available node that matches one of the specified models. <code>version</code> string Version allows you to specify an optional version string for the workload. This can be useful for tracking different iterations or configurations of the same logical workload. It does not directly affect resource creation but serves as metadata. <code>replicas</code> integer Replicas specifies the number of replicas for the workload. See here for more details on how this field impacts scheduling. 1 <code>gpusPerReplica</code> integer GpusPerReplica specifies the number of GPUs allocated per replica. See here for more details on how this field impacts scheduling.If you specify <code>gpusPerReplica</code>, you must also specify <code>replicas</code>. <code>duration</code> Duration Duration specifies the maximum duration over which the workload can run. This is useful for avoiding workloads running indefinitely. <code>preferredTopologyLabel</code> string PreferredTopologyLabel specifies the preferred topology label for scheduling the workload. This is used to influence how the workload is distributed across nodes in the cluster.If not specified, Kaiwo will use the default topology labels defined in the default topology of KaiwoQueueConfig starting at the host level.The levels are evaluated one-by-one going up from the level indicated by the label. If the PodSet cannot fit within a given topology label then the next topology level up is considered.If the PodSet cannot fit at the highest topology level, then it is distributed among multiple topology domains <code>requiredTopologyLabel</code> string RequiredTopologyLabel specifies the required topology label for scheduling the workload. This is used to ensure that the workload is scheduled on nodes that match the specified topology label. <code>resources</code> ResourceRequirements Resources specify the default resource requirements applied for all pods inside the workflow.This field defines default Kubernetes <code>ResourceRequirements</code> (requests and limits for CPU,memory, ephemeral-storage) applied to all containers (including init containers) withinthe workload's pods.Behavior:These values act as defaults. If a container within the underlying Job, Deployment,or Ray spec (if provided by the user) already defines a specific request or limit(e.g., <code>memory</code> limit), the value from <code>resources</code> for that specific metric will not override it.Interaction with GPU fields: The GPU requests/limits (<code>amd.com/gpu</code> or <code>nvidia.com/gpu</code>)are controlled exclusively by the <code>gpus</code>, <code>gpusPerReplica</code>, and <code>gpuVendor</code> fields(and the associated calculation logic described above). Any GPU specifications withinthe <code>resources</code> field are ignored.Default CPU/Memory with GPUs: When Kaiwo generates the underlyingJob/Deployment/RayCluster spec (i.e., the user did not provide <code>spec.job</code>,<code>spec.deployment</code>, or <code>spec.rayService</code>/<code>spec.rayJob</code>), and GPUs are requested(<code>gpusPerReplica</code> &gt; 0), Kaiwo applies default CPU and Memory requests/limitsbased on the GPU count (e.g., 4 CPU cores and 32Gi Memory per GPU).These GPU-derived defaults will override any CPU/Memory settings defined inthe <code>resources</code> field in this specific scenario. If the user does providethe underlying spec, these GPU-derived CPU/Memory defaults are not applied,respecting the user's definition or the values from the <code>resources</code> field. <code>image</code> string Image specifies the default container image to be used for the primary workload container(s).- If containers defined within the underlying Job, Deployment, or Ray spec do not specify an image, this image will be used.- If this field is also empty, the latest tag of ghcr.io/silogen/rocm-ray is used <code>imagePullSecrets</code> LocalObjectReference array ImagePullSecrets is a list of Kubernetes <code>LocalObjectReference</code> (containing just the secret <code>name</code>) referencing secrets needed to pull the container image(s). These are added to the <code>imagePullSecrets</code> field of the PodSpec for all generated pods. <code>env</code> EnvVar array Env is a list of Kubernetes <code>EnvVar</code> structs. These environment variables are added to the primary workload container(s) in the generated pods. They are appended to any environment variables already defined in the underlying Job, Deployment, or Ray spec. <code>secretVolumes</code> SecretVolume array SecretVolumes allows you to mount specific keys from Kubernetes Secrets as files into the workload containers. <code>ray</code> boolean Ray determines whether the operator should use RayCluster for workload execution.If <code>true</code>, Kaiwo will create Ray-specific resources.If <code>false</code> (default), Kaiwo will create standard Kubernetes resources (BatchJob for <code>KaiwoJob</code>, Deployment for <code>KaiwoService</code>).This setting dictates which underlying spec (<code>job</code>/<code>rayJob</code> or <code>deployment</code>/<code>rayService</code>) is primarily used. false <code>storage</code> StorageSpec Storage configures persistent storage using Kubernetes PersistentVolumeClaims (PVCs).Enabling <code>storage.data.download</code> or <code>storage.huggingFace.preCacheRepos</code> will cause Kaiwo to create a temporary Kubernetes Job (the \"download job\") before starting the main workload. This job runs a container that performs the downloads into the respective PVCs. The main workload only starts after the download job completes successfully. <code>dangerous</code> boolean Dangerous, if when set to <code>true</code>, Kaiwo will not add the default <code>PodSecurityContext</code> (which normally sets <code>runAsUser: 1000</code>, <code>runAsGroup: 1000</code>, <code>fsGroup: 1000</code>) to the generated pods. Use this only if you need to run containers as root or a different specific user and understand the security implications. false <code>clusterQueue</code> string ClusterQueue specifies the name of the Kueue <code>ClusterQueue</code> that the workload should be submitted to for scheduling and resource management.This value is set as the <code>kueue.x-k8s.io/queue-name</code> label on the underlying resources.If omitted, it defaults to the value specified by the <code>DEFAULT_CLUSTER_QUEUE_NAME</code> environment variable in the Kaiwo controller (typically \"kaiwo\"), which is set during installation.Note! If the applied KaiwoQueueConfig includes no quota for the default queue, no workload will run that tries to fall back on it.The <code>kaiwo submit</code> CLI command can override this using the <code>--queue</code> flag or the <code>clusterQueue</code> field in the <code>kaiwoconfig.yaml</code> file. <code>priorityClass</code> string WorkloadPriorityClass specifies the name of Kueue <code>WorkloadPriorityClass</code> to be assigned to the job's pods. This influences the scheduling priority relative to other pods in the cluster."},{"location":"reference/crds/kaiwo.silogen.ai/#commonstatusspec","title":"CommonStatusSpec","text":"<p>Appears in: - KaiwoJobStatus - KaiwoServiceStatus</p> Field Description Default Validation <code>startTime</code> Time StartTime records the timestamp when the first pod associated with the workload started running. <code>conditions</code> Condition array Conditions lists the observed conditions of the workload resource, following standard Kubernetes conventions. May include conditions reflecting the underlying Deployment or RayService state. <code>status</code> WorkloadStatus Status reflects the current high-level phase of the workload lifecycle (e.g., PENDING, STARTING, READY, FAILED). <code>duration</code> integer Duration indicates how long the service has been running since StartTime, in seconds. Calculated periodically while running. <code>observedGeneration</code> integer ObservedGeneration records the <code>.metadata.generation</code> of the workload resource that was last processed by the controller."},{"location":"reference/crds/kaiwo.silogen.ai/#datastoragespec","title":"DataStorageSpec","text":"<p>DataStorageSpec configures the primary data volume for the workload.</p> <p>Appears in: - StorageSpec</p> Field Description Default Validation <code>mountPath</code> string MountPath specifies the path inside the workload containers where the data PersistentVolumeClaim will be mounted. /workload <code>storageSize</code> string StorageSize specifies the requested size for the data PersistentVolumeClaim (e.g., \"100Gi\", \"1Ti\"). If set, a PVC will be created. <code>download</code> ObjectStorageDownloadSpec Download configures optional tasks to download data from various sources into the data volume before the main workload starts. See <code>ObjectStorageDownloadSpec</code>."},{"location":"reference/crds/kaiwo.silogen.ai/#gcsdownloaditem","title":"GCSDownloadItem","text":"<p>GCSDownloadItem defines parameters for downloading data from Google Cloud Storage.</p> <p>Appears in: - DownloadTaskConfig - ObjectStorageDownloadSpec</p> Field Description Default Validation <code>applicationCredentials</code> ValueReference ApplicationCredentials references a Kubernetes Secret containing the GCS service account key JSON file content. See <code>ValueReference</code>. <code>buckets</code> CloudDownloadBucket array Buckets lists the GCS buckets and the specific files/folders to download from them. See <code>CloudDownloadBucket</code>."},{"location":"reference/crds/kaiwo.silogen.ai/#gitdownloaditem","title":"GitDownloadItem","text":"<p>GitDownloadItem defines parameters for cloning a Git repository or parts of it.</p> <p>Appears in: - DownloadTaskConfig - ObjectStorageDownloadSpec</p> Field Description Default Validation <code>repository</code> string Repository specifies the Git repository URL (e.g., \"https://github.com/user/repo.git\"). <code>branch</code> string Branch specifies the branch to clone. This takes precedence over <code>commit</code>. <code>commit</code> string Commit specifies the exact commit hash to check out. This is ignored if <code>commit</code> is specified. <code>username</code> ValueReference Username optionally references a Secret containing the Git username for authentication. See <code>ValueReference</code>. <code>token</code> ValueReference Token optionally references a Secret containing the Git token (or password) for authentication. See <code>ValueReference</code>. <code>path</code> string Path specifies a sub-path within the repository to copy. If omitted, the entire repository is copied. <code>targetPath</code> string TargetPath specifies the destination path relative to the data volume's mount point (<code>DataStorageSpec.MountPath</code>) where the repository or <code>path</code> content should be copied."},{"location":"reference/crds/kaiwo.silogen.ai/#hfstoragespec","title":"HfStorageSpec","text":"<p>HfStorageSpec configures storage specifically for Hugging Face model caching.</p> <p>Appears in: - StorageSpec</p> Field Description Default Validation <code>mountPath</code> string MountPath specifies the path inside workload containers where the Hugging Face cache PVC will be mounted.This path is also automatically set as the <code>HF_HOME</code> environment variable in the containers. /hf_cache <code>storageSize</code> string StorageSize specifies the requested size for the Hugging Face cache PersistentVolumeClaim (e.g., \"50Gi\", \"200Gi\"). If set, a PVC will be created. <code>preCacheRepos</code> HuggingFaceDownloadItem array PreCacheRepos is a list of Hugging Face repositories to download into the cache volume before the main workload starts."},{"location":"reference/crds/kaiwo.silogen.ai/#huggingfacedownloaditem","title":"HuggingFaceDownloadItem","text":"<p>HuggingFaceDownloadItem defines parameters for pre-caching a Hugging Face repository or specific files from it.</p> <p>Appears in: - DownloadTaskConfig - HfStorageSpec</p> Field Description Default Validation <code>repoId</code> string RepoID is the Hugging Face Hub repository ID (e.g., \"meta-llama/Llama-2-7b-chat-hf\"). <code>files</code> string array Files is an optional list of specific files to download from the repository. If omitted, the entire repository is downloaded."},{"location":"reference/crds/kaiwo.silogen.ai/#kaiwojob","title":"KaiwoJob","text":"<p>KaiwoJob represents a batch workload managed by Kaiwo. It encapsulates either a standard Kubernetes Job or a RayJob, along with common metadata, storage configurations, and scheduling preferences. The Kaiwo controller reconciles this resource to create and manage the underlying workload objects.</p> <p>Appears in: - KaiwoJobList</p> Field Description Default Validation <code>apiVersion</code> string <code>kaiwo.silogen.ai/v1alpha1</code> <code>kind</code> string <code>KaiwoJob</code> <code>metadata</code> ObjectMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>spec</code> KaiwoJobSpec Spec defines the desired state of the KaiwoJob, including workload type (Job/RayJob), configuration, resources, and common metadata. <code>status</code> KaiwoJobStatus Status reflects the most recently observed state of the KaiwoJob, including its phase, start/completion times, and conditions."},{"location":"reference/crds/kaiwo.silogen.ai/#kaiwojoblist","title":"KaiwoJobList","text":"<p>KaiwoJobList</p> Field Description Default Validation <code>apiVersion</code> string <code>kaiwo.silogen.ai/v1alpha1</code> <code>kind</code> string <code>KaiwoJobList</code> <code>metadata</code> ListMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>items</code> KaiwoJob array"},{"location":"reference/crds/kaiwo.silogen.ai/#kaiwojobspec","title":"KaiwoJobSpec","text":"<p>KaiwoJobSpec defines the desired state of KaiwoJob.</p> <p>Appears in: - KaiwoJob</p> Field Description Default Validation <code>user</code> string User specifies the owner or creator of the workload. It should typically be the user's email address. This value is primarily used for labeling (<code>kaiwo.silogen.ai/user</code>) the generated resources (like Pods, Jobs, Deployments) for identification and filtering (e.g., with <code>kaiwo list --user &lt;email&gt;</code>).In the future, if authentication is enabled, this must be the email address which is checked against authenticated user for match. <code>podTemplateSpecLabels</code> object (keys:string, values:string) PodTemplateSpecLabels allows you to specify custom labels that will be added to the <code>template.metadata.labels</code> section of the generated Pods (within Jobs, Deployments, or RayCluster specs). Standard Kaiwo system labels (like <code>kaiwo.silogen.ai/user</code>, <code>kaiwo.silogen.ai/name</code>, etc.) are added automatically and take precedence if there are conflicts. <code>gpus</code> integer Gpus specifies the total number of GPUs allocated to the workload. See here for more details on how this field impacts scheduling. 0 <code>gpuVendor</code> string GpuVendor specifies the GPU vendor (e.g., amd, nvidia, etc.). See here for more details on how this field impacts scheduling. amd <code>gpuModels</code> string array GpuModels allows you to optionally specify the GPU models that your workload will run on. You can see available models either by using the CLI and running <code>kaiwo status amd/nvidia</code> or by using kubectl command <code>kubectl get nodes -o custom-columns=NAME:.metadata.name,MODEL:.metadata.labels.kaiwo\\/gpu-model</code>This field is used to filter the available nodes for scheduling. You can specify multiple models, and Kaiwo will select the best available node that matches one of the specified models. <code>version</code> string Version allows you to specify an optional version string for the workload. This can be useful for tracking different iterations or configurations of the same logical workload. It does not directly affect resource creation but serves as metadata. <code>replicas</code> integer Replicas specifies the number of replicas for the workload. See here for more details on how this field impacts scheduling. 1 <code>gpusPerReplica</code> integer GpusPerReplica specifies the number of GPUs allocated per replica. See here for more details on how this field impacts scheduling.If you specify <code>gpusPerReplica</code>, you must also specify <code>replicas</code>. <code>duration</code> Duration Duration specifies the maximum duration over which the workload can run. This is useful for avoiding workloads running indefinitely. <code>preferredTopologyLabel</code> string PreferredTopologyLabel specifies the preferred topology label for scheduling the workload. This is used to influence how the workload is distributed across nodes in the cluster.If not specified, Kaiwo will use the default topology labels defined in the default topology of KaiwoQueueConfig starting at the host level.The levels are evaluated one-by-one going up from the level indicated by the label. If the PodSet cannot fit within a given topology label then the next topology level up is considered.If the PodSet cannot fit at the highest topology level, then it is distributed among multiple topology domains <code>requiredTopologyLabel</code> string RequiredTopologyLabel specifies the required topology label for scheduling the workload. This is used to ensure that the workload is scheduled on nodes that match the specified topology label. <code>resources</code> ResourceRequirements Resources specify the default resource requirements applied for all pods inside the workflow.This field defines default Kubernetes <code>ResourceRequirements</code> (requests and limits for CPU,memory, ephemeral-storage) applied to all containers (including init containers) withinthe workload's pods.Behavior:These values act as defaults. If a container within the underlying Job, Deployment,or Ray spec (if provided by the user) already defines a specific request or limit(e.g., <code>memory</code> limit), the value from <code>resources</code> for that specific metric will not override it.Interaction with GPU fields: The GPU requests/limits (<code>amd.com/gpu</code> or <code>nvidia.com/gpu</code>)are controlled exclusively by the <code>gpus</code>, <code>gpusPerReplica</code>, and <code>gpuVendor</code> fields(and the associated calculation logic described above). Any GPU specifications withinthe <code>resources</code> field are ignored.Default CPU/Memory with GPUs: When Kaiwo generates the underlyingJob/Deployment/RayCluster spec (i.e., the user did not provide <code>spec.job</code>,<code>spec.deployment</code>, or <code>spec.rayService</code>/<code>spec.rayJob</code>), and GPUs are requested(<code>gpusPerReplica</code> &gt; 0), Kaiwo applies default CPU and Memory requests/limitsbased on the GPU count (e.g., 4 CPU cores and 32Gi Memory per GPU).These GPU-derived defaults will override any CPU/Memory settings defined inthe <code>resources</code> field in this specific scenario. If the user does providethe underlying spec, these GPU-derived CPU/Memory defaults are not applied,respecting the user's definition or the values from the <code>resources</code> field. <code>image</code> string Image specifies the default container image to be used for the primary workload container(s).- If containers defined within the underlying Job, Deployment, or Ray spec do not specify an image, this image will be used.- If this field is also empty, the latest tag of ghcr.io/silogen/rocm-ray is used <code>imagePullSecrets</code> LocalObjectReference array ImagePullSecrets is a list of Kubernetes <code>LocalObjectReference</code> (containing just the secret <code>name</code>) referencing secrets needed to pull the container image(s). These are added to the <code>imagePullSecrets</code> field of the PodSpec for all generated pods. <code>env</code> EnvVar array Env is a list of Kubernetes <code>EnvVar</code> structs. These environment variables are added to the primary workload container(s) in the generated pods. They are appended to any environment variables already defined in the underlying Job, Deployment, or Ray spec. <code>secretVolumes</code> SecretVolume array SecretVolumes allows you to mount specific keys from Kubernetes Secrets as files into the workload containers. <code>ray</code> boolean Ray determines whether the operator should use RayCluster for workload execution.If <code>true</code>, Kaiwo will create Ray-specific resources.If <code>false</code> (default), Kaiwo will create standard Kubernetes resources (BatchJob for <code>KaiwoJob</code>, Deployment for <code>KaiwoService</code>).This setting dictates which underlying spec (<code>job</code>/<code>rayJob</code> or <code>deployment</code>/<code>rayService</code>) is primarily used. false <code>storage</code> StorageSpec Storage configures persistent storage using Kubernetes PersistentVolumeClaims (PVCs).Enabling <code>storage.data.download</code> or <code>storage.huggingFace.preCacheRepos</code> will cause Kaiwo to create a temporary Kubernetes Job (the \"download job\") before starting the main workload. This job runs a container that performs the downloads into the respective PVCs. The main workload only starts after the download job completes successfully. <code>dangerous</code> boolean Dangerous, if when set to <code>true</code>, Kaiwo will not add the default <code>PodSecurityContext</code> (which normally sets <code>runAsUser: 1000</code>, <code>runAsGroup: 1000</code>, <code>fsGroup: 1000</code>) to the generated pods. Use this only if you need to run containers as root or a different specific user and understand the security implications. false <code>clusterQueue</code> string ClusterQueue specifies the name of the Kueue <code>ClusterQueue</code> that the workload should be submitted to for scheduling and resource management.This value is set as the <code>kueue.x-k8s.io/queue-name</code> label on the underlying resources.If omitted, it defaults to the value specified by the <code>DEFAULT_CLUSTER_QUEUE_NAME</code> environment variable in the Kaiwo controller (typically \"kaiwo\"), which is set during installation.Note! If the applied KaiwoQueueConfig includes no quota for the default queue, no workload will run that tries to fall back on it.The <code>kaiwo submit</code> CLI command can override this using the <code>--queue</code> flag or the <code>clusterQueue</code> field in the <code>kaiwoconfig.yaml</code> file. <code>priorityClass</code> string WorkloadPriorityClass specifies the name of Kueue <code>WorkloadPriorityClass</code> to be assigned to the job's pods. This influences the scheduling priority relative to other pods in the cluster. <code>entrypoint</code> string EntryPoint defines the command or script that the primary container in the job's pod(s) should execute.It can be a multi-line string. Shell script shebangs (<code>#!/bin/bash</code>) are detected.For standard Kubernetes Jobs (<code>ray: false</code>), this populates the <code>command</code> and <code>args</code> fields of the container spec (typically <code>[\"/bin/sh\", \"-c\", \"&lt;entrypoint_script&gt;\"]</code>).For RayJobs (<code>ray: true</code>), this populates the <code>rayJob.spec.entrypoint</code> field. For RayJobs, this must reference a Python script.This overrides any default command specified in the container image or the underlying <code>job</code> or <code>rayJob</code> spec sections if they are also defined. <code>rayJob</code> RayJob RayJob defines the RayJob configuration.If this field is present (or if <code>spec.ray</code> is <code>true</code>), Kaiwo will create a <code>RayJob</code> resource instead of a standard <code>batchv1.Job</code>.Common fields like <code>image</code>, <code>resources</code>, <code>gpus</code>, <code>replicas</code>, etc., will be merged into this spec, potentially overriding values defined here unless explicitly configured otherwise.This provides fine-grained control over the Ray cluster configuration (head/worker groups) and Ray job submission parameters. <code>job</code> Job Job defines the Kubernetes Job configuration.If this field is present and <code>spec.ray</code> is <code>false</code>, Kaiwo will use this as the base for the created <code>batchv1.Job</code>.Common fields like <code>image</code>, <code>resources</code>, <code>gpus</code>, <code>entrypoint</code>, etc., will be merged into this spec, potentially overriding values defined here.This provides fine-grained control over standard Kubernetes Job parameters like <code>backoffLimit</code>, <code>ttlSecondsAfterFinished</code>, pod template details, etc."},{"location":"reference/crds/kaiwo.silogen.ai/#kaiwojobstatus","title":"KaiwoJobStatus","text":"<p>KaiwoJobStatus defines the observed state of KaiwoJob.</p> <p>Appears in: - KaiwoJob</p> Field Description Default Validation <code>startTime</code> Time StartTime records the timestamp when the first pod associated with the workload started running. <code>conditions</code> Condition array Conditions lists the observed conditions of the workload resource, following standard Kubernetes conventions. May include conditions reflecting the underlying Deployment or RayService state. <code>status</code> WorkloadStatus Status reflects the current high-level phase of the workload lifecycle (e.g., PENDING, STARTING, READY, FAILED). <code>duration</code> integer Duration indicates how long the service has been running since StartTime, in seconds. Calculated periodically while running. <code>observedGeneration</code> integer ObservedGeneration records the <code>.metadata.generation</code> of the workload resource that was last processed by the controller. <code>completionTime</code> Time CompletionTime records the timestamp when the KaiwoJob finished execution (either successfully or with failure)."},{"location":"reference/crds/kaiwo.silogen.ai/#kaiwoqueueconfig","title":"KaiwoQueueConfig","text":"<p>KaiwoQueueConfig manages Kueue resources like ClusterQueues, ResourceFlavors, and WorkloadPriorityClasses based on its spec. It acts as a central configuration point for Kaiwo's integration with Kueue. Typically, only one cluster-scoped resource named 'kaiwo' should exist. The controller ensures that the specified Kueue resources are created, updated, or deleted to match the desired state defined here. KaiwoQueueConfig manages Kueue resources.</p> <p>Appears in: - KaiwoQueueConfigList</p> Field Description Default Validation <code>apiVersion</code> string <code>kaiwo.silogen.ai/v1alpha1</code> <code>kind</code> string <code>KaiwoQueueConfig</code> <code>metadata</code> ObjectMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>spec</code> KaiwoQueueConfigSpec Spec defines the desired state for Kueue resources managed by Kaiwo. <code>status</code> KaiwoQueueConfigStatus Status reflects the most recently observed state of the Kueue resource synchronization."},{"location":"reference/crds/kaiwo.silogen.ai/#kaiwoqueueconfiglist","title":"KaiwoQueueConfigList","text":"<p>KaiwoQueueConfigList contains a list of KaiwoQueueConfig resources.</p> Field Description Default Validation <code>apiVersion</code> string <code>kaiwo.silogen.ai/v1alpha1</code> <code>kind</code> string <code>KaiwoQueueConfigList</code> <code>metadata</code> ListMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>items</code> KaiwoQueueConfig array"},{"location":"reference/crds/kaiwo.silogen.ai/#kaiwoqueueconfigspec","title":"KaiwoQueueConfigSpec","text":"<p>KaiwoQueueConfigSpec defines the desired configuration for Kaiwo's management of Kueue resources. There should typically be only one KaiwoQueueConfig resource in the cluster, named 'kaiwo'.</p> <p>Appears in: - KaiwoQueueConfig</p> Field Description Default Validation <code>clusterQueues</code> ClusterQueue array ClusterQueues defines a list of Kueue ClusterQueues that Kaiwo should manage. Kaiwo ensures these ClusterQueues exist and match the provided specs. MaxItems: 1000  <code>resourceFlavors</code> ResourceFlavorSpec array ResourceFlavors defines a list of Kueue ResourceFlavors that Kaiwo should manage. Kaiwo ensures these ResourceFlavors exist and match the provided specs. If omitted or empty, Kaiwo attempts to automatically discover node pools and create default flavors based on node labels. MaxItems: 20  <code>workloadPriorityClasses</code> WorkloadPriorityClass array WorkloadPriorityClasses defines a list of Kueue WorkloadPriorityClasses that Kaiwo should manage. Kaiwo ensures these priority classes exist with the specified values. See Kueue documentation for <code>WorkloadPriorityClass</code>. MaxItems: 20  <code>topologies</code> Topology array Topologies defines a list of Kueue Topologies that Kaiwo should manage. Kaiwo ensures these Topologies exist with the specified values. See Kueue documentation for <code>Topology</code>. MaxItems: 10"},{"location":"reference/crds/kaiwo.silogen.ai/#kaiwoqueueconfigstatus","title":"KaiwoQueueConfigStatus","text":"<p>KaiwoQueueConfigStatus represents the observed state of KaiwoQueueConfig.</p> <p>Appears in: - KaiwoQueueConfig</p> Field Description Default Validation <code>conditions</code> Condition array Conditions lists the observed conditions of the KaiwoQueueConfig resource, such as whether the managed Kueue resources are synchronized and ready. <code>status</code> QueueConfigStatusDescription Status reflects the overall status of the Kueue resource synchronization managed by this config (e.g., READY, FAILED)."},{"location":"reference/crds/kaiwo.silogen.ai/#kaiwoservice","title":"KaiwoService","text":"<p>KaiwoService represents a long-running service workload managed by Kaiwo. It encapsulates either a standard Kubernetes Deployment  or a RayService (via an AppWrapper), along with common metadata, storage configurations, and scheduling preferences. The Kaiwo controller reconciles this resource to create and manage the underlying workload objects.</p> <p>Appears in: - KaiwoServiceList</p> Field Description Default Validation <code>apiVersion</code> string <code>kaiwo.silogen.ai/v1alpha1</code> <code>kind</code> string <code>KaiwoService</code> <code>metadata</code> ObjectMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>spec</code> KaiwoServiceSpec Spec defines the desired state of the KaiwoService, including workload type (Deployment/RayService), configuration, resources, and common metadata. <code>status</code> KaiwoServiceStatus Status reflects the most recently observed state of the KaiwoService, including its phase, start time, duration, and conditions."},{"location":"reference/crds/kaiwo.silogen.ai/#kaiwoservicelist","title":"KaiwoServiceList","text":"<p>KaiwoServiceList</p> Field Description Default Validation <code>apiVersion</code> string <code>kaiwo.silogen.ai/v1alpha1</code> <code>kind</code> string <code>KaiwoServiceList</code> <code>metadata</code> ListMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>items</code> KaiwoService array"},{"location":"reference/crds/kaiwo.silogen.ai/#kaiwoservicespec","title":"KaiwoServiceSpec","text":"<p>KaiwoServiceSpec defines the desired state of KaiwoService.</p> <p>Appears in: - KaiwoService</p> Field Description Default Validation <code>user</code> string User specifies the owner or creator of the workload. It should typically be the user's email address. This value is primarily used for labeling (<code>kaiwo.silogen.ai/user</code>) the generated resources (like Pods, Jobs, Deployments) for identification and filtering (e.g., with <code>kaiwo list --user &lt;email&gt;</code>).In the future, if authentication is enabled, this must be the email address which is checked against authenticated user for match. <code>podTemplateSpecLabels</code> object (keys:string, values:string) PodTemplateSpecLabels allows you to specify custom labels that will be added to the <code>template.metadata.labels</code> section of the generated Pods (within Jobs, Deployments, or RayCluster specs). Standard Kaiwo system labels (like <code>kaiwo.silogen.ai/user</code>, <code>kaiwo.silogen.ai/name</code>, etc.) are added automatically and take precedence if there are conflicts. <code>gpus</code> integer Gpus specifies the total number of GPUs allocated to the workload. See here for more details on how this field impacts scheduling. 0 <code>gpuVendor</code> string GpuVendor specifies the GPU vendor (e.g., amd, nvidia, etc.). See here for more details on how this field impacts scheduling. amd <code>gpuModels</code> string array GpuModels allows you to optionally specify the GPU models that your workload will run on. You can see available models either by using the CLI and running <code>kaiwo status amd/nvidia</code> or by using kubectl command <code>kubectl get nodes -o custom-columns=NAME:.metadata.name,MODEL:.metadata.labels.kaiwo\\/gpu-model</code>This field is used to filter the available nodes for scheduling. You can specify multiple models, and Kaiwo will select the best available node that matches one of the specified models. <code>version</code> string Version allows you to specify an optional version string for the workload. This can be useful for tracking different iterations or configurations of the same logical workload. It does not directly affect resource creation but serves as metadata. <code>replicas</code> integer Replicas specifies the number of replicas for the workload. See here for more details on how this field impacts scheduling. 1 <code>gpusPerReplica</code> integer GpusPerReplica specifies the number of GPUs allocated per replica. See here for more details on how this field impacts scheduling.If you specify <code>gpusPerReplica</code>, you must also specify <code>replicas</code>. <code>duration</code> Duration Duration specifies the maximum duration over which the workload can run. This is useful for avoiding workloads running indefinitely. <code>preferredTopologyLabel</code> string PreferredTopologyLabel specifies the preferred topology label for scheduling the workload. This is used to influence how the workload is distributed across nodes in the cluster.If not specified, Kaiwo will use the default topology labels defined in the default topology of KaiwoQueueConfig starting at the host level.The levels are evaluated one-by-one going up from the level indicated by the label. If the PodSet cannot fit within a given topology label then the next topology level up is considered.If the PodSet cannot fit at the highest topology level, then it is distributed among multiple topology domains <code>requiredTopologyLabel</code> string RequiredTopologyLabel specifies the required topology label for scheduling the workload. This is used to ensure that the workload is scheduled on nodes that match the specified topology label. <code>resources</code> ResourceRequirements Resources specify the default resource requirements applied for all pods inside the workflow.This field defines default Kubernetes <code>ResourceRequirements</code> (requests and limits for CPU,memory, ephemeral-storage) applied to all containers (including init containers) withinthe workload's pods.Behavior:These values act as defaults. If a container within the underlying Job, Deployment,or Ray spec (if provided by the user) already defines a specific request or limit(e.g., <code>memory</code> limit), the value from <code>resources</code> for that specific metric will not override it.Interaction with GPU fields: The GPU requests/limits (<code>amd.com/gpu</code> or <code>nvidia.com/gpu</code>)are controlled exclusively by the <code>gpus</code>, <code>gpusPerReplica</code>, and <code>gpuVendor</code> fields(and the associated calculation logic described above). Any GPU specifications withinthe <code>resources</code> field are ignored.Default CPU/Memory with GPUs: When Kaiwo generates the underlyingJob/Deployment/RayCluster spec (i.e., the user did not provide <code>spec.job</code>,<code>spec.deployment</code>, or <code>spec.rayService</code>/<code>spec.rayJob</code>), and GPUs are requested(<code>gpusPerReplica</code> &gt; 0), Kaiwo applies default CPU and Memory requests/limitsbased on the GPU count (e.g., 4 CPU cores and 32Gi Memory per GPU).These GPU-derived defaults will override any CPU/Memory settings defined inthe <code>resources</code> field in this specific scenario. If the user does providethe underlying spec, these GPU-derived CPU/Memory defaults are not applied,respecting the user's definition or the values from the <code>resources</code> field. <code>image</code> string Image specifies the default container image to be used for the primary workload container(s).- If containers defined within the underlying Job, Deployment, or Ray spec do not specify an image, this image will be used.- If this field is also empty, the latest tag of ghcr.io/silogen/rocm-ray is used <code>imagePullSecrets</code> LocalObjectReference array ImagePullSecrets is a list of Kubernetes <code>LocalObjectReference</code> (containing just the secret <code>name</code>) referencing secrets needed to pull the container image(s). These are added to the <code>imagePullSecrets</code> field of the PodSpec for all generated pods. <code>env</code> EnvVar array Env is a list of Kubernetes <code>EnvVar</code> structs. These environment variables are added to the primary workload container(s) in the generated pods. They are appended to any environment variables already defined in the underlying Job, Deployment, or Ray spec. <code>secretVolumes</code> SecretVolume array SecretVolumes allows you to mount specific keys from Kubernetes Secrets as files into the workload containers. <code>ray</code> boolean Ray determines whether the operator should use RayCluster for workload execution.If <code>true</code>, Kaiwo will create Ray-specific resources.If <code>false</code> (default), Kaiwo will create standard Kubernetes resources (BatchJob for <code>KaiwoJob</code>, Deployment for <code>KaiwoService</code>).This setting dictates which underlying spec (<code>job</code>/<code>rayJob</code> or <code>deployment</code>/<code>rayService</code>) is primarily used. false <code>storage</code> StorageSpec Storage configures persistent storage using Kubernetes PersistentVolumeClaims (PVCs).Enabling <code>storage.data.download</code> or <code>storage.huggingFace.preCacheRepos</code> will cause Kaiwo to create a temporary Kubernetes Job (the \"download job\") before starting the main workload. This job runs a container that performs the downloads into the respective PVCs. The main workload only starts after the download job completes successfully. <code>dangerous</code> boolean Dangerous, if when set to <code>true</code>, Kaiwo will not add the default <code>PodSecurityContext</code> (which normally sets <code>runAsUser: 1000</code>, <code>runAsGroup: 1000</code>, <code>fsGroup: 1000</code>) to the generated pods. Use this only if you need to run containers as root or a different specific user and understand the security implications. false <code>clusterQueue</code> string ClusterQueue specifies the name of the Kueue <code>ClusterQueue</code> that the workload should be submitted to for scheduling and resource management.This value is set as the <code>kueue.x-k8s.io/queue-name</code> label on the underlying resources.If omitted, it defaults to the value specified by the <code>DEFAULT_CLUSTER_QUEUE_NAME</code> environment variable in the Kaiwo controller (typically \"kaiwo\"), which is set during installation.Note! If the applied KaiwoQueueConfig includes no quota for the default queue, no workload will run that tries to fall back on it.The <code>kaiwo submit</code> CLI command can override this using the <code>--queue</code> flag or the <code>clusterQueue</code> field in the <code>kaiwoconfig.yaml</code> file. <code>priorityClass</code> string WorkloadPriorityClass specifies the name of Kueue <code>WorkloadPriorityClass</code> to be assigned to the job's pods. This influences the scheduling priority relative to other pods in the cluster. <code>entrypoint</code> string EntryPoint specifies the command or script executed in a Deployment.Can also be defined inside Deployment struct as regular command in the form of string array.It is not used when <code>ray: true</code> (use <code>serveConfigV2</code> or the <code>rayService</code> spec instead for Ray entrypoints). <code>serveConfigV2</code> string Defines the applications and deployments to deploy, should be a YAML multi-line scalar string.Can also be defined inside RayService struct <code>rayService</code> RayService RayService allows providing a full <code>rayv1.RayService</code> spec.If present (or <code>spec.ray</code> is <code>true</code>), Kaiwo creates a <code>RayService</code> (wrapped in an AppWrapper for Kueue integration) instead of a <code>Deployment</code>.Common fields are merged into the <code>RayClusterSpec</code> within this spec.Allows fine-grained control over the Ray cluster and Ray Serve configurations. <code>deployment</code> Deployment Deployment allows providing a full <code>appsv1.Deployment</code> spec.If present and <code>spec.ray</code> is <code>false</code>, this is used as the base for the created <code>Deployment</code>.Common fields are merged into this spec.Allows fine-grained control over Kubernetes Deployment parameters (strategy, selectors, pod template, etc.)."},{"location":"reference/crds/kaiwo.silogen.ai/#kaiwoservicestatus","title":"KaiwoServiceStatus","text":"<p>KaiwoServiceStatus defines the observed state of KaiwoService.</p> <p>Appears in: - KaiwoService</p> Field Description Default Validation <code>startTime</code> Time StartTime records the timestamp when the first pod associated with the workload started running. <code>conditions</code> Condition array Conditions lists the observed conditions of the workload resource, following standard Kubernetes conventions. May include conditions reflecting the underlying Deployment or RayService state. <code>status</code> WorkloadStatus Status reflects the current high-level phase of the workload lifecycle (e.g., PENDING, STARTING, READY, FAILED). <code>duration</code> integer Duration indicates how long the service has been running since StartTime, in seconds. Calculated periodically while running. <code>observedGeneration</code> integer ObservedGeneration records the <code>.metadata.generation</code> of the workload resource that was last processed by the controller."},{"location":"reference/crds/kaiwo.silogen.ai/#objectstoragedownloadspec","title":"ObjectStorageDownloadSpec","text":"<p>ObjectStorageDownloadSpec aggregates download tasks for various object storage and Git sources within the <code>DataStorageSpec</code>.</p> <p>Appears in: - DataStorageSpec</p> Field Description Default Validation <code>s3</code> S3DownloadItem array S3 lists any S3 downloads <code>gcs</code> GCSDownloadItem array GCS lists and Google Cloud Storage downloads <code>azureBlob</code> AzureBlobStorageDownloadItem array AzureBlob lists any Azure Blob Storage downloads <code>git</code> GitDownloadItem array Git lists any Git downloads"},{"location":"reference/crds/kaiwo.silogen.ai/#queueconfigstatusdescription","title":"QueueConfigStatusDescription","text":"<p>Underlying type: string</p> <p>Appears in: - KaiwoQueueConfigStatus</p> Field Description <code>READY</code> <code>FAILED</code>"},{"location":"reference/crds/kaiwo.silogen.ai/#resourceflavorspec","title":"ResourceFlavorSpec","text":"<p>ResourceFlavorSpec defines the configuration for a Kueue ResourceFlavor managed by Kaiwo.</p> <p>Appears in: - KaiwoQueueConfigSpec</p> Field Description Default Validation <code>name</code> string Name specifies the name of the Kueue ResourceFlavor resource (e.g., \"amd-mi300-8gpu\"). <code>nodeLabels</code> object (keys:string, values:string) NodeLabels specifies the labels that pods requesting this flavor must match on nodes. This is used by Kueue for scheduling decisions. Keys and values should correspond to actual node labels. Example: <code>\\{\"kaiwo/nodepool\": \"amd-gpu-nodes\"\\}</code> MaxProperties: 10  <code>taints</code> Taint array Taints specifies a list of taints associated with this flavor. MaxItems: 5  <code>tolerations</code> Toleration array Tolerations specifies a list of tolerations associated with this flavor. This is less common than using Taints; Kueue primarily uses Taints to derive Tolerations. MaxItems: 5  <code>topologyName</code> string TopologyName specifies the name of the Kueue Topology that this flavor belongs to. If specified, it must match one of the Topologies defined in the KaiwoQueueConfig.This is used to group flavors by topology for scheduling purposes."},{"location":"reference/crds/kaiwo.silogen.ai/#s3downloaditem","title":"S3DownloadItem","text":"<p>S3DownloadItem defines parameters for downloading data from an S3-compatible object store.</p> <p>Appears in: - DownloadTaskConfig - ObjectStorageDownloadSpec</p> Field Description Default Validation <code>endpointUrl</code> string EndpointUrl specifies the S3 API endpoint URL (e.g., \"https://s3.us-east-1.amazonaws.com\" or a MinIO endpoint). <code>accessKeyId</code> ValueReference AccessKeyId optionally references a Kubernetes Secret containing the S3 access key ID. See <code>ValueReference</code>. <code>secretKey</code> ValueReference SecretKey optionally references a Kubernetes Secret containing the S3 secret access key. See <code>ValueReference</code>. <code>buckets</code> CloudDownloadBucket array Buckets lists the S3 buckets and the specific files/folders to download from them. See <code>CloudDownloadBucket</code>."},{"location":"reference/crds/kaiwo.silogen.ai/#secretvolume","title":"SecretVolume","text":"<p>SecretVolume defines how to mount a specific key from a Kubernetes Secret into the workload's containers.</p> <p>Appears in: - CommonMetaSpec - KaiwoJobSpec - KaiwoServiceSpec</p> Field Description Default Validation <code>name</code> string Name defines the name of the Kubernetes Volume that will be created. Should be unique within the pod. <code>secretName</code> string SecretName specifies the name of the Kubernetes Secret resource to mount from. <code>key</code> string Key specifies the key within the Secret whose value should be mounted. If omitted, the entire secret might be mounted as files (depending on Kubernetes behavior). <code>subPath</code> string SubPath defines the filename within the <code>MountPath</code> directory where the secret <code>Key</code>'s content will be placed. Useful for mounting a single secret key as a file. <code>mountPath</code> string MountPath defines the directory path inside the container where the secret volume (or the <code>SubPath</code> file) should be mounted."},{"location":"reference/crds/kaiwo.silogen.ai/#storagespec","title":"StorageSpec","text":"<p>StorageSpec defines the storage configuration for the workload.</p> <p>Appears in: - CommonMetaSpec - KaiwoJobSpec - KaiwoServiceSpec</p> Field Description Default Validation <code>storageEnabled</code> boolean StorageEnabled must be <code>true</code> to enable the creation of any PersistentVolumeClaims defined within this spec. If <code>false</code>, <code>data</code> and <code>huggingFace</code> sections are ignored. <code>storageClassName</code> string StorageClassName specifies the name of the Kubernetes <code>StorageClass</code> to use when creating PersistentVolumeClaims for <code>data</code> and <code>huggingFace</code> volumes. Must refer to an existing StorageClass in the cluster. <code>accessMode</code> PersistentVolumeAccessMode AccessMode determines the access mode (e.g., <code>ReadWriteOnce</code>, <code>ReadWriteMany</code>, <code>ReadOnlyMany</code>) for the created PersistentVolumeClaims.In a multi-node setting, ReadWriteMany is generally required, as pods scheduled on different nodes cannot access ReadWriteOnce PVCs. This is true even when <code>replicas: 1</code> if you are using download jobs, as the download pod may get scheduled on a different pod than the main workload pod. ReadWriteMany <code>data</code> DataStorageSpec Data configures the main data PersistentVolumeClaim and optional pre-download tasks for it. <code>huggingFace</code> HfStorageSpec HuggingFace configures a PersistentVolumeClaim specifically for caching Hugging Face models and datasets, with options for pre-caching."},{"location":"reference/crds/kaiwo.silogen.ai/#topology","title":"Topology","text":"<p>Topology is the Schema for the topology API</p> <p>Appears in: - KaiwoQueueConfigSpec</p> Field Description Default Validation <code>metadata</code> ObjectMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>spec</code> TopologySpec Required: {}"},{"location":"reference/crds/kaiwo.silogen.ai/#topologyspec","title":"TopologySpec","text":"<p>Appears in: - Topology</p> Field Description Default Validation <code>levels</code> TopologyLevel array levels define the levels of topology. MaxItems: 8 MinItems: 1"},{"location":"reference/crds/kaiwo.silogen.ai/#valuereference","title":"ValueReference","text":"<p>ValueReference provides a way to reference sensitive values stored in Kubernetes Secrets, typically used for credentials needed by download tasks.</p> <p>Appears in: - AzureBlobStorageDownloadItem - GCSDownloadItem - GitDownloadItem - S3DownloadItem</p> Field Description Default Validation <code>file</code> string File specifies the expected path within the download job's container where the secret value will be mounted as a file. This path is usually automatically generated by the controller based on SecretName and SecretKey. <code>secretName</code> string SecretName is the name of the Kubernetes Secret resource containing the value. <code>secretKey</code> string SecretKey is the key within the specified Secret whose value should be used."},{"location":"reference/crds/kaiwo.silogen.ai/#workloadstatus","title":"WorkloadStatus","text":"<p>Underlying type: string</p> <p>Appears in: - CommonStatusSpec - KaiwoJobStatus - KaiwoServiceStatus</p> Field Description `` WorkloadStatusNew indicates the resource has been created but not yet processed by the controller. <code>DOWNLOADING</code> WorkloadStatusDownloading indicates that the resource is currently running the download job <code>PENDING</code> WorkloadStatusPending indicates the resource is waiting for prerequisites (like Kueue admission) to complete. <code>STARTING</code> WorkloadStatusStarting indicates the Kaiwo workload has been admitted, and the underlying workload (Job, Deployment, RayService) is being created or started. <code>RUNNING</code> WorkloadStatusRunning indicates the workload pods are running. For KaiwoJob, this means the job has started execution. For KaiwoService, pods are up but may not yet be fully ready/healthy. <code>COMPLETE</code> WorkloadStatusComplete indicates a KaiwoJob has finished successfully. <code>ERROR</code> WorkloadStatusError indicates the workload encountered an error which can be recovered from. <code>FAILED</code> WorkloadStatusFailed indicates the workload (KaiwoJob or KaiwoService) encountered an error and cannot proceed or recover. <code>TERMINATING</code> WorkloadStatusTerminating indicates that the workload should begin to terminate the underlying resources. <code>TERMINATED</code> WorkloadStatusTerminated indicates the workload has been terminated by the user or system. This could be due to duration deadline being met and pressure for GPU demand."},{"location":"scientist/cli/","title":"Kaiwo CLI","text":""},{"location":"scientist/cli/#installation","title":"Installation","text":"<p>The installation of Kaiwo CLI tool is easy as it's a single binary. The only requirement is a kubeconfig file to access a Kubernetes cluster (see authentication below for authentication plugins). If you are unsure where to get a kubeconfig, speak to your infrastructure/platform administrator. Just like kubectl, Kaiwo will first look for a <code>KUBECONFIG=path</code> environment variable. If <code>KUBECONFIG</code> is not set, Kaiwo will then look for kubeconfig file in the default location <code>~/.kube/config</code>.</p> <p>You can use the convenience script to install the CLI:</p> <pre><code>curl -sSL https://raw.githubusercontent.com/silogen/kaiwo/main/get-kaiwo-cli.sh | bash -s --\n</code></pre> <p>This will install the latest CLI. If you want to install a different version, you can run</p> <pre><code>KAIWO_VERSION=vX.X.X curl -sSL https://raw.githubusercontent.com/silogen/kaiwo/main/get-kaiwo-cli.sh | bash -s --\n</code></pre> <p>You're off to the races!</p> <p>If you want to uninstall the Kaiwo CLI, you can run</p> <pre><code>curl -sSL https://raw.githubusercontent.com/silogen/kaiwo/main/get-kaiwo-cli.sh | bash -s --\n</code></pre> <p>Although not strictly required, we recommend that you also install kubectl just in case you need some functionality that Kaiwo can't provide.</p>"},{"location":"scientist/cli/#authentication","title":"Authentication","text":"<p>Speak to your infrastructure/platform administrator whether your cluster requires external authentication (OIDC, Azure, GKE). If authentication is required, you will have to install a separate authentication plugin. The following plugins should work with Kaiwo, so you won't necessarily need a separate installation of kubectl.</p> <ul> <li>int128/kubelogin: kubectl plugin for Kubernetes OpenID Connect authentication (kubectl oidc-login)) (tested)</li> <li>Azure Kubelogin (untested)</li> <li>GKE: gke-gcloud-auth-plugin (tested)</li> </ul> <p>For example, your kubeconfig that uses kubelogin should resemble the following format:</p> <pre><code>apiVersion: v1\nclusters:\n-   cluster:\n        server: https://kube-api-endpoint:6443\n    name: default\ncontexts:\n-   context:\n        cluster: default\n        user: default\n    name: default\ncurrent-context: default\nkind: Config\npreferences: {}\nusers:\n-   name: default\n    user:\n        exec:\n            apiVersion: client.authentication.k8s.io/v1beta1\n            args:\n            - get-token\n            - --oidc-issuer-url=https://my.issuer.address.com/realms/realm_name\n            - --oidc-client-id=my_client_id_name\n            - --oidc-client-secret=my_client_id_secret\n            command: kubelogin\n            interactiveMode: IfAvailable\n            provideClusterInfo: false\n</code></pre> <p>In case your certificate trust store gives \"untrusted\" certificate errors, you can use <code>insecure-skip-tls-verify: true</code> under cluster and <code>--insecure-skip-tls-verify</code> in <code>kubelogin get-token</code> as a temporary workaround. As usual, we don't recommend this in production.</p>"},{"location":"scientist/cli/#configuration","title":"Configuration","text":"<p>Command-Line Flags:</p> <p>Users configure the <code>kaiwo</code> CLI tool via a YAML file. If this is not set, kaiwo cli will prompt you to create a config file interactively. The config file can be specified via the <code>--config</code> flag or the <code>KAIWOCONFIG</code> environment variable. If neither is set, kaiwo will look for a config file in the default location.</p> <p>Location Precedence:</p> <ol> <li>Path specified by <code>--config &lt;path&gt;</code> flag in <code>kaiwo submit</code>.</li> <li>Path specified by the <code>KAIWOCONFIG</code> environment variable.</li> <li>Default path: <code>~/.config/kaiwo/kaiwoconfig.yaml</code>.</li> </ol> <p>Fields:</p> <ul> <li><code>user</code>: The user's identifier (typically email) to be associated with submitted workloads (sets <code>spec.user</code> and <code>kaiwo.silogen.ai/user</code> label).</li> <li><code>clusterQueue</code>: The default Kueue <code>ClusterQueue</code> to submit workloads to (sets <code>spec.clusterQueue</code> and <code>kueue.x-k8s.io/queue-name</code> label).</li> </ul> <p>Example:</p> <pre><code># ~/.config/kaiwo/kaiwoconfig.yaml\nuser: scientist@example.com\nclusterQueue: team-a-queue\n</code></pre> <p>The <code>kaiwo submit</code> command provides an interactive prompt to create this file if it's missing and user/queue information isn't provided via flags.</p>"},{"location":"scientist/cli/#usage","title":"Usage","text":"<p>You can use the Kaiwo CLI to</p> <ul> <li><code>kaiwo submit</code>: Quickly launch Kaiwo workloads (jobs and services)</li> <li><code>kaiwo manage</code>: List and manage currently running workloads</li> <li><code>kaiwo logs</code>: Fetch workload logs</li> <li><code>kaiwo monitor</code>: Monitor (GPU) workloads</li> <li><code>kaiwo exec</code>: Execute arbitrary commands inside the workload containers</li> <li><code>kaiwo stats</code>: Check the status of your cluster</li> </ul> <p>For a list of full functionality run <code>kaiwo --help</code>, or for a specific command, <code>kaiwo &lt;command&gt; --help</code>.</p>"},{"location":"scientist/cli/#before-running-workloads-with-kaiwo","title":"Before running workloads with Kaiwo","text":"<p>Kaiwo uses Kueue to manage job queuing. Make sure your cluster-admin has created two necessary Kueue resources on the cluster: <code>ResourceFlavor</code> and <code>ClusterQueue</code>. Manifests for these can be found under <code>cluster-admins</code> directory. By default, kaiwo will always submit workloads to <code>kaiwo</code> ClusterQueue if no other queue is provided with <code>-q</code>or<code>--queue</code> option during <code>kaiwo submit</code>. Kaiwo will automatically create the namespaced <code>LocalQueue</code> resource if it doesn't exist. Speak to your cluster-admin if you are unsure which <code>ClusterQueue</code> is allocated to your team.</p>"},{"location":"scientist/cli/#submitting-workloads","title":"Submitting workloads","text":"<p>Given a Kaiwo manifest, you can submit it via the following command:</p> <pre><code>kaiwo submit -f &lt;manifest.yaml&gt;\n</code></pre> <p>As you may want to leave the user and queue definitions empty to allow different users to run the workload, you can provide this information via other methods (see above).</p> <p>Caution</p> <p>One important note about GPU requests: it is up to the user to ensure that the code can run on the requested number of GPUs. If the code is not written to run on the requested number of GPUs, the job will fail. Note that some parallelized code may only work on a specific number of GPUs such as 1, 2, 4, 8, 16, 32 but not 6, 10, 12 etc. If you are unsure, start with a single GPU and scale up as needed. For example, the total number of attention heads must be divisible by tensor parallel size.</p>"},{"location":"scientist/cli/#managing-workloads","title":"Managing workloads","text":"<p>You can list currently running workloads by running <code>kaiwo manage [flags]</code>. This displays a terminal application which you can use to:</p> <ul> <li>Select the workload type</li> <li>Delete the workload</li> <li>List the workload logs</li> <li>Port forward to the workload</li> <li>Run a command within a workload container</li> <li>Monitor a workload pod</li> </ul> <p>By default, only workloads that you have submitted are shown. You can use the following flags:</p> <ul> <li><code>-n / --namespace</code> to specify the namespace</li> <li><code>-u / --user</code> to specify a different user</li> <li><code>--all-users</code> to show workloads from all users</li> </ul>"},{"location":"scientist/cli/#fetching-workload-logs","title":"Fetching workload logs","text":"<p>You can fetch workload logs by running</p> <pre><code>kaiwo logs &lt;workloadType&gt;/&lt;workloadName&gt; [flags]\n</code></pre> <p>where <code>&lt;workloadType&gt;</code> is either <code>job</code> or <code>service</code>.</p> <p>The following flags are supported:</p> <ul> <li><code>-f / --follow</code> to follow the output</li> <li><code>-n / --namespace</code> to specify the namespace</li> <li><code>--tail</code> to specify the number of lines to tail</li> </ul>"},{"location":"scientist/cli/#monitoring-workloads","title":"Monitoring workloads","text":"<p>You can monitor workload GPU usage by running</p> <pre><code>kaiwo monitor &lt;workloadType&gt;/&lt;workloadName&gt; [flags]\n</code></pre> <p>where <code>&lt;workloadType&gt;</code> is either <code>job</code> or <code>service</code>.</p> <p>The following flags are supported:</p> <ul> <li><code>-n / --namespace</code> to specify the namespace</li> </ul>"},{"location":"scientist/cli/#executing-commands","title":"Executing commands","text":"<p>You can execute a command inside a container interactively by running</p> <pre><code>kaiwo exec &lt;workloadType&gt;/&lt;workloadName&gt; [flags]\n</code></pre> <p>where <code>&lt;workloadType&gt;</code> is either <code>job</code> or <code>service</code>.</p> <p>The following flags are supported:</p> <ul> <li><code>-i / --interactive</code> to enable interactive mode (default true)</li> <li><code>-t / --tty</code> to enable TTY (default true)</li> <li><code>--command</code> to specify the command to execute</li> <li><code>-n / --namespace</code> to specify the namespace</li> </ul>"},{"location":"scientist/cli/#checking-cluster-status","title":"Checking cluster status","text":"<p>You can check the current resource availability (including GPUs) of your cluster by running: </p> <p><pre><code>kaiwo status amd\n</code></pre> or <pre><code>kaiwo status nvidia\n</code></pre></p> <p>You can check the current queue statuses for GPU jobs by running:</p> <pre><code>kaiwo status queues\n</code></pre>"},{"location":"scientist/overview/","title":"Overview","text":"<p>This section is targeted at AI Scientists, engineers, and researchers who are interested in using Kaiwo to deploy AI workloads. It provides an overview of Kaiwo's features and benefits, as well as guidance on how to get started with deploying AI workloads with Kaiwo.</p> <p>The two main components of Kaiwo are the Kaiwo CLI and the Kaiwo Operator. The components are described here.</p> <p>Features and Benefits to AI Scientists</p> <ul> <li>Easy Deployment: Kaiwo simplifies the process of deploying AI workloads on Kubernetes, allowing scientists to focus on their research rather than infrastructure management.</li> <li>Broad Workload Support: Kaiwo supports a wide range of AI workloads, including distributed multi-node pretraining, fine-tuning, online inference, and batch inference. This flexibility allows scientists to run various types of workloads without needing to switch tools. At the moment, we support Batch Jobs, Deployments, RayJobs, and RayServices. We will continue to add support for other workload types in the future.</li> <li>Scalability: Kaiwo leverages the power of Kubernetes to scale workloads up or down based on demand, ensuring efficient resource utilization.</li> <li>Resource Management: Kaiwo provides advanced resource management capabilities, allowing scientists to allocate resources based on workload requirements. By default, Kaiwo monitors workloads' GPU usage and terminates workloads that underutilize GPUs for too long, ensuring capacity is released back to those that need it.</li> <li>Monitoring and Logging: Kaiwo offers built-in monitoring and logging features, enabling scientists to track the performance of their workloads and troubleshoot issues easily.</li> <li>Integration with Ray: Kaiwo integrates seamlessly with Ray, a powerful distributed computing framework, enabling scientists to run large-scale AI workloads efficiently.</li> <li>Integration with Kueue: Kaiwo uses Kueue for queueing and scheduling of all supported workload types, ensuring efficient management of workloads in a Kubernetes environment.</li> </ul> <p>To get started with Kaiwo, scientists can follow the quickstart guides. These guides cover various aspects of deploying AI workloads, including training, distributed training, inference, and distributed inference. The quickstart guides are designed to help scientists quickly understand how to use Kaiwo and get their workloads up and running on Kubernetes.</p>"},{"location":"scientist/quickstart/","title":"Quickstart Guides","text":"<p>This section provides quickstart guides for deploying AI workloads with Kaiwo. It covers the following topics:</p> <ul> <li>CLI quickstart</li> <li>Training</li> <li>Distributed Training</li> <li>Inference</li> <li>Distributed Inference</li> </ul>"},{"location":"scientist/quickstart/#cli-quickstart","title":"CLI Quickstart","text":"<p>This quickstart assumes Kaiwo Operator has been installed. If you suspect this is not the case, see here.</p> <p>Workloads can be submitted to Kaiwo Operator via Kaiwo CLI or Kubectl. Kaiwo CLI is a command-line interface that simplifies the process of submitting and managing workloads on Kubernetes. It provides a user-friendly interface for interacting with the Kaiwo Operator, making it easier to deploy and manage AI workloads.</p> <p>This is the TL;DR version of the installation instructions. For more details, see the installation guide.</p> <p>Make sure you have a working KUBECONFIG file. Then, install Kaiwo CLI by running the following commands in your terminal:</p> <pre><code>export KAIWO_VERSION=v.0.1 &amp;&amp; \\\nwget https://github.com/silogen/kaiwo/releases/download/$KAIWO_VERSION/kaiwo_linux_amd64 &amp;&amp; \\\nmv kaiwo_linux_amd64 kaiwo &amp;&amp; \\\nchmod +x kaiwo &amp;&amp; \\\nsudo mv kaiwo /usr/local/bin/ &amp;&amp; \\\nwget https://github.com/silogen/kaiwo/releases/download/$KAIWO_VERSION/workloads.zip &amp;&amp; \\\nunzip workloads.zip &amp;&amp; \\\nkaiwo version &amp;&amp; \\\nkaiwo help\n</code></pre> <p>You're off to the races!</p>"},{"location":"scientist/quickstart/#training","title":"Training","text":""},{"location":"scientist/quickstart/#simple-multi-gpu-training-workload","title":"Simple multi-GPU training workload","text":"<p>Let's take a look at how to deploy a multi-GPU training workload with Kaiwo. For training, we need to use a KaiwoJob. KaiwoJobs handle regular Batch Jobs and RayJobs. For example, if Kaiwo's default image is sufficient for your workload (note, the image assumes AMD GPUs), you can use the following which will run Direct Preference Optimization (DPO) on a single node with 4 GPUs. Source code and manifest can be found here:</p> <pre><code>apiVersion: kaiwo.silogen.ai/v1alpha1\nkind: KaiwoJob\nmetadata:\n  name: dpo-singlenode\nspec:\n  user: test@amd.com\n  gpus: 4\n  entrypoint: |\n    accelerate launch code/dpo.py \\\n    --dataset_name trl-lib/ultrafeedback_binarized \\\n    --model_name_or_path Qwen/Qwen2-0.5B-Instruct \\\n    --learning_rate 5.0e-6 \\\n    --num_train_epochs 1 \\\n    --per_device_train_batch_size 8 \\\n    --logging_steps 25 \\\n    --eval_strategy steps \\\n    --eval_steps 50 \\\n    --output_dir Qwen2-0.5B-DPO \\\n    --no_remove_unused_columns \\\n    --use_peft \\\n    --lora_r 32 \\\n    --lora_alpha 16 \\\n    --bf16 \\\n    --optim=\"adamw_torch\"  \n  storage:\n    storageEnabled: true\n    storageClassName: multinode\n    data:\n      storageSize: 10Mi\n      mountPath: /workload\n      download:\n        git:\n        - repository: https://github.com/silogen/kaiwo.git\n          path: workloads/training/LLMs/dpo-singlenode\n          targetPath: code\n    huggingFace:\n      storageSize: \"30Gi\"\n      # automatically sets HF_HOME env variable for all containers\n      preCacheRepos:\n      - repoId: Qwen/Qwen2-0.5B-Instruct\n</code></pre> <p>You can submit this to kubernetes either via <code>kubectl apply -f filename.yaml</code> or by running <code>kaiwo submit -f filename.yaml</code>. Here are reasons why you may want to use <code>kaiwo submit</code></p> <ol> <li>Kaiwo will automatically add <code>user</code> (your email) and <code>clusterQueue</code> to the manifest upon submission. If it's your first submission, kaiwo cli will ask you for this information. You only have to do this once.</li> <li>If your kaiwojobs include <code>user</code>, you can manage and monitor your workloads easily later with <code>kaiwo manage</code>. For example, you can list your submissions, check their GPU utilization, port-forward to a pod or execute commands.</li> </ol> <p>After receiving this simple workload submission, Kaiwo Operator does the following at minimum:</p> <ol> <li>It adds your workload to the queue you provided, assuming you were granted permission to use the queue. This depends on which namespace you have access to. Queueing policies are set by administrators in KaiwoQueueConfig</li> <li>It runs your storage task (if any) and waits for it to finish before reserving GPUs. This is done by creating a separate Job that will run before your AI workload. </li> <li>Kaiwo will use binpacking and try find a node that is already partially reserved before looking for new nodes. If you didn't provide <code>gpuVendor</code> field, the operator will look for nodes with AMD GPUs. You can change this by providing <code>gpuVendor: nvidia</code>.</li> <li>Kaiwo Operator creates environment variable <code>NUM_GPUS</code> in the container, which is set to the number of GPUs requested. This means you don't have to hardcode the number of GPUs in your code. You can use this variable in your entrypoint or in your code.</li> </ol>"},{"location":"scientist/quickstart/#using-storage-task-with-kaiwojobsservices","title":"Using storage task with KaiwoJobs/Services","text":"<p>As our example above shows, Kaiwo makes it possible to download artifacts (model weights, data, code, etc.) into a persistent volume before starting the training workload. This is done by filling in <code>data</code> or <code>huggingFace</code> sections of KaiwoJob/KaiwoService. We must specify a mountPath under <code>data</code>. All subsequent targetPaths will be relative to this mountPath. The storage task will create separate persistent volume claims for <code>data</code> and <code>huggingFace</code> with the specified storageClassName and storageSize. We specify a mountPath for <code>huggingFace</code> as well, which will be used to set the HF_HOME environment variable in each container. This is useful if you want to use the HuggingFace cache in your training workload.  For more details on storage tasks, see here.</p>"},{"location":"scientist/quickstart/#distributed-training","title":"Distributed training","text":"<p>Our example of distributed training uses Ray and DeepSpeed's Zero-3 optimization which partitions optimizer states, gradients, and parameters across GPUs. This allows us to train models that are larger than the memory of a single GPU. ZeRO-3 also includes the infinity offload engine, which can offload model states to RAM or NVME disks for significant GPU memory savings. Source code and manifest can be found here.</p> <p>The training example requires object storage for saving model checkpoints. If you don't have an object storage solution, you can use MinIO, which is a self-hosted S3-compatible object storage solution. The following manifest will deploy MinIO on your cluster and create a bucket called <code>silogen-dev</code> for you. You can change the bucket name in the manifest if you want.</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: minio-secret\n  namespace: kaiwo\ndata:\n  access_key_id: bWluaW8= # minio\n  secret_key: bWluaW8xMjM= # minio123\n---\n\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: minio-pvc\n  namespace: kaiwo\nspec:\n  accessModes:\n  - ReadWriteMany\n  resources:\n    requests:\n      storage: 500Gi\n  storageClassName: multinode\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: minio-deployment\n  namespace: kaiwo\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: minio\n  template:\n    metadata:\n      labels:\n        app: minio\n    spec:\n      containers:\n      - name: minio\n        image: minio/minio\n        args: [\"server\", \"/data\"]\n        resources:\n          limits:\n            cpu: \"1\"\n            memory: \"1Gi\"\n          requests:\n            cpu: \"1\"\n            memory: \"1Gi\"\n        env:\n        - name: MINIO_ROOT_USER\n          valueFrom:\n            secretKeyRef:\n              name: minio-secret\n              key: access_key_id\n        - name: MINIO_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: minio-secret\n              key: secret_key\n        ports:\n        - containerPort: 9000\n        volumeMounts:\n        - name: minio-data\n          mountPath: /data\n      - name: bucket-init\n        image: minio/mc\n        resources:\n          limits:\n            cpu: \"1\"\n            memory: \"1Gi\"\n          requests:\n            cpu: \"1\"\n            memory: \"1Gi\"\n        env:\n        - name: MINIO_ROOT_USER\n          valueFrom:\n            secretKeyRef:\n              name: minio-secret\n              key: access_key_id\n        - name: MINIO_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: minio-secret\n              key: secret_key\n        command:\n        - sh\n        - -c\n        - |\n          until /usr/bin/mc alias set local http://minio-service:9000 $MINIO_ROOT_USER $MINIO_ROOT_PASSWORD; do\n            echo \"Waiting for MinIO to be available...\"\n            sleep 5\n          done\n          /usr/bin/mc mb -p local/silogen-dev || echo \"Bucket already exists\"\n          echo \"Bucket init done, sleeping forever...\"\n          tail -f /dev/null\n      volumes:\n      - name: minio-data\n        persistentVolumeClaim:\n          claimName: minio-pvc\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: minio-service\n  namespace: kaiwo\nspec:\n  selector:\n    app: minio\n  ports:\n  - protocol: TCP\n    port: 9000\n    targetPort: 9000\n    name: minio-endpoint\n  type: ClusterIP\n</code></pre> <p>Once you have storage available, you can run the following KaiwoJob manifest. This will run a distributed training workload with 16 GPUs automatically using as many nodes as required. For example, if you have 4 x 8 GPU nodes where 50% of capacity is reserved on each node, Kaiwo will create 4 replicas each using 4 GPUs. Notice that this scenario of 50% GPU reservation on every node is unlikely. Kaiwo automatically uses binpacking, ensuring that each GPU node is used to maximum capacity before another GPU node is requested. </p> <p>The following manifest will also create a persistent volume claim for the model weights. The model weights will be downloaded from HuggingFace and cached in the persistent volume before any GPUs are reserved. Notice that you will need a secret that holds your Huggingface token if you are downloading a gated model.</p> <pre><code>apiVersion: kaiwo.silogen.ai/v1alpha1\nkind: KaiwoJob\nmetadata:\n  name: multinode-stage-zero3-pretraining-example\nspec:\n  user: test@amd.com\n  gpus: 16\n  ray: true\n  entrypoint: |\n    python code/main.py \\\n    --model-name=meta-llama/Llama-3.1-8B-Instruct \\\n    --ds-config=./code/zero_3_offload_optim_param.json \\\n    --bucket=silogen-dev \\\n    --num-epochs=1 \\\n    --num-devices=$NUM_GPUS \\\n    --batch-size-per-device=32 \\\n    --eval-batch-size-per-device=32 \\\n    --ctx-len=1024\n  env:\n  - name: AWS_ACCESS_KEY_ID\n    valueFrom:\n      secretKeyRef:\n        name: minio-secret\n        key: access_key_id\n  - name: AWS_SECRET_ACCESS_KEY\n    valueFrom:\n      secretKeyRef:\n        name: minio-secret\n        key: secret_key\n  - name: HF_TOKEN\n    valueFrom:\n      secretKeyRef:\n        name: hf-token\n        key: hf-token\n  - name: MODEL_ID\n    value: meta-llama/Llama-3.1-8B-Instruct\n  storage:\n    storageEnabled: true\n    storageClassName: multinode\n    data:\n      storageSize: 20Mi\n      mountPath: /workload\n      download:\n        git:\n        - repository: https://github.com/silogen/kaiwo.git\n          path: workloads/training/LLMs/full-parameter-pretraining/full-param-zero3-single-multinode\n          targetPath: code\n    huggingFace:\n      storageSize: \"100Gi\"\n      mountPath: \"/hf_cache\" # Also sets the env var HF_HOME to this value in each container\n      preCacheRepos:\n      - repoId: meta-llama/Llama-3.1-8B-Instruct\n        files: []\n</code></pre> <p>Notice that our finetuning example is almost identical to this pre-training example except the former uses Lora for parameter-efficient finetuning. The only difference is the entrypoint and Lora config. You can find the manifest and source code here</p>"},{"location":"scientist/quickstart/#batch-inference-single-and-multi-node","title":"Batch inference (single- and multi-node)","text":"<p>Batch inference is a common use case for AI workloads, where large amounts of data are processed in batches to generate predictions or insights. Kaiwo supports batch inference workloads using KaiwoJobs. The following example demonstrates how to deploy a batch inference workload with Kaiwo. Our example uses vLLM and Ray to scale up inference to multiple replicas on multiple nodes (one model replica per node). </p> <p>Once again, model weights will be downloaded from HuggingFace and cached in the persistent volume before any GPUs are reserved. Notice that you will need a secret that holds your Huggingface token if you are downloading a gated model.</p> <p>Run offline inference with the following manifest. Source code and manifest can be found here</p> <pre><code>apiVersion: kaiwo.silogen.ai/v1alpha1\nkind: KaiwoJob\nmetadata:\n  name: batch-inference-vllm-example\nspec:\n  user: test@amd.com\n  gpusPerReplica: 4\n  replicas: 1\n  ray: true\n  entrypoint: python code/main.py\n  env:\n  - name: HF_TOKEN\n    valueFrom:\n      secretKeyRef:\n        name: hf-token\n        key: hf-token\n  - name: MODEL_ID\n    value: meta-llama/Llama-3.1-8B-Instruct\n  storage:\n    storageEnabled: true\n    storageClassName: multinode\n    data:\n      storageSize: 20Mi\n      mountPath: /workload\n      download:\n        git:\n        - repository: https://github.com/silogen/kaiwo.git\n          path: workloads/inference/LLMs/offline-inference/vllm-batch-single-multinode\n          targetPath: code\n    huggingFace:\n      storageSize: \"100Gi\"\n      mountPath: \"/hf_cache\" # Also sets the env var HF_HOME to this value in each container\n      preCacheRepos:\n      - repoId: meta-llama/Llama-3.1-8B-Instruct\n        files: []\n</code></pre>"},{"location":"scientist/quickstart/#online-inference-single-and-multi-node","title":"Online inference (single- and multi-node)","text":"<p>Similar to our offline example, our online inference example also uses vLLM and Ray. The online inference example supports multi-node inference (one model partitioned across multiple nodes). However, we recommend sticking to a single node when possible as there are likely to be performance penalties from network bottlenecks.</p> <p>Run online inference with the following manifest. Source code and manifest can be found here</p> <pre><code>apiVersion: kaiwo.silogen.ai/v1alpha1\nkind: KaiwoService\nmetadata:\n  name: online-inference-vllm-example\nspec:\n  user: test@amd.com\n  gpus: 4\n  ray: true\n  serveConfigV2: |\n    applications:\n    - name: llm\n      route_prefix: /\n      import_path: workloads.inference.LLMs.online-inference.vllm-online-single-multinode:deployment\n      runtime_env:\n          working_dir: \"https://github.com/silogen/kaiwo/archive/b66c14303f3beadc08e11a89fd53d7f71b2a15cd.zip\"\n      deployments:\n      - name: VLLMDeployment\n        autoscaling_config:\n          metrics_interval_s: 0.2\n          look_back_period_s: 2\n          downscale_delay_s: 600\n          upscale_delay_s: 30\n          target_num_ongoing_requests_per_replica: 20\n        graceful_shutdown_timeout_s: 5\n        max_concurrent_queries: 100\n  env:\n  - name: NCCL_P2P_DISABLE\n    value: \"1\"\n  - name: MODEL_ID\n    value: \"meta-llama/Llama-3.1-8B-Instruct\"\n  - name: GPU_MEMORY_UTILIZATION\n    value: \"0.9\"\n  - name: PLACEMENT_STRATEGY\n    value: \"PACK\"\n  - name: MAX_MODEL_LEN\n    value: \"8192\"\n  - name: MAX_NUM_SEQ\n    value: \"4\"\n  - name: MAX_NUM_BATCHED_TOKENS\n    value: \"32768\"\n  - name: HF_TOKEN\n    valueFrom:\n      secretKeyRef:\n        name: hf-token\n        key: hf-token\n  storage:\n    storageEnabled: true\n    storageClassName: multinode\n    huggingFace:\n      storageSize: \"100Gi\"\n      mountPath: \"/hf_cache\" # Also sets the env var HF_HOME to this value in each container\n      preCacheRepos:\n      - repoId: meta-llama/Llama-3.1-8B-Instruct\n        files: []\n</code></pre>"},{"location":"scientist/scheduling/","title":"Scheduling","text":""},{"location":"scientist/scheduling/#replicas-gpus-gpusperreplica-and-gpuvendor","title":"<code>replicas</code>, <code>gpus</code>, <code>gpusPerReplica</code>, and <code>gpuVendor</code>","text":"<p>These fields collectively control the number of workload instances and how GPUs are allocated across them. Their interaction depends on the workload type (Job/Service) and whether Ray is used (<code>ray: true</code>).</p> <p>Purpose:</p> <ul> <li><code>replicas</code>: Sets the desired number of instances (pods). Default: 1. Ignored for non-Ray Jobs.</li> <li><code>gpus</code>: Specifies the total number of GPUs requested across all replicas. Default: 0.</li> <li><code>gpusPerReplica</code>: Specifies the number of GPUs requested per replica. Default: 0.</li> <li><code>gpuVendor</code>: Either <code>amd</code> (default) or <code>nvidia</code>. Determines the GPU resource key (e.g., <code>amd.com/gpu</code>, <code>nvidia.com/gpu</code>).</li> </ul> <p>Behavior:</p> <ol> <li> <p>Non-Ray Workloads (<code>ray: false</code>):</p> <ul> <li>KaiwoJob: Only one pod is created. <code>replicas</code> is ignored. <code>gpus</code> or <code>gpusPerReplica</code> (if set &gt; 0) determines the GPU request for the single pod's container. If both <code>gpus</code> and <code>gpusPerReplica</code> are set, <code>gpusPerReplica</code> takes precedence if &gt; 0, otherwise <code>gpus</code> is used.</li> <li>KaiwoService (Deployment): <code>replicas</code> directly sets the <code>deployment.spec.replicas</code>. <code>gpus</code> or <code>gpusPerReplica</code> (if set &gt; 0) determines the GPU request for each replica's container. If both <code>gpus</code> and <code>gpusPerReplica</code> are set, <code>gpusPerReplica</code> takes precedence if &gt; 0, otherwise <code>gpus</code> is used (implying <code>gpusPerReplica = gpus / replicas</code>, though this division isn't explicitly performed; the request per pod is set based on the determined <code>gpusPerReplica</code> value).</li> </ul> </li> <li> <p>Ray Workloads (<code>ray: true</code>):</p> <ul> <li>The controller performs a calculation (<code>CalculateNumberOfReplicas</code>) considering cluster node capacity (specifically, the minimum GPU capacity available on nodes matching the <code>gpuVendor</code>, referred to as <code>minGpusPerNode</code>).</li> <li>User Precedence: If the user explicitly sets both <code>replicas</code> (&gt; 0) and <code>gpusPerReplica</code> (&gt; 0), these values are used directly, provided the total requested GPUs (<code>replicas * gpusPerReplica</code>) does not exceed the total available GPUs of the specified <code>gpuVendor</code> in the cluster. The <code>gpus</code> field is ignored in this case.</li> <li>Calculation Fallback: If the user does not explicitly set both <code>replicas</code> and <code>gpusPerReplica</code>, or if the requested total exceeds cluster capacity, the controller calculates the optimal <code>replicas</code> and <code>gpusPerReplica</code> based on the <code>gpus</code> field and the cluster's <code>minGpusPerNode</code>.<ul> <li>The <code>totalUserRequestedGpus</code> is determined (using <code>gpus</code> field, capped at total cluster capacity).</li> <li>The final <code>replicas</code> is calculated as <code>ceil(totalUserRequestedGpus / minGpusPerNode)</code>.</li> <li>The final <code>gpusPerReplica</code> is calculated as <code>totalUserRequestedGpus / replicas</code>.</li> </ul> </li> <li>The calculated or user-provided <code>replicas</code> value sets the Ray worker group replica count (<code>minReplicas</code>, <code>maxReplicas</code>, <code>replicas</code>). This is due the fact that Kueue does not support Ray's autoscaling.</li> <li>The calculated or user-provided <code>gpusPerReplica</code> value sets the GPU resource request/limit for each Ray worker pod's container.</li> </ul> </li> </ol> <p>Summary Table (Ray Workloads):</p> User Input (<code>spec.*</code>) Calculation Performed? Outcome (<code>replicas</code>, <code>gpusPerReplica</code>) Notes <code>replicas &gt; 0</code>, <code>gpusPerReplica &gt; 0</code> No* Uses user's <code>replicas</code>, user's <code>gpusPerReplica</code> *If total fits cluster. <code>gpus</code> ignored. Highest precedence. <code>gpus &gt; 0</code> (only) Yes Calculated based on <code>gpus</code> and <code>minGpusPerNode</code> Aims to maximize GPUs per node up to <code>minGpusPerNode</code>. <code>replicas &gt; 0</code>, <code>gpus &gt; 0</code> Yes Calculated based on <code>gpus</code> and <code>minGpusPerNode</code> (user <code>replicas</code> ignored) Falls back to calculation based on total <code>gpus</code>. <code>gpusPerReplica &gt; 0</code>, <code>gpus &gt; 0</code> Yes Calculated based on <code>gpus</code> and <code>minGpusPerNode</code> (user <code>gpusPerReplica</code> ignored) Falls back to calculation based on total <code>gpus</code>. All three set No* Uses user's <code>replicas</code>, user's <code>gpusPerReplica</code> *If total fits cluster (like row 1). Otherwise, calculates based on <code>gpus</code>. None set (or only <code>gpuVendor</code>) No <code>replicas=1</code>, <code>gpusPerReplica=0</code> No GPUs requested."}]}